[[hardware]]
== 4. Soluciones por hardware

image::jrmora/04-hardware.jpg[align="center"]

Hemos visto algoritmos que solucionan la exclusión mutua sin soporte especial de hardware, solo requieren _registros atómicos_ (las variables enteras compartidas)footnote:[Salvo el algoritmo de la panadería, este no requiere registros que aseguren atomicidad de lecturas y escrituras. Aunque no pueda asegurar espera limitada también asegura exclusión mutua con registros que retornan valores erróneos, como los registros _seguros_ que se estudian más adelante (<<Lamport15>>).]. Son _spinlocks_ pero sin uso práctico, son muy ineficientes.

Lo son, en primer lugar, por los requisitos de almacenamiento. El número de registros necesarios –tamaño de arrays– es proporcional al número máximo de procesos concurrentesfootnote:[Está demostrado (<<Herlihy12>>) que dichos algoritmos son óptimos en cuestión de espacio]. En sistemas _SMP_ esto implica una sobrecarga importante, el sistema de coherencia de caché debe mantener la consistencia de zonas extensas de memoria.

En segundo lugar, si los procesos se ejecutan en un único procesador el avance es tan lento como impredecible ya que depende del grado de competencia y comportamiento del _scheduler_.

Desde que se comenzó a estudiar el problema de la concurrencia –inicios de la década de 1960– se buscaron soluciones por hardware que permitiesen implementar algoritmos más eficientes y seguros.


=== Inhabilitación de interrupciones
Si el problema fundamental es el intercalado provocado por las interrupciones, ¿por qué no deshabilitarlas? Aunque se recurre a este mecanismo en casos muy concretos en el núcleofootnote:[Como +local_irq_disable()+ o +local_irq_enable()+ en Linux.], no es una solución genérica segura. Si un proceso puede deshabilitar las interrupciones también puede tomar el control del sistema: se anula la cualidad de apropiativo del _scheduler_. No es una solución aceptable para _procesos de usuarios_.

Inhabilitar interrupciones presenta dificultades aún en el núcleo del sistema operativo. Existe el riesgo de perderlas y la complicación para hacerlo en todos los procesadores. Además, por la dificultad de deshabilitar interrupciones simultáneamente en varios procesadores tampoco se previene el efecto de intercalación: la memoria puede ser modificada por un procesador sin las interrupciones inhabilitadas.

=== Sincronización por hardware
Se desarrollaron alternativas a nivel del procesador, las _primitivas de sincronización de hardware_. Son instrucciones que leen y modifican el valor de uno o varios registros sin ser interrumpidas. También aseguran coherencia de caché e introducen barreras de memoria para mantener el orden parcial de instrucciones.

No existe un único conjunto estándar de primitivas, los fabricantes desarrollaron sus propias instrucciones. Es difícil y arriesgado decidir cuáles implementarán en _silicio_, ya que deberán ser usadas por décadas sin posibilidad de cambiarlas. Así pues, casi todas las arquitecturas ofrecen un conjunto de primitivas, _get&add_, _test&set (TAS)_, _swap_, _compare&swap (CAS)_, etc.

Antes de entrar en detalles de las instrucciones, definiremos formalmente a los _registros_ y sus propiedades de consistencia.

=== Tipos de registros
Desde el punto de vista formal de concurrencia, el término genérico _registro_ no se refiere solo a registros del procesador. Puede involucrar a zonas de memoria RAM, memoria caché, o en general a un _objeto compartido_. A nivel de hardware los procesos se comunican leyendo y escribiendo en memoria compartida: la comunicación se hace vía _registros de lectura-escritura_. Un registro de este tipo encapsula dos métodos, _read_ y _store_. O _get_ y _write_ cuando se habla de objetos compartidos genéricos que pueden ser implementados en lenguajes de alto nivel.

Hay diferentes tipos de registros, cada uno con diferentes _propiedades de consistencia_.

[[safe_register]]
==== Registros _seguros_
Los registros con propiedades de consistencia más débiles son los _registros seguros_ (o _safe registers_). El nombre es un accidente histórico, son muy inseguros (<<Herlihy12>>). Estos registros solo aseguran que se retorna el último valor escrito si no hay operaciones _get_ y _write_ concurrentes, caso contrario pueden devolver cualquier valor aceptable en el rango del registro. Por ejemplo, si es un único byte y hay procesos concurrentes que escriben solo 0 o 1, el _get_ de un registro _seguro_ puede devolver valores entre 0 y 255 ya que todos están en el rango de ocho bits.

==== Registros regulares
En el siguiente nivel están los _registros regulares_. Una operación de lectura con escrituras concurrentes puede retornar alguno de los valores recientemente escritos. En un caso de concurrencia similar al anterior, el _get_ de este tipo de registros devolvería solo 0 o 1. Se dice que estos registros proveen _consistencia por inactividad_ (_quiescent consistency_) porque aseguran que devolverán el mismo valor después de un período de inactividad entre el último _write_ y el siguiente _get_.

[[atomic_register]]
==== Registros atómicos
Los registros que devuelven el último valor escrito se denominan _registros atómicos_. Generalmente son registros de un único byte, una _palabra_, enteros de varios bytes, o referencias a memoria u objetos que cumplen las siguientes dos condiciones (<<Lamport2>>):

1. El método _get_ retorna el último valor escrito. Si una lectura retorna un valor y no hubo otra escritura intermedia, la siguiente lectura retornará el mismo valor.

2. Si hay varios _write_ concurrentes, _get_ retornará uno de los valores escritos. Si un _write_ concurrente es el número 1 y otro es 100, _get_ retornará 1 o 100.

[[RMW]]
=== Primitivas de hardware y registros _Read-Modify-Write_
Como observamos en el algoritmo de la panadería, el número de registros necesarios crece linealmente con el número de procesos concurrentes. Además, como las esperas activas recorren muchos registros introducen presión sobre zonas extensas de la caché. También obliga a la especificación manual y explícita de barreras de memoria para asegurar la consistencia secuencial. Las soluciones por software al problema de sincronización de procesos son ineficientes e inseguras.

Desde los inicios de la multiprogramaciónfootnote:[La capacidad del sistema operativo de tener varios procesos activos en memoria e intercalar su ejecución.] se diseñaron instrucciones atómicas que permitieron implementar algoritmos más seguros y eficientes. Estas primitivas pueden ser expresadas como abstracciones, denominadas genéricamente _registros Read-Modify-Write_ o _RMW_. Los registros _RMW_ pueden implementarse como construcciones de lenguajes o instrucciones de procesador, sus propiedades son similares.

[[consensus]]
[NOTE]
.Registros RMW no triviales
====
Los registros _RMW_ que proveen operaciones adicionales a la _función identidad_ (i.e. _get_) se denominan _no triviales_. <<Herlihy91, Maurice Herlihy>> demostró que los registros no triviales tienen un _consenso_ de al menos 2 (o son de _clase 2_). Las instrucciones de sincronización mencionadas (_get&add_, _TAS_, _swap_, _CAS_, etc.) implementan registros _RMW_ no triviales.

_CAS_ es la más potente de la lista. <<Herlihy91, Herlihy>> demostró que pertenece a la clase de _consenso N_ (o _infinito_). En palabras del autor (<<Herlihy12>>):

[quote, Maurice Herlihy]
_CAS_ es a la computación asíncrona el equivalente de las máquinas de Turing de la computación secuencial.

Afortunadamente, todos los procesadores implementan _CAS_ o una equivalente en capacidad de consenso: _load-linked/store-conditional_ (o _LL/SC_, disponible en las arquitecturas PowerPC, MIPS, Alpha y ARM).
====

Hay varios tipos de instrucciones que implementan registros _RMW_, las disponibles en la mayoría de procesadores son:

////
 - _get_: Retorna el valor del registro, se denomina también _función identidad_, por sí misma no tiene utilidad alguna pero es parte.
////
- _get&set_: Asigna un nuevo valor al registro y retorna el anterior (o la equivalente pero con orden invertido _set&get_).

- _get&add_: Incrementa el valor del registro en el valor indicado y retorna el valor anterior (o su equivalente _add&set_)footnote:[Algunos macros también ofrecen _get_and_sub_ o _sub_and_set_, idénticas a sumar un valor negativo.].

- _test&set_: Verifica el valor del registro, si es cero asigna el nuevo valor (habitualmente 1, por ejemplo en IBM 360 el registro es binario o booleano, solo admite 0 y 1).

- _swap_: Intercambia el valor de dos registros.

- _compare&swap_: Compara el valor del registro con otro, si son iguales asigna uno nuevo y retorna el anterior.


Los fabricantes implementan conjuntos de operaciones diferentes; para facilitar la programación y portabilidad los compiladores proveen macros, o _intrinsics_, más abstractos. Estos macros generan la secuencia de instrucciones nativas para cada arquitecturafootnote:[Por ejemplo GCC <<Atomics, tenía los macros>> `__sync_*`, pero en las últimas versiones fueron reemplazados por <<Atomics_C11, nuevos macros>> más cercanos al modelo de memoria de C11 y C++11.] así los desarrolladores no se deben preocupar de programar en ensamblador para cada arquitecturafootnote:[En el núcleo Linux no se usan macros, ya que lo haría dependiente del compilador y tampoco generan el código más eficiente. Se programa en ensamblador _empotrado_ para cada arquitectura.].


=== Exclusión mutua con registros _Read-Modify-Write_

Estudiaremos los algoritmos de exclusión mutua para _N_ procesos con instrucciones de hardware. La mayoría de los <<code_hardware, ejemplos>> están en lenguaje C, para evitar programar en ensamblador usé los macros atómicos de GCC (<<Atomics_C11>>). Cuando es posible, también están en Go con las primitivas atómicas del módulo +sync+.

Las instrucciones _LL/SC_ solo pueden ser programadas en ensamblador de algunas arquitecturas. Sus ejemplos están en ese lenguaje, solo funcionan en arquitecturas ARM (incluidas las Raspberry Pi).

Dejando de lado las limitaciones y restricciones prácticas de programar con instrucciones del procesador, es sorprendente la simplicidad de los algoritmos de exclusión mutua con estas primitivas. Sobre todo después de analizar los problemas de los algoritmos sin soporte del hardware.

[[get_and_set_alg]]
==== _Get&Set_
Se usa una variable global +mutex+ inicializada a cero que indica que no hay procesos en la sección crítica. En el preprotocolo se almacena 1 y se verifica si el valor anterior era 0 (es decir, no había ningún proceso en la sección crítica). Si es diferente a cero, esperará en un bucle hasta que lo sea.

La función +lock+ es la entrada a la sección crítica, +unlock+ la salida.

[source,python]
----
        mutex = 0

def lock():
    while getAndSet(mutex, 1) != 0:
        pass

def unlock():
    mutex = 0
----

El <<getAndSet, código en C>> está implementado con el macrofootnote:[De aquí en adelante, cuando se hace referencia a los macros atómicos de GCC se eliminará el prefijo `__atomic_` para evitar palabras tan largas que no se llevan bien con las pantallas pequeñas.] `exchange_n`. A pesar de su nombre no se trata de la instrucción _swap_, sino un equivalente de _get&set_.

==== _Get&Add_

Se puede implementar exclusión mutua con un algoritmo muy similar al de la panadería, cada proceso obtiene un número y espera por su turno. La obtención del _siguiente número_ es atómica, no se generan números repetidos. Así, no se necesita un array ni un bucle para controles adicionales. Este contraste muestra claramente las ventajas de disponer registros _RMW_.

Se requieren dos variables, +number+ para el siguiente número y +turn+ para indicar el turno de entrada.

[source,python]
----
        number = 0
        turn = 0

def lock():
    """ current is a local variable """
    current = getAndAdd(number, 1)
    while current != turn:
        pass

def unlock():
    getAndAdd(turn, 1)
----

[[get_and_add_ticket]]
El <<getAndAdd, código en C>> está implementado con el macro `fetch_add` y <<gocounter_get_and_add_go, en Go>> con +atomic.AddUint32+.footnote:[Estrictamente no es _get_and_add_ sino _add_and_get_, devuelve el valor después de sumar. Pero son equivalentes, solo hay que cambiar la inicialización de la variable +turn+.]

A diferencia de la implementación con _get&set_, esta asegura espera limitada: el número que selecciona cada proceso es único y crecientefootnote:[Aunque hay que tener en cuenta que el valor de +number+ llegará a su máximo y rotará.]. Los _spinlocks_ de este tipo son conocidos como <<ticket_lock, _ticket locks_>>. Son muy usados en el núcleo de Linux, aseguran espera limitada y equidad (_fairness_): los procesos entran a la sección crítica en orden FIFO.


==== _Test&Set_
La instrucción _test&set_ (_TAS_) fue la más usada hasta la década de 1970, cuando empezó a ser reemplazada por operaciones que permiten niveles de consenso más elevados. La implementación en hardware usa una variable entera binaria (o booleana) que puede tomar valores 0 y 1.

La instrucción solo tiene un operando. Si su valor es 0 le asigna 1 y retorna 0, caso contrario retorna 1 (es decir, retorna el valor anterior del registro).

[source,python]
----
def TAS(register):
    if register == 0:
        register = 1
        return 0

    return 1
----

La implementación de exclusión mutua con _TAS_:

[source,python]
----
        mutex = 0

def lock():
    while TAS(mutex) == 1:
        pass

def unlock():
    mutex = 0
----

<<testAndSet, El código en C>> está implementado con el macro +test_and_set+.


==== _Swap_
Esta instrucción intercambia atómicamente dos posiciones de memoria, usualmente palabras de 32 o 64 bits. Su algoritmo:

[source,python]
----
def swap(register1, register2):
    tmp = register1
    register1 = register2
    register2 = tmp
----

El algoritmo de exclusión mutua es casi idéntico al que usa _TAS_. La diferencia es que el valor anterior de +mutex+ se verifica en la variable local que se usó para el intercambio:

[source,python]
----
        mutex = 0

def lock():
    local = 1
    while local != 0:
        swap(mutex, local)

def unlock():
    mutex = 0
----

Para la <<counter_swap_c, implementación en C>> se usa el macro `exchange`. <<gocounter_swap_go, En Go>> se pueden usar las funciones atómicas del paquete +sync/atomic+, por ejemplo con +SwapInt32+ footnote:[Esta función no estaba disponible en Go para ARM hasta 2013, asegúrate de tener una versión moderna.].

[[em_cas]]
==== _Compare&Swap_

Esta instrucción se introdujo en 1973 para la arquitectura IBM 370/XAfootnote:[Inventada por Charlie Salisbury, se dice que se llamó inicialmente CAS por sus iniciales y posteriormente se cambió a _compare and swap_.] para solucionar las limitaciones de _test&set_ en operaciones complejas como actualización de colas (<<Gifford>>). Actualmente _CAS_ está disponible en la mayoría de arquitecturas CISC, incluida Intel/AMD. Provee el mayor _nivel de consenso_. La instrucción requiere tres operandos:

Registro (_register_):: La dirección de memoria cuyo valor se comparará y a la que se asignará un nuevo valor, si corresponde.

Valor esperado (_expected_):: Si el valor del registro es igual al esperado entonces se le asignará el nuevo valor. El macro de GCC incluye una operación adicional, si falla la comparación copia el valor del registro a la posición de memoria del _valor esperado_.

Nuevo valor (_desired_):: El valor que se asignará al registro si su valor era igual al esperado.


El algoritmo de la instrucción esfootnote:[GCC tiene dos macros para _CAS_, +compare_exchange_n+ y +compare_exchange+, ambos retornan un booleano si se pudo hacer el cambio. Se diferencian por la forma de un parámetro. En el primero el valor esperado se pasa por copia, en el segundo por referencia.]:

[source,python]
----
def CAS(register, expected, desired):
    if register == expected:
        register = desired
        return True
    else:
        expected = register
        return False
----


La implementación de exclusión mutua <<counter_compare_and_swap_c, en C>> es también sencilla, en el ejemplo se usa una variable local porque el macro de GCC requiere un puntero para el valor esperado. Si +mutex+ vale cero –no hay procesos en la sección crítica–, se le asigna uno y puede continuar. En caso de fallo –+mutex+ valía uno–, volverá a intentarlo en un bucle:

[source,python]
----
        mutex = 0

def lock():
    local = 0
    while not CAS(mutex, local, 1):
        local = 0

def unlock():
    mutex = 0
----

La instrucción +CompareAndSwapInt32+ <<gocounter_compare_and_swap_go, en Go>> es algo diferente, los argumentos del _valor esperado_ y el _nuevo_ no se pasan por referencia, sino por valor:

[source,go]
----
func lock() {
    for ! CompareAndSwapInt32(&mutex, 0, 1) {}
}
----

[[aba_problem]]
===== El _problema ABA_
_CAS_ tiene un defecto conocido y estudiado, el _problema ABA_. Aunque no se presenta en algoritmos sencillos como el de exclusión mutua, solo en casos de intercalados más complejos. Por ejemplo, dos procesos _P_ y _Q_ que modifican un registro con _CAS_:

- El proceso _P_ lee el valor _A_ y se interrumpe.
- _Q_ modifica el registro con el valor _B_ y vuelve a poner el mismo valor _A_ antes que _P_ vuelva a ejecutarse (de allí el nombre _ABA_).
- _P_ ejecutará la instrucción _CAS_ sin haber detectado el cambio.

Si _A_ y _B_ son valores simples no hay conflictos. Pero si son punteros a estructuras más complejas, como nodos de una pila, un campo de esas estructuras pudo haber cambiado y provocar errores.

[[free_lock_stack]]
====== Pilas concurrentes sin exclusión mutua

Veremos un caso práctico de implementación de _pilas concurrentes sin exclusión mutua_ (_free-lock stacks_) con _CAS_.


[NOTE]
.Estructuras _lock-free_
====
Una estructura de datos compartida es _sin exclusión mutua_ (o _lock-free_) si sus operaciones no requieren exclusión mutua.

Existe interés académico por estos mecanismos porque permiten paralelizar las operaciones sobre estructuras esenciales: _hashes_, colas, árboles balanceados, etc. No son problemas sencillos debido a las limitaciones de las primitivas de hardware para manipular registros de tamaño superior a una palabra, lo que obliga a diseñar algoritmos complejos para componer operaciones atómicas. Por ejemplo, todavía se estudia la solución eficiente a una cola _lock-free_ que permita agregar o quitar elementos por ambos extremos.

A continuación implementamos una pila sin exclusión mutua, en el capítulo siguiente veremos colas sin exclusión mutua necesarias para los algoritmos de _spinlocks_ <<mcs_queue, _MCS_>> y <<clh_queue, _CLH_>>.
====

La pila es una lista encadenada de nodos del tipo +node+ y tiene dos operaciones: _pop_ y _push_. La estructura +node+ contiene un puntero al siguiente elemento (+next+) y una estructurafootnote:[En el código simplificado no se muestra cada +struct+, en el código se pudo haber usado +typedef+, pero preferí no agregar más _capas_ que las estrictamente necesarias.] que almacena los datos (o _payload_, su estructura interna nos es irrelevante):

[[struct_node]]
[source, c]
----
struct node {
    struct node *next;
    struct node_data data;
};
----

Las funciones +push+ y +pop+ añaden y eliminan elementos de la pila respectivamente. Los argumentos de +push+ son el puntero a la cabecera de la pila y al nodo a añadir. El argumento de +pop+ es el puntero a la cabeza de la pila; retorna el puntero al primer elemento de la pila, o +NULL+ si está vacía.

A continuación el código en C simplificado de ambas funciones.

._push_
[source, c]
----
void push(node **head, node *e) {
    e->next = *head;                <1>
    while(!CAS(head, &e->next, &e));<2>
}
----
<1> El nodo siguiente al nodo a insertar será el apuntado por la cabecera.
<2> Si la cabecera no fue modificada, se hará el cambio y apuntará al nuevo nodo +e+. Si +head+ fue modificada, su nuevo valor se copia a +e->next+ (apuntará al elemento nuevo que apuntaba +head+) y se volverá a intentar. Cuando se haya podido hacer el _swap_ +head+ apuntará correctamente a +e+ y +e->next+ al elemento que estaba antes.

._pop_
[source, c]
----
node *pop(node **head) {
    node *result, *orig;

    orig = *head;
    do {
        if (! orig) {
            return NULL;              <1>
        }
    } while(!CAS(head, &orig, &orig->next));<2>

    return orig;
}
----
<1> Si es +NULL+ la pila está vacía y retorna el mismo valor.
<2> Si la cabecera apuntaba a un nodo y no fue modificada, se hará el cambio y la cabecera apuntará al siguiente nodo. Si fue modificada, se hace una copia del último valor a +orig+ y se volverá a intentar.


Este algoritmo es correcto para gestionar una pila concurrente, pero solo si es imposible eliminar un nodo e inmediatamente insertar otro con la misma dirección de memoria. Con _CAS_ no se puede detectar si ocurrió una inserción de este tipo, es el problema ABA.

Supongamos una pila con tres nodos que comienzan en las direcciones 10, 20 y 30:

[quote]
--
+head => [10] => [20] => [30]+
--

El proceso _P_ acaba de ejecutar +orig = *head+ dentro de _pop_ y es interrumpido, su variable +orig+ quedó apuntando a la dirección 10. Otros procesos eliminan dos elementos de la pila:

[quote]
--
+head => [30]+
--

Ahora _Q_ inserta un nuevo nodo con una dirección de memoria usada previamente, la 10:

[quote]
--
+head => [10] => [30]+
--


Cuando _P_ continúe su ejecución _CAS_ hará el cambio, la dirección de +head+ es igual que la de +orig+, 10. Pero la copia de +orig+ en _P_ es de un nodo antiguo, dejará la cabecera apuntando a un nodo que ya no existe. Los siguientes nodos habrán quedado _descolgados_ e inaccesibles:

[quote]
--
+head => ¿20?    [30]+
--

====== ABA con malloc
El _reciclado_ de direcciones es habitual si se usa +malloc+ y +free+ al insertar y eliminar nodosfootnote:[Las implementaciones de +malloc+ suelen volver a usar las direcciones de los elementos que acaban de ser liberados.]. [[stack_cas_malloc]]Podemos comprobarlo, el siguiente <<stack_cas_malloc_c, programa en C>> usa estas funciones en cuatro hilos diferentes. Cada uno de ellos ejecuta repetidamente el siguiente código:

[source, c]
----
e = malloc(sizeof(node));
e->data.tid = tid;
e->data.c = i;
push(&head, e);           <1>
e = pop(&head);           <2>
if (e) {
    e->next = NULL;       <3>
    free(e);
} else {
    puts("Error, empty"); <4>
}
----
<1> Se añade el elemento nuevo a la pila, su memoria fue obtenida con +malloc+.
<2> Inmediatamente se elimina de la lista. El resultado nunca debería ser +NULL+: todos los hilos primero agregan y luego quitan.
<3> Antes de liberar la memoria del elemento recién eliminado se pone +next+ en +NULL+. No debería hacer falta, pero lo hacemos por seguridad y observar que los errores son ocasionados por el problema ABA.
<4> Si no pudo obtener un elemento de la lista, se imprime el error.

En todas las ejecuciones se generan errores de pila vacía, o liberación duplicada del mismo fragmento de memoria:

----
Error, stack empty
*** Error in `./stack_cas_malloc': free(): invalid pointer: 0x00007fcc700008b0 ***
Aborted (core dumped)
----

En sistemas con un único procesador quizás se necesiten varias ejecuciones, o aumentar el número de operaciones en la constante +OPERATIONS+, para que el error se manifieste. Es uno de los problemas inherentes de la programación concurrente, a menudo la probabilidad de que ocurra el error es muy baja. Es muy difícil detectar el _bug_ si se desconoce el problema _ABA_.

====== ABA con doble pila
Algunas implementaciones de +malloc+ no retornan las direcciones usadas recientemente por lo que quizás no se observe el error de doble liberación. Para forzar el reuso de direcciones recientes –y así probar el problema _ABA_–, se puede usar una segunda pila como _caché_ de los nodos eliminados de la primera.

[[cas_double_stack]] No se libera la memoria de los nodos con +free+, sino que se insertan en una segunda pila de _caché_ de libres, +free_nodes+. En lugar de solicitar memoria cada vez, se reciclan los nodos de la pila de libres.

<<stack_cas_freelist_c, El programa>> ejecutará repetidamente el siguiente código:


[source, c]
----
e = pop(&free_nodes);     <1>
if (! e) {
    e = malloc(sizeof(node)); <2>
    puts("malloc");
}
e->data.tid = tid;
e->data.c = i;
push(&head, e);           <3>
e = pop(&head);           <4>
if (e) {
    push(&free_nodes, e); <5>
} else {
    puts("Error, empty"); <6>
}
----
<1> Obtiene un nodo de la pila de libres.
<2> La pila de libres estaba vacía, se solicita memoria. Debería haber, como máximo, tantos +malloc+ como hilos.
<3> Se agrega el elemento a la pila de +head+.
<4> Se elimina un elemento de la pila de +head+.
<5> Si se pudo extraer el elemento, se agrega a la pila de libres.
<6> La pila estaba vacía, es un error.

La ejecución del programa dará numerosos errores de _pila vacía_, se harán también más +malloc+ de los que deberían. Ambos son consecuencia del problema ABA.

----
0 malloc
Error in 2 it shouldn't be empty
Error in 2 it shouldn't be empty
Error in 0 it shouldn't be empty
0 malloc
Error in 3 it shouldn't be empty
----


[[stack_cas_tagged]]
===== Compare&Swap etiquetado
Una solución para el problema ABA es usar bits adicionales para _etiquetar_ una _transacción_ (_tagged CAS_). Se requiere que _CAS_ compare e intercambie registros que incluyan el _valor esperado_ y la etiqueta. Es decir, que opere con registros mayores al tamaño de palabra de la arquitecturafootnote:[Se usa _CAS_ principalmente con punteros del mismo tamaño que el de palabra de la arquitectura.].

Algunos fabricantes introdujeron instrucciones _CAS_ que permiten la verificación e intercambio de registros de mayor tamaño que una palabra. Las instrucciones +cmpxchg8b+ y +cmpxchg16b+ de Intel operan con áreas de 64 y 128 bits, en lugar de solo 32 o 64 respectivamente. Se pueden usar esos bits adicionales para la _etiqueta_.

Para la manipulación de pilas se requiere un campo adicional en las cabeceras. Se define la estructura +node_head+ compuesta por el puntero al nodo (+node+) y un entero que será la etiqueta (+aba+). En cada intercambio se incrementa el valor anterior de +aba+, así es como se identifica cada _transacción_.

[source, c]
----
struct node_head {
    struct node *node;       <1>
    uintptr_t aba;           <2>
};

struct node_head stack_head; <3>
struct node_head free_nodes;
----
<1> El puntero al nodo que contiene los datos.
<2> Será usada como etiqueta, un contador que se incrementará en cada _transacción_. Es un entero del mismo tamaño que los punteros (32 o 64 bits según la arquitectura).
<3> Los punteros a las pilas no serán un simple puntero, sino la estructura con el puntero y la etiqueta.

Del <<stack_cas_tagged_c, código completo en C>> analicemos en detalle el funcionamiento de +push+:

[source, c]
----
void push(node_head *head, node *e) {
    node_head orig, next;

    __atomic_load(head, &orig);  <1>
    do {
        next.aba = orig.aba + 1; <2>
        next.node = e;
        e->next = orig.node;     <3>
    } while (!CAS(head, &orig, &next); <4>
}
----
<1> Al tratarse de una estructura que no es un _registro atómico_, se debe asegurar la copia atómica de +head+ a +orig+.
<2> +next+ tendrá los datos de +head+ después del _CAS_, en este se incrementa el valor de +aba+ para indicar una nueva transacción.
<3> El siguiente del nuevo nodo es el que está ahora en la cabeza.
<4> Se intenta el intercambio, solo se hará si tanto el puntero al nodo y el entero +aba+ son idénticos a los copiados en +orig+. Si entre la primera instrucción y la comparación en el +while+ el valor de +head+ fue modificado, el valor de +aba+ también habrá cambiado (será mayor), por lo que _CAS_ retornará falso aunque el puntero al nodo sea el mismo.

[[llsc]]
==== Load-Link/Store-Conditional (_LL/SC_)

_CAS_ es la más potente de las operaciones atómicas anteriores, permite el consenso con infinitos procesos (_consenso de clase N_). Los fabricantes de arquitecturas RISCfootnote:[PowerPC, Alpha, MIPS y ARM.] diseñaron una técnica diferente para implementar registros _RMW_ que es tan potente que puede emular a cualquiera de las anteriores: las instrucciones _LL/SC_. De hecho, al compilar los programas de ejemplo en algunas de esas arquitecturas –por ejemplo, en Raspberry Pi–, el compilador reemplaza los macros por una serie de instrucciones con _LL/SC_.

El diseño de _LL/SC_ se basa en dos operacionesfootnote:[+lwarx+/+stwc+ en PowerPC, +ll+/+sc+ en MIPS, +ldrex+/+strex+ en ARM.] que trabajan en cooperación con el sistema de coherencia de caché. Una es similar a la tradicional cargar (_load_) una dirección de memoria; la otra a la de almacenar (_store_) en una posición de memoria. La diferencia es que ambas están _enlazadas_, la ejecución de la segunda (_SC_) es condicional: almacena el valor solo si la dirección de memoria no fue modificada desde la ejecución de la primera (_LL_).

===== _LL/SC_ en ARM

Las instrucciones _LL/SC_ en ARM, +ldrex+ y +strex+, funcionan de la siguiente manera:

+ldrex+:: Carga una dirección de memoria en un registro y _etiqueta_ esa dirección como de _acceso exclusivo_. No hay limitaciones en el número de instrucciones hasta el correspondiente +strex+.

+strex+:: Almacena el valor de un registro en una dirección de memoria, pero solo si esa dirección ha sido _reservada_ anteriormente con un +ldrex+ y no fue modificada por otro proceso.

Las siguientes instrucciones cargan una dirección (indicada por +r0+) en el registro +r1+, hacen algunas operaciones y almacenan el resultado en la misma dirección. Si la dirección indicada por +r0+ cambió desde la ejecución de +ldrex+ dará un fallo (indicado por el valor del registro +r2+).

----
ldrex   r1, [r0]     <1>
...
strex   r2, r1, [r0] <2>
----
<1> Carga el contenido de la dirección indicada por +r0+ en el registro +r1+ y _etiqueta_ esa dirección como exclusivafootnote:[En ARM se etiqueta en el sistema del _monitor de acceso exclusivo_, en otras arquitecturas se asocia un bit del _TLB_ o de memoria caché.].
<2> Almacena el valor del registro +r1+ en la dirección apuntada por +r0+ si y solo si esa dirección no fue modificada por otro proceso. Si almacenó el valor pone +r2+ en 0, caso contrario en 1.

Vale la pena analizar cómo se emulan otras instrucciones atómicas con _LL/SC_, por ejemplo _get&add_ y _CAS_:

.Emulación de _get&add_
----
.L1:
    ldrex   r1, [r0]     <1>
    add     r1, r1, #1   <2>
    strex   r2, r1, [r0] <3>
    cmp     r2, #0
    bne     .L1          <4>
----
<1> Carga la dirección especificada por +r0+ en +r1+.
<2> Incrementa en 1.
<3> Almacena _condicionalmente_ la suma.
<4> Si falló vuelve a intentarlo cargando el nuevo valor.


[[CAS_assembly]]
.Emulación de _CAS_
----
    ldr     r0, [r2]     <1>
.L1
    ldrex   r1, [r3]     <2>
    cmp     r1, r0
    bne     .L2          <3>
    strex   lr, ip, [r3] <4>
    cmp     lr, #0
    bne     .L1          <5>
.L2
    ...
----
<1> Carga el contenido del valor esperado en +r0+.
<2> Carga el contenido del _registro_ en +r1+.
<3> El resultado de la comparación es falso, sale del _CAS_.
<4> Intenta almacenar el nuevo valor en la dirección indicada por +r3+ (es decir, hace el _swap_).
<5> Si no se pudo almacenar vuelve a intentarlo.


===== _LL/SC_ y ABA
Las instrucciones _LL/SC_ tienen algunos problemas que afectan al _avance_. El resultado del _store condicional_ puede retornar erroresfootnote:[No implica que falle el algoritmo implementado, solo que se itere otra vez.] _espurios_ por:

- cambio de contexto del proceso;
- emisiones _broadcast_ en el bus de caché;
- actualizaciones en la misma línea de caché;
- otras operaciones de lectura o escritura entre el _LL_ y el _SC_.

La recomendación general es que el fragmento de código dentro de una sección exclusiva sea breve y que se minimicen las escrituras a memoria.

La principal ventaja de las instrucciones _LL/SC_ es que no sufren el problema ABA: el primer cambio -de _A_ a _B_- ya invalidará el _store_ condicional posterior. Cuando analizamos el problema ABA vimos cómo se puede reproducir el problema con un <<cas_double_stack, par de colas>> que intercambian sus nodos. El programa usa el macro atómico para _CAS_, cuando se compila para ARM se emula esa operación, también con sus problemas. Así, a pesar de que en ARM se traduce a operaciones _LL/SC_, también provoca los mismos errores:

----
*** Error in `./stack_cas_malloc': double free or corruption (fasttop): 0x75300468 ***
Aborted
----

En una arquitectura con _LL/SC_ hay que implementar el algoritmo directamente con esas instrucciones, pero no hay macros adecuados en GCC. Hay que programar en ensamblador.


[[llsc_code]]
===== _LL/SC_ en ensamblador nativo
Veremos la implementación correcta con _LL/SC_ del programa con <<cas_double_stack, dos pilas _concurrentes_>> que sufría el problema ABA. Las operaciones _pop_ y _push_ se implementan esta vez en ensamblador, el código tendrá dos partes:

1. El <<stack_llsc_freelist_c, módulo en C>> es similar al código de _CAS_ con doble pila, pero sin la implementación de las funciones +pop+ y +push+.

2. Las funciones +pop+ y +push+ están implementadas <<stack_llsc_freelist_s, en ensamblador>> de ARM.

El código en ensamblador es sencillo y breve, solo 32 líneas en total, pero analicemos en detalle la función +pop+:

._pop_
----
pop:
    push    {ip, lr}
1:
    ldrex   r1, [r0]     <1>
    cmp     r1, #0
    beq     2f           <2>
    ldr     r2, [r1]     <3>
    strex   ip, r2, [r0] <4>
    cmp     ip, #0
    bne     1b           <5>
2:
    mov     r0, r1       <6>
    pop     {ip, pc}
----
<1> Carga _LL_ del primer argumento de la función (+head+), la dirección del primer elemento de la lista punterofootnote:[Recordad que el primer argumento es la _dirección_ del puntero, es decir un _puntero a puntero_.].
<2> En la línea anterior se compara si es igual a cero. Si es así la cola está vacía, sale del bucle y retorna +NULL+.
<3> Carga en +r2+ el puntero del siguiente elementofootnote:[Dado que +next+ es el primer campo, su dirección coincide con la del nodo, por eso no hay _desplazamiento_ en el código ensamblador cuando lee o modifica +next+.] de la lista, la dirección de +e->next+ de <<struct_node, la estructura del nodo>>.
<4> Almacena el siguiente elemento en +head+.
<5> Copia el contenido de +r1+ a +r0+, es el puntero devuelto por la función.

Si se conocen las características y posibilidades de _LL/SC_, no es difícil simular las otras operaciones atómicas. No obstante, es más sencillo implementar el algoritmo directamente con _LL/SC_. Pero, salvo los compiladores de fabricantes, no existen macros para estas operaciones. Probablemente porque es muy complicado simular _LL/SC_ en arquitecturas que no las tienen.

////

No queda más remedio que programarlas en ensamblador, pero se puede evitar el problema ABA y al mismo tiempo ganar en eficiencia.


Los siguientes son los tiempos de ejecución de los algoritmos de pilas concurrentes en Raspberry Pi 1 y 2.

[[free_lock_stack_times]]
.Tiempos de ejecución de pila concurrente en Raspberry Pi
[caption=""]
image::free_lock_stacks.png[align="center"]


Con un único núcleo del ARMv6 la implementación con _LL/SC nativo_ es más de dos veces más rápido que el siguiente, que sufre del problema ABA –por lo tanto, incorrecto–; y más de cuatro veces más rápido que la simulación de _CAS etiquetado_. En el más moderno ARMv7 con varios núcleos, el _CAS con malloc_ simulado es el más rápido, pero erróneo. La implementación en ensamblador con LL/SC es la siguiente más rápida, aunque las diferencias con el _CAS etiquetado_ implementado en C con los macros GCC no es tan notable.
////

=== Recapitulación

En este capítulo hemos visto las instrucciones por hardware esenciales para construir _spinlock_ eficientes. Analizamos varias de ellas, desde las más básicas hasta las más potentes: _CAS_ y _LL/SC_. Además de la exclusión mutua vimos el uso de las primitivas _RMW_ para resolver problemas más sofisticados, como las pilas concurrentes sin bloqueo. También estudiamos el problema ABA y su solución, _CAS etiquetado_.

No hay instrucciones de hardware unificadas para todas las arquitecturas, ni tampoco una estandarización a nivel de lenguajes de programación. Esa es la razón por la que los compiladores implementan sus propios _macros atómicos_ que traducen o emulan los registros _RMW_ representados por el macro.

Simular las instrucciones _LL/SC_ con _CAS_ o _TAS_ es más complicado –si no imposible– por lo que GCC no incluye macros para emularlas. Tuvimos que recurrir a ensamblador para poder usarlas en procesadores ARM.

Los _spinlocks_ basados en instrucciones por hardware son fundamentales, se requieren algoritmos más eficientes y construcciones más sofisticadas, como lectores-escritores. Son los temas del siguiente capítulo.

[NOTE]
.Por las dudas
====
En todos los ejemplos de exclusión mutua la sección crítica consistía solo en incrementar un contador compartido. Es perfecto para mostrar que una operación aritmética tan simple también sufre los problemas de concurrencia. No obstante, espero que os hayáis dado cuenta que no hace falta recurrir a un _spinlock_ para incrementar una variable compartida. Se puede hacer de forma directa y óptima con _get&add_ o _add&get_.

Por ejemplo en C:

[source, c]
----
for (i=0; i < max; i++) {
    c = add_fetch(&counter, 1, __ATOMIC_RELAXED);
}
----

O en Go:

[source, go]
----
for i := 0; i < max; i++ {
    c = atomic.AddInt32(&counter, 1)
}
----
====
