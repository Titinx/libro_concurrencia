[[spinlocks]]
== _Spinlocks_ avanzados
Las soluciones de exclusión mutua anteriores tienen en común una espera activa que continuamente verifica el estado de un registro _RMW_ hasta que el proceso puede entrar a la sección crítica. Estos algoritmos se denominan _spinlocks_, el de Dekker, Peterson, la panadería o cualquiera de las soluciones de exclusión mutua del capítulo anterior son también _spinlocks_.

Su uso tiene sentido si se cumple una de las siguientes condiciones:

. El código en la sección crítica es muy breve y la competencia es relativamente baja. Los _spinlocks_ se emplean desde los inicios de los sistemas operativos en rutinas críticas -como gestores de interrupciones- y otros mecanismos de sincronización de más alto nivel y sin esperas activas (los que veremos a partir del siguiente capítulo).

. Los procesos se ejecutan en paralelo en diferentes procesadores, mientras unos procesos están en sus _spinlocks_ otros pueden avanzar y salir de la sección crítica. Los _spinlocks_ permiten evitar mayores pérdidas de tiempo ocasionadas por llamadas de sistema o cambios de estado de procesos. Pero si hay más procesos compitiendo en _spinlocks_ que CPUs se llega a una situación similar a la de un único procesador, los procesos avanzarán muy lentamente. En estos casos quizás tiene más sentido utilizar construcciones sin esperas activas.

El problema principal es la ineficiencia provocada por la espera activa y los requerimientos de almacenamiento en las soluciones algorítmicas sin registros <<RMW, _RMW_>>. Por ello se desarrollaron las primitivas de hardware que permiten minimizar el impacto y sobre todo eliminar la necesidad de recorrer múltiples registros. Estas primitivas suponen una gran mejora en el espacio necesario -requieren solo una palabra por cada sección crítica (o _lock_)- como de facilidades de programación.

Pero no todos los procesadores ofrecen las mismas instrucciones, para obtener el máximo de eficiencia hay que programar para cada arquitectura (como es habitual en el núcleo de los sistemas operativos). Para facilitar la portabilidad los compiladores incluyen primitivas fundamentales, macros o _intrinsics_, que son traducidas a las operaciones que implementan o simulan esas primitivas y que son las que usé para los programas de ejemplofootnote:[Salvo el código en ensamblador con +ldrex/strex+ para ARM.].


Analizaremos el comportamiento de cada uno de estos _spinlocks_ y las técnicas más usadas para optimizarlos. En la siguiente figura se muestran los tiempos de CPU en segundos de la ejecución de los algoritmos del capítulo anterior ejecutados sobre diferentes procesadores: Intel Core2 con 4 núcleos, Intel i5 con 2 núcleos y cuatro _hilos_, Intel Xeon con 2 procesadores independientes de 8 núcleos cada uno (16 en total) y Raspberry 2 con ARMv7 de 4 núcleos.


****
Dado que el interés de este capítulo es analizar la eficiencia relativa de diferemtes algoritmos recurro a gráficas para poder compararlos y contrastarlos visualmente. Aunque tanta información puede resultar molesta, creo que es importante romper con una costumbre de los libros de textos más habituales: se hacen afirmaciones rotundas pero sin presentar las mediciones ni el contexto en que fueron tomadas.

Quizás tenían sentido el momento que se diseñaron esos algoritmos -o se escribió la primera edición de los libros- pero los sistemas de multiprocesadores han evolucionado mucho, algunos algoritmos que presentaban ventajas hace décadas hoy casi no la tienen. Durante este capítulo veréis que hay algoritmos que fueron diseñados para comportarse mejor que otros, y quizás lo hacían con la arquitectura de su época, pero hoy esas diferencias no existen o no son tan relevantes.
****


Cada grupo es una medición diferente. El primero (_none_) es el tiempo sin ningún mecanismo de exclusión mutua. El segundo muestra los tiempos del algoritmo de la panaderia, el tercero (_ultimate_) es el más eficiente, incrementar directamente la variable entera +counter+ usando la instrucción atómica _get&add_. Los siguientes hacia la derecha son los algoritmos con instrucciones de hardware del capítulo anterior _swap_, _get&add_, _test&set_, _get&set_ y _compare&swap_ respectivamente.


[[hardware_times]]
.Tiempos de ejecución para los diferentes macros e instrucciones de hardware
[caption=""]
image::times-hardware.png[align="center"]

Todos los algoritmos de exclusión mutua imponen un sobrecoste importantefootnote:[Como era de esperar, el algoritmo de la panadería es el menos eficiente.] que no es uniforme para los diferentes procesadores. En Intel Core2 e i5 la operación más eficiente es _get&add_. En el Xeon de 16 núcleos es _get&set_ (seguido muy de cerca por _TAS_), y en Raspberry 2 es casi un empate entre _CAS_ y _get&add_. Puede observarse también que con _CAS_ el procesador ARM tiene resultados mejores que los más potentes procesadores Intel. Inesperado dado que Intel tiene _CAS_ nativo (+cmpxhg+) pero en ARM se emula con _LL/SC_.footnote:[También muestra las buenas propiedades de LL/SC.]

=== Optimizaciones
Las implementaciones anteriores son ineficientes por dos razones:

Uso y competencia por el procesador:: Los procesos consumen el 100% CPU verificando el valor de una variable, si hay más hilos compitiendo que procesadores la mayor parte del tiempo se pierde en el bucle de verificación.

La presión sobre la memoria caché:: Estos algoritmos no son _escalables_. En sistemas con varios procesadores todos los procesos verifican el estado de la misma variable (_hot spot_) por lo que se generan mensajes extras de sincronización de caché.

Aunque son preferibles los _spinlocks_ escalables veremos técnicas básicas para mejorar el rendimiento de los anteriores. Al final del capítulo estudiaremos los dos algoritmos escalables más importantes.


._Spinlocks_ escalables
****
Se denominan _spinlocks escalables_ aquellos en que los _fallosfootnote:[No implica que haya producido un error en el sistema sino que el procesador no tiene una copia actualizada en su memoria caché por lo que se deben producir intercambios de mensajes para actualizarla al último valor.] de memoria caché_ se mantienen constantes independientemente de las iteraciones necesarias en la entrada a la sección crítica (<<MCS1>>, <<Boyd-Wickizer>>).

Si en cada iteración (o _spin_) los procesos en diferentes procesadores verifican las mismas variables se produce como mínimo un _fallo de caché_ cada vez que un proceso cambia su valor, la actualización debe propagarse a las caché locales de los otros procesadores. El problema se agrava por el <<false_sharing, _false sharing_>>, los datos que se modifican en la sección crítica suelen estar en áreas cercanas a las variables de los _spinlocks_, cada modificación de esas variables supone un coste adicional de sincronización. Por ello se estudiaron y desarrollaron los <<scalable_spinlocks, _spinlocks escalables_>>.
****

Las tres técnicas de optimización que veremos a continuación no son _escalables_ pero las mejoras en eficiencia pueden ser considerables.

==== Verificación local
Se trata de reducir la presión sobre el sistema de coherencia de caché y evitar la llamada a la instrucción atómica. Antes de llamarla se verifica (_cortocircuito_) el valor de la variable sobre la que se itera -+mutex+ en los ejemplos-, si vale 1 ya no se continúa con la instrucción atómicafootnote:[Cuando se usa con _TAS_ a esta estrategia se la conoce como _TAS_ o _TATAS_.].


----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        pass
----

Las mejoras dependen de la instrucción atómica y de los mecanismos de coherencia de caché. En los <<execution_times, tiempos de ejecución>> se observa que la mejora es notable en procesadores Intel pero casi despreciable en la arquitectura ARM, tanto en tiempos de CPU como en tiempos de retorno.

Código fuente para <<test_test_and_set_c, _TAS_>>, <<test_swap_c, _swap_>> y <<test_compare_and_swap_c, _CAS_>>.

==== Ceder el procesador
Si un proceso debe continuar en la espera activa porque no se cumple la condición de salida se _ab&ona_ el procesador. Se puede usar la llamada de sistema estándar +sched_yield+ que hace que el sistema operativo quite al proceso de ejecución y lo mueva a la cola de _listos_.

[source, python]
----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        sched_yield()
----

Como puede observarse en <<execution_times, los gráficos>> la cesión del procesador produce reducciones de tiempos en todas las arquitecturas (código fuente para <<test_and_set_yield_c, _TAS_>>, <<swap_yield_c, _swap_>> y <<compare_and_swap_yield_c, _CAS_>>).

[[exponential_backoff]]
==== Espera exponencial
La forma de reducir la competencia (_contention_) y evitar el efecto ping-pong de los procesos pasando de _listos_ a _ejecución_ es bloquearlos por un tiempo variable dependiendo de las veces que ha _fallado_ la condición durante la espera activa.



._Exponential backoff_
****
_Exponential backoff_ es la técnica usada por redes Ethernet, WiFi y similares de bus compartido para calcular el tiempo de espera para reenviar una trama después de una colisión, _backoff_ se refiere a la espera y _exponential_ a que el límite del tiempo de espera se duplica en cada _fallo_. El tiempo efectivo de espera de cada proceso es un número aleatorio entre 1 y el límitefootnote:[Se usa un número aleatorio para evitar que todos los procesos reintenten simultáneamente.].

El siguiente es el código en C usado en los ejemplos para forzar la espera con tiempos que se duplican dependiendo del valor del argumento +failures+:

[source, c]
----
#define FAILURES_LIMIT 12
void backoff(int failures) {
    struct timespec deadline = {.tv_sec = 0};
    unsigned limit;

    if (failures > FAILURES_LIMIT) {
        limit = 1 << FAILURES_LIMIT;
    } else {
        limit = 1 << failures;
    }

    deadline.tv_nsec = 1 + rand() % limit;
    clock_nanosleep(CLOCK_REALTIME, 0, &deadline, NULL);
}
----

En cada iteración fallida del _spinlock_ el proceso incrementa el contador de fallos (+failures+) y llama a la función _backoff_. Ésta calcula el límite (+limit+) con desplazamiento de bits. Cada posición desplazada multiplica por dos desplazando el bit 1 hacia la izquierda con un máximo de 12 posiciones, unos 4096 nanosegundos. Luego se calcula el tiempo que esperará con un número aleatorio entre 1 y el límite.

****


[source, c]
----
        mutex = 0

def lock():
    failures = 0

    while mutex or TAS(mutex):
        failures += 1
        backoff(failures)
----

El problema con el _backoff_ es la elección de la unidad de tiempo y el límite de espera, los valores adecuados dependen de cada arquitectura y caso de uso. Si la espera es muy breve producirá un efecto similar al +sched_yield+ con una sobrecarga aún mayor del sistema operativofootnote:[El proceso pasa de ejecución a _bloqueado_ luego a _listo_ y nuevamente a ejecución en un tiempo muy breve.]. Por el contrario, si la unidad es muy grande producirá demoras innecesarias y con CPUs inactivas porque todos los procesos están _bloqueados_.

Sin embargo la mejora del _backoff_ es general para todos los procesadores probados, también para los tiempos de retornofootnote:[Me sorprendió, no esperaba que mejore al _yield_, y menos por el sobrecoste de lo cálculos de _backoff_ más la transición breve por el estado _bloqueado_.] con respecto a +sched_yield+ (en los procesadores Intel la diferencia es importante, en ARM es mínima).

Código fuente para <<test_and_set_backoff_c, _TAS_>>, <<swap_backoff_c, _swap_>> y <<compare_and_swap_backoff_c, _CAS_>>.

[[execution_times]]
==== Tiempos de ejecución
A continuación cuatro gráficas que representan los tiempos de CPU de los diferentes algoritmos en cuatro procesadores distintos. Cabe recordar que el ejemplo que usamos -hilos que solo incrementan un contador compartido- son muy extremos. Aunque la sección crítica es muy breve lo único que hacen es entrar y salir continuamente sin ejecutar código fuera de ella, lo que implica que la competencia es extremadamente elevada y muy lejos de ser un caso práctico. Solo sirve para tener una base de comparación entre diferentes procesadores y arquitecturas.

También hay que tener en cuenta que los ejemplos están programados en _C portable_ usando los macros atómicos de GCC. Éste no siempre genera el código más eficiente para las diferentes arquitecturas, por ejemplo en ARM los macros de barreras de memoria siempre generan una barrera completa (+dmb sy+) aunque se especifique que solo se desea una barrera _release_. La solución es programar en ensamblador de la arquitectura, como se hace en el núcleo de los sistemas operativos, pero habría sido más costoso y dificultado la transmisión de las ideas fundamentalesfootnote:[Y hasta a las pruebas que podéis hacer vosotros mismos.].

.Intel Core2 cuatro núcleos
image::optimized-intel-quad.png[align="center"]

.Intel i5 dos núcleos con extensión SMP
image::optimized-intel.png[align="center"]

.Intel Xeon 16 núcleos
image::optimized-xeon.png[align="center"]

.ARMv7 Raspberry 2 cuatro núcleos
image::optimized-arm7.png[align="center"]


De los tiempos de las gráficos hay algunos aspectos interesantes que vale la pena destacar:

- La mayor eficiencia del Intel i5 sobre el Core2 a pesar de que el segundo tiene más núcleos _reales_ se debe a que el _Front Side Buffer_ del Intel Core2 usa bus compartido para los mensajes del protocolo de coherencia de caché mientras que el i5 tiene el nuevo sistema <<quickpath, _QuickPath Interconnect_>>.

- El Xeon con 16 núcleos tiene peores tiempos que los menos potentes Core2 e i5. La diferencia es que tiene dos microprocesadores diferentes, el coste de sincronización de caché es superior a los chips únicos con varios _cores_.

- El buen comportamiento y uniformidad de ARM para todas las instrucciones, sobre todo porque se emulan con el _LL/SC_. En ambas versiones del procesador, v6 y v7 (de Raspberry 1 y 2 respectivamente) el _compare&swap_ es la más eficiente.

- En las plataformas con varios procesadores +sched_yield+ y el +backoff+ producen reducciones de tiempos importantes, incluso cuando el número de procesos concurrentes (cuatro) es igual al número de procesadores (en el Intel Quad y en ARMv7 de Raspberry 2). La mejora no se debe a la reducción de uso de la CPU sino a la menor presión sobre el sistema de coherencia de cachéfootnote:[Puedes hacer la prueba, en la versión de _backoff_ reemplaza el +clock_nanosleep+ por un bucle como +for (i = 0; i < limit; i++);+ y verás que se produce la misma reducción -incluso mayor-, simplemente por no acceder a las variables compartidas continuamente.], la causa principal por la que se estudiaron _spinlocks_ escalables.

===== Tiempos de CPU vs tiempos de reloj

En los análisis anteriores usamos tiempos de CPU y no el _tiempo de retorno_: el tiempo de _reloj_ total desde que se arrancan los hilos hasta que finalizan todos. ¿Cuál es más representativo o útil? Es una duda razonable. El tiempo de CPU es útil para conocer efectivamente cuánta CPU necesitan para la ejecuciónfootnote:[Es una medida importante, por ejemplo para reducir el consumo de batería en móviles.], pero no da suficiente información sobre _cuánto tarda_ la ejecución. Por ejemplo, con más procesadores se consumen más ciclos de reloj aunque el tiempo de retorno se haya reducido (de hecho es lo que ocurre).

Cuando se analiza la diferencia entre usar o no +sched_yield+ y _backoff_ la duda es aún mayor. Sabemos que lo más probable es que el consumo de ciclos de CPU se reduzcan en la espera activa, pero también que aumentará el sobrecoste del sistema operativo por los cambios de contexto de los procesos. Sin tener los datos de tiempos de retorno no podemos estar seguros que realmente se ejecuten _más rápido_. Intento evitar el exceso de gráficos pero valía la pena mostrar estos tiempos, al menos los más significativos. En los dos siguientes se puede observar el tiempo de retorno medido en _tiempo de reloj_ de los algoritmos anteriores para el Xeon de 16 núcleos y el ARMv7 de Raspberry 2.

.Tiempos de retorno en Intel Xeon 16 núcleos
image::optimized-xeon-real.png[align="center"]

.Tiempos de retorno en ARMv7 de Raspberry 2 cuatro núcleos
image::optimized-arm7-real.png[align="center"]

Aún en arquitecturas tan diferentes ceder el procesador representa un ahorro importante de CPU y de tiempo. En el Xeon de 16 núcleos la diferencia entre el _yield_ y el _backoff_ es mucho más notable. Éste tiene más núcleos que hilos por lo que un _yield_ solo hace que un proceso abandone el procesador pero probablemente el _scheduler_ lo lleve inmediatamente a ejecución en otro núcleo, depende mucho de sus algoritmos de _afinidad de CPU_. También puede ser que la unidad de tiempo elegida (un nanosegundo) se adecuada para el Xeon pero no tanto para el ARM, a pesar de ello se sigue ganando unos pocos milisegundos.


.Cede el procesador
****
Las esperas activas ya son suficientemente malas si no son imprescindibles. A menos que se trate un gestor de interrupciones, rutinas críticas del núcleo del sistema operativo, o un sistema de tiempo real donde se haya medido y calibrado casi al nivel de instrucciones individuales, no tendrás problemas poner un +sched_yield+ o _backoff_ exponencial en un _spinlock_ con mucha competencia. Esta regla es válida aún cuando te parezca que sobran procesadores.
****


[[readers_writers]]
=== Lectores-escritores
La mayoría de las operaciones sobre la memoria son lecturas. En estos casos lo que interesa es que éstas sean consistentes. En los ejemplos -un único contador entero- no existe el problema de lectura inconsistente: las palabras de 32 bits son <<atomic_register, registros atómicos>> en las arquitecturas modernas de 32 o más bits, si un proceso lee la variable siempre obtendrá el último valor escrito. Para estructuras de mayor tamaño -o incluso para acceder a ficheros o dispositivos externos- hay que imponer restricciones para que la memoria no sea modificada cuando otros procesos la están leyendo.

Se puede usar exclusión mutua pero la _serialización_ de los accesos de solo lectura es ineficiente. Una de las relajaciones más importantes a las condiciones de la exclusión mutua es que se permita más de un lector en la sección crítica, estos algoritmos de sincronización son llamados lectores-escritores (_reader-writer_).

Las condiciones que deben cumplir son:

- Se permite más de un lector en la sección crítica.

- Mientras haya un lector en la sección crítica no puede entrar ningún escritor.

- Los lectores no pueden entrar si hay un escritor en la sección crítica.

- Solo puede haber un escritor en la sección crítica.

Así como la exclusión mutua tiene un mecanismo de entrada (_lock_) y otro de salida (_unlock_), los de lectores-escritores necesitan distinguir entre ellos con entradas y salidas diferenciadas (_reader_lock_, _writer_lock_, _reader_unlock_ y _writer_unlock_).

El siguiente algoritmo es relativamente simple (<<rw_lock_c, código en C>>) implementado con las instrucciones _compare&swap_ y _get&add_. Se usa una variable global entera _mutex_ como en los algoritmos anteriores pero el bit más significativo se reserva para indicar si un escritor está en la sección crítica, los bits restantes se usan para contar el número de lectores. Para un entero de 32 bits se permiten hasta 2^31^ lectoresfootnote:[Se un número muy elevado y puede reducirse a enteros más pequeños pero en las mediciones de tiempo no encontré diferencia favorable.].

Los lectores primero esperan a que no haya ningún escritor, luego incrementan el número de lectores e intentan hacer el _CAS_. Si fue posible entran a la sección crítica, caso contrario vuelven a intentar desde el inicio del bucle.

.Entrada y salida para lectores
[source, python]
----
            rw_lock = 0             <1>

def reader_lock():
    while True:
        while rw_lock & 0x80000000: <2>
            pass
        old = rw_lock & 0x7fffffff  <3>
        new = old + 1               <4>
        if CAS(rw_lock, old, new):  <5>
            return


def reader_unlock():
    getAndAdd(rw_lock, -1)          <6>
----
<1> La variable global +mutex+, en el ejemplo de 32 bits.
<2> Verifica si el bit más significativo es 1, si es así hay un escritor e itera hasta que sea 0.
<3> No hay escritores, obtiene el número de lectores.
<4> Incrementa el número de lectores.
<5> Si +rw_lock+ no fue modificado el _compare&swap_ almacenará el nuevo valor. Si  +rw_lock+ fue modificado volverá al inicio del +while+ y lo intentará nuevamente.
<6> Decrementa atómicamente el número de lectores.

Los escritores primero esperan a que no haya otro escritor en la sección crítica, luego ponen el bit más significativo en 1 e intentan el intercambio con _CAS_. Si no fue posible vuelven a intentarlo desde el principio. Si fue satisfactorio esperan a que no queden lectores para entrar a la sección crítica.

.Entrada y salida para escritores
[source, python]
----
def writer_lock():
    while True:
        while rw_lock & 0x80000000:     <1>
            pass
        old = rw_lock & 0x7fffffff      <2>
        new = old | 0x80000000          <3>
        if CAS(rw_lock, old, new):      <4>
            while rw_lock & 0x7fffffff: <5>
                pass
            return


def writer_unlock():
    rw_lock = 0    <6>

----
<1> Verifica el bit más significativo e itera hasta que no haya ningún escritor.
<2> Obtiene el número de lectores actuales.
<3> Calcula el nuevo valor, será el número de lectores con el bit más significativo en 1 indicando que hay un escritor.
<4> Si el valor tomado de +rw_lock+ no cambió se almacena el nuevo, caso contrario vuelve al principio del +while+ para reintentar.
<5> Espera que salgan todos los lectores, los siguientes ya no podrán entrar porque el bit más significativo está en 1.
<6> Para salir solo debe poner +rw_lock+ en cero ya que no quedan lectores ni escritores en la sección crítica.


Una característica importante de los algoritmos de lectores-escritores es la prioridad que da a unos o a otros. Si lo que interesa es _rendimiento_ (_throughput_) y lecturas muy rápidas es mejor dar prioridad a los lectores. Si por el contrario interesa que las actualizaciones sean rápidas y acceder a los últimos valores lo antes posible se deben usar algoritmos que den prioridad a los escritores. El problema es el riesgo de inanición de los que tienen la menor proridad, aunque hay algoritmos que aseguran equidad los más comunes dan prioridad a uno de ellos (<<MCS2>>).

Queda a ejercicio del lector encontrar si este algoritmo da prioridad a los lectores o escritoresfootnote:[¡Seguro que no lo has pensado! este algoritmo da prioridad a los escritores. Cuando un escritor desea entrar a la sección crítica pone en 1 el bit más significativo independientemente del estado y número de lectores, haciendo que los siguientes lectores que lleguen esperen hasta que el escritor haya entrado y salido.].

[[fairness]]
=== _Spinlocks_ equitativos

Los algoritmos anteriores no cumplen uno de los <<em_requisites, requisitos deseables>> de la exclusión mutua, asegurar que la espera es limitada. Aunque estadísticamente no se pueden producir esperas infinitasfootnote:[En miles o centenares de miles de iteraciones es extremadamente improbable que nunca le toque a un proceso.] sí que plantea problemas de equidad -un proceso se retrasa mucho más que otros-, por ejemplo en 2008 se detectó este efecto en el núcleo de Linux (<<Corbet1>>, <<Corbet2>>).

[quote, Nick Piggin]
On an 8 core (2 socket) Opteron, spinlock unfairness is extremely noticable, with a userspace test having a difference of up to 2x runtime per thread, and some threads are starved or "unfairly" granted the lock up to 1 000 000 (!) times.

Para evitarlo hay que usar algoritmos que aseguran que los procesos entran a la sección crítica en el orden que han llegado (_FIFO_).

==== _Ticket-lock_
[[ticket_lock]]
Una solución sencilla la hemos descubierto al introducir la instrucción <<get_and_add_ticket, _get&add_>>, la idea es la misma que el algoritmo de la panadería solo que la obtención del número se hace con esta operación atómica, así se evita que los procesos puedan seleccionar el mismo número o lo hagan fuera de orden. Se usan dos variables: el número creciente y el turno. Un proceso obtiene su número y luego espera por su turno, cuando sale de la sección crítica incrementa el turno para que entre el siguiente proceso.

El <<ticket_lock_c, código en C>> de este algoritmo es idéntico al anterior de _get&add_, para hacerlo más eficiente se unificaron ambas variables en una única estructura de 32 bits, 16 bits para +turn+ y +number+ respectivamente. El número y turno pueden llegarán hasta 2^16^ y rotarán.

[source, c]
----
struct tickets {
    uint16_t turn;
    uint16_t number;
};
----

==== Lectores-escritores equitativo

Con la base el algoritmo _ticket-lock_ se puede implementar un algoritmo de lectores-escritores que asegure la equidad entre ellos (a diferencia de los que dan prioridad a unos u otros). Se necesitan dos variables diferentes para los turnos individuales, una estructura del siguiente tipo:

image::ticket_rw.png[width="80%", align="center"]

<<ticket_rw_lock_c, En C>> se define de la siguiente forma:

[source, c]
----
struct ticket_rw {
    uint16_t number;
    union {
        uint32_t combined;
        struct {
            uint16_t writer_turn;
            uint16_t reader_turn;
        };
    };
};
----

El campo +number+ es similar al algoritmo _ticket-lock_, +writer_turn+ y +reader_turn+ indicarán los turnos para escritores y lectores respectivamente. Ambas variables serán incrementadas para permitir que entren lectores o escritores de forma equitativa. El orden en que se haga la suma dejará entrar a unos u otros. Un escritor solo dará el turno a otros lectores o escritores cuando salga de la sección crítica. Un lector dará paso a otros lectores en cuanto haya entrado a la sección crítica y permitirá a escritores cuando haya salido.

Se define el campo +combined+ que incluye a ambos turnos para asignar atómicamente a ambos. Para el desarrollo del algoritmo suponemos una variable global +rw_local+ del tipo o clase +ticket_rw+.


.Entrada y salida para escritores
[source, python]
----
def writer_lock():
    number = getAndAdd(rw_lock.number, 1) <1>
    while number != rw_lock.writer_turn:  <2>
        pass
----
<1> El escritor obtiene su número.
<2> Espera que sea su turno.


[source, python]
----
def writer_unlock():
    tmp.writer_turn = rw_lock.writer_turn + 1 <1>
    tmp.reader_turn = rw_lock.reader_turn + 1 <1>
    rw_lock.combined = tmp.combined           <2>
----
<1> Incrementa el turno para lectores y escritores en una variable temporal.
<2> Asigna atómicamente ambos turnos. Cuando el escritor sale de la sección crítica debe poder entrar el siguiente lector o escritor, por lo tanto incrementa ambas variables.


.Entrada y salida para lectores
[source, python]
----
def reader_lock:
    number = getAndAdd(rw_lock.number, 1)  <1>

    while number != rw_lock.reader_turn:   <2>
        pass
    rw_lock.reader_turn++                  <3>
----
<1> El lector obtiene su número.
<2> Espera su turno.
<3> Cuando entró incrementa el turno de lectores para que puedan entrar el siguiente lector. Éste hará lo mismo, así puede haber varios lectores en la sección críticafootnote:[No hace falta que la suma se haga con operaciones atómicas ya que solo un lector puede ejecutarla, el siguiente no entra hasta que haya sido incrementada.].


[source, python]
----
def reader_unlock:
    getAndAdd(rw_lock.writer_turn) <1>

----
<1> El lector al salir incrementa el turno de escritor por si al siguiente es uno de ellos. No hace falta incrementar el turno de lectores, ya lo hizo antes al entrar a la sección crítica.

El algoritmo es equitativo, todos los procesos entran en el orden en que obtuvieron su número independientemente de que sea lector o escritor. Los lectores incrementan el turno de lectores inmediatamente, si el siguiente proceso es un escritor ningún lector podrá entrar, estos esperarán hasta que entre el escritor que tiene el turno y a su salida incremente el turno dando oportunidad de entrada a un lector o escritor.


[[scalable_spinlocks]]
=== _Spinlocks_ escalables

Es deseable que los _spinlocks_ sean escalables, el número de invalidaciones de caché (que generan _fallos de caché_, también llamados _cache bouncing_) debe ser constante independientemente del número de procesos o procesadores involucrados. La forma de lograrlo es que cada proceso itere sobre posiciones de memoria diferentes.

==== _Array-lock_
La solución obvia es que cada proceso tenga su propia posición en un array de _locks_ inicializados en cero, salvo la primera posición que será 1 para que el primer proceso pueda entrar. Los procesos que compitan por la sección crítica tendrán una posición única en ese array, ésta vendrá indicada por la variable +tail+ inicializada en cero. Cada proceso obtiene su posición con la operación _get&add_ que simultáneamente incrementa +tail+.

La variable que indica si un proceso puede entrar es booleana por lo que se usará un único byte. Para evitar el _false sharing_ es mejor separar cada posición por varios bytes. Para ello se define una estructura de mayor tamaño con un campo de un byte para la verificación, o la alternativa es que directamente se defina un array con posiciones de relleno (_padding_) para separar las posiciones del array que sí se usarán.

.Estructura de _array-lock_
image::array_lock.png[align="center"]

En la figura anterior _Thread 0_ ya entró en la sección crítica, _Thread 1_ y _Thread 2_ están esperando verificando el estado de sus respectivas posiciones en el array y +tail+ apunta a la siguiente posición. Cuando _Thread 0_ salga de la sección crítica cambiará el estado de +flag[1]+ y podrá entrar _Thread 1_.

La inicialización (en C) es la siguiente:

[source, c]
----
#define PADDING 32
char flag[NUM_THREADS * PADDING];
int tail;
...
    flag[0] = 1;
----

Si hay cuatro hilos máximo la dimensión del array será +4 * 32+ (128 bytes en total). El cálculo de la posición real (+my_index+) requiere de una multiplicación y módulo. El algoritmo resumido (<<array_lock_c, código completo en C>>) es el siguiente:


[source, python]
----
def lock(my_index):
    slot = getAndAdd(tail, 1)
    my_index = (slot % NUM_THREADS) * PADDING
    while not flag[my_index]:
        pass
    flag[my_index] = 1


def unlock(my_index):
    next = (my_index + PADDING) % SIZE
    flag[next] = 1;

----

Este algoritmo también es equitativo, solo requiere la instrucción atómica _get&add_ y los procesos entran en orden _FIFO_. Según la teoría y bibliografía especializada (por ejemplo <<Herlihy12>>) aseguran que así se evita el _false sharing_ y por lo tanto es más eficiente que _ticket-lock_, analizaremos cuánto hay de verdad <<spinlock_times, más adelante>>.


[[mcs_queue]]
==== MCS _Spinlock_ (1991)

[[lock-free_queue]]Una estrategia para disminuir la presión sobre la caché es hacer que las esperas activas verifiquen en su propia variable local, así se asegura que no se comparten líneas de caché y no se penaliza si éstas se almacenan en las proximidades de otras variables locales de los procesos. El algoritmo de cola MCSfootnote:[El nombre  MCS son las iniciales de los apellidos los autores.] fue descubiertofootnote:[Siempre tengo la duda -no soy el único- de si a los algoritmos son inventados o descubiertos, uso indistintamente ambas dependiendo e influido por el tipo de algoritmo o lo que leí de otros autores.] en 1991 por John M. Mellor-Crummey y Michael L. Scott (<<MCS1>>). Se considera uno de los algoritmos más importantes e influyentes de exclusión mutua, sus autores recibieron el premio _Edsger W. Dijkstra Prize in Distributed Computing_ de 2006.

Algoritmos derivados, conocidos como _colas no bloqueantes_ (_lock-free queues_), son muy usados en librerías _runtime_ y maquinas virtuales, como en la implementación de <<java_monitor, _monitores_ de la máquina virtual de Java>> y en las librerías +java.util.concurrent+ (<<Lea>>).

Para implementarlo se requieren las operaciones atómicas _swap_ y _compare&swap_. Es rápido, equitativo (FIFO) y no necesita asignación previa de memoria (como en _array-lock_). Los procesos deben pasar como argumento la dirección de un nodo (de la pila) local, cada nodo tiene la siguiente estructura:

[source, c]
----
struct mcs_spinlock {
    struct mcs_spinlock *next;
    unsigned char locked;
};
----

El campo +next+ es un puntero al nodo del siguiente proceso en la cola para la sección crítica, el campo +locked+ es una variable booleana que será 1 si el proceso de ese nodo debe esperar o 0 cuando puede entrar a la sección crítica. Cada proceso verifica su propia variable, cuando el que estaba en la sección crítica la abandona actualizará el campo del siguiente en la cola.

.Cola MCS
image::mcs.png[align="center"]

En la figura anterior se representa al hilo _Thread 0_ que ya salió de su sección crítica, _Thread 1_ está en ella, el siguiente es _Thread 2_, el último en la cola es _Thread 3_. Cada uno de los procesos en espera activa verifica el campo +locked+ de su nodo local. La variable _tail_ apunta al último proceso en la cola, si no hay ningún proceso será +NULL+ (o 0, +None+, etc.).

El siguiente es el <<mcs_spinlock_c, código en C>> simplificado del algoritmofootnote:[Dada la importancia de manipular punteros en este algoritmo y el siguiente consideré más apropiado mostrar en _pseudocódigo C_.]:

[source, c]
----
void lock(mcs_spinlock *node) {
    mcs_spinlock *predecessor;

    node->next = NULL;               <1>
    node->locked = 1;                <1>
    predecessor = node;              <2>
    predecessor = SWAP(&tail, node); <2>
    if (predecessor != NULL) {       <3>
        predecessor->next = node;    <3>
        while (node->locked);        <4>
    }
    node->locked = 0;
}
----
<1> Inicialización del nodo, _locked_ se pone en _verdadero_.
<2> Preparación para el _swap_, +predeccesor+ apunta inicialmente al nodo actual, cuando se haga el intercambio si había un proceso esperando o en la sección crítica +predecessor+ apuntará al nodo de ese proceso, caso contrario será +NULL+.
<3> Si hay otro proceso hará que su campo +next+ apunte al nodo actual.
<4> Espera activa hasta que el predecesor cambie el estado de +locked+ a falso.

[source, c]
----
void unlock(mcs_spinlock *node) {
    mcs_spinlock *last;

    if (! node->next) {
        last = node;                     <1>
        if ( CAS(&tail, &last, NULL) ) { <1>
            return;                      <2>
        } else {
            while (! node->next);        <3>
        }
    }
    node->next->locked = 0;              <4>
}
----
<1> Si +next+ del proceso actual es +NULL+ entonces podría ser el último de la cola, prepara +last+ para hacer el _compare&swap_.
<2> Se pudo hacer el intercambio lo que significa que no hay ningún proceso intentando entrar a la sección crítica, retorna sin hacer nada más, el puntero +tail+ habrá quedado con +NULL+.
<3> Si no se pudo hacer el intercambio, hay un proceso que está ejecutando el +lock+ pero todavía no ejecutó la instrucción +predecessor->next = node+, se espera hasta que lo hace.
<4> Se ejecuta solo si había un proceso esperando, en este caso le asigna 0 al campo +locked+ de su nodo para que pueda continuar.


.Barreras de memoria
****
En el código C de algunos de los algoritmos se usa `thread_fence` o `store_n` para introducir barreras de memoria explícitas. La necesidad de barreras no se menciona en la bibliografía o los artículos científicos citados pero son necesarias por lo explicado en <<barriers>>: aunque el sistema de caché sea coherente aún se puede producir ejecución de instrucciones fuera de orden. Si algunos _caminos_ del algoritmo de salida (_unlock_) no ejecutan ninguna instrucción atómica que implique también una barrera de memoria puede ocurrir que instrucciones de la sección crítica se ejecuten después de haber acabado la salida (+unlock+).

Durante las pruebas y validación del código de ejemplo comprobé que en algunos procesadores se manifestaba esta condición de carrera, en particular con el ARMv7 de Raspberry 2. Preferí mostrar la versión simplificada en estas páginas pero la versión completa y correcta en el listado del código fuente para que funcione correctamente en todas las arquitecturas, aunque en algunas de ellas -como en Intel- significara una sobrecarga innecesaria.
****


==== CLH _Spinlock_ (1993)
Una par de años después de la publicación del algoritmo de _MCS_ dos grupos descubrieron el _CLH_ de forma independiente, Travis Craig  de la Universidad de Washington (<<Craig>>) y Anders Landin y Eric Hagersten del Instituto Sueco de Ciencias de la Computación (<<CLH>>).

Como el _MCS_, este algoritmo también está basado en una cola y es equitativo pero los punteros son en sentido inverso, no apuntan al siguiente que le toca el turno sino al nodo del proceso predecesor.

[[clh_queue]]
.Cola CLH
image::clh.png[align="center"]

El algoritmo es breve pero más complejo, tiene más niveles de indirección (se opera sobre las direcciones de memoria de punteros de memoria) y a diferencia de _MCS_ los procesos verifican el estado de una variable en el nodo predecesor. Sus ventajas son:

- Como _MCS_ la espera activa se hace sobre variables independientes aunque no necesariamente locales a cada proceso.
- Solo requiere la instrucción atómica _get&set_.
- La memoria de los nodos puede ser gestionada independientemente. Los procesos pueden proveer un nodo a una dirección estática o el propio módulo de _spinlocks_ puede gestionar la memoria (por ejemplo haciendo +malloc+ en el +lock+ y +free+ del nodo que ya no se usa en el +unlock+).
- Puede ser adaptado a sistemas sin coherencia de caché.

La estructura de cada nodo es similar a _MCS_:

[source, c]
----
struct clh_node {
    unsigned char locked;
    struct clh_node *prev;
};
----

A diferencia de _MCS_ se debe comenzar con un nodo _sin propietario_ y la variable +tail+ apuntando a dicho nodo. Por ejemplo:

[source, c]
----
struct clh_node lock_node;          <1>
struct clh_node *tail = &lock_node; <2>
----
<1> El nodo _sin propietario_.
<2> +tail+ apunta inicialmente a ese nodo.

La versión simplificada del <<clh_spinlock_c, algoritmo en C>> es la siguiente:

[source, c]
----
void lock(clh_node *node) {
    clh_node *predecessor;

    node->locked = 1;                    <1>
    node->prev = getAndSet(&tail, node); <2>
    predecessor = node->prev;            <2>
    while (predecessor->locked);         <3>
}
----
<1> Se almacena al nodo actual como +locked+, este campo será verificado por el siguiente proceso que pretenda entrar a la sección crítica.
<2> Se obtiene la dirección de +tail+ que indica cuál es el predecesor del proceso actual y se almacena en +tail+ la dirección del nodo actual. El valor que tenía +tail+ se almacena en el campo +prev+ (es el puntero al nodo del proceso anterior) y se hace una copia en +predecessor+.
<3> Se hace la espera activa sobre el campo +locked+ del nodo anterior, cuando sea falso el proceso actual podrá continuar.

[source, c]
----
void unlock(clh_node **node) {
    clh_node *pred;
    clh_node *tmp;

    pred = (*node)->prev; <1>
    tmp = *node;          <2>
    *node = pred;         <3>
    tmp->locked = 0;      <4>
}
----
<1> Se hace una copia del puntero al nodo del proceso anterior (sobre el que este procesó iteró en el +lock+).
<2> Se hace una copia temporal para no perder la dirección del nodo actual.
<3> El puntero que apuntaba al nodo del proceso actual ahora apuntará al del predecesor. Se podría liberar esa memoria pero en estos ejemplos la reciclamos para no hacer +malloc/free+ en cada +lock+ y +unlock+.
<4> Se almacena falso en el campo +locked+ del nodo actual, el proceso que está a continuación en la cola podrá entrar a la sección crítica.


[[spinlock_times]]
=== Análisis de tiempos de ejecución
_Ticket-lock_ es un algoritmo equitativo muy utilizado pero no es _escalable_, los procesos verifican la misma posición de memoria. La respuesta es usar un array con posiciones de relleno para evitar el _false sharing_. Algunos autores proponen que el relleno complete el tamaño de una palabra (cuatro u ocho bytes), otros que sean de mayor longitud para que no compartan líneas de caché. ¿Cuál es la separación apropiada?, ésta depende de la arquitectura y es difícil saber a priori cuál es la mejor para cada una. Depende de muchos factores, el tipo de instrucción, los canales de comunicación para sincronización o el mecanismo de monitorización de los registros de _LL/SC_ (en las arquitecturas que lo implementan).

Para tomar una decisión informada del _padding_ a usar hice pruebas con los diferentes procesadores variando el tamaño del relleno. La siguiente figura muestra los tiempos de CPU de cada procesador para diferentes tamaños. El eje horizontal muestra la separación entre las diferentes posiciones del array (desde 2 a 256 bytes) y el vertical el tiempo de CPU en segundos.

.Diferentes tamaños de relleno
image::array-paddings.png[align="center"]

En Intel Xeon e i5 los tiempos son constantes mientras que en Raspberry 2 e Intel Core2 se produce un descenso importante a los 16 y 32 bytes. Para hacer una comparación razonable el tamaño del relleno elegido asegura que la separación entre posiciones consecutivas es 32 bytes. En las dos imágenes a continuación se muestran los tiempos comparados de CPU y tiempo de reloj respectivamente para los algoritmos _ticket-lock_, _array-lock_, _MCS_ y _CLH_.

.Ticket-lock vs array-lock vs MCS vs CLH
image::ticket-mcs-clh.png[align="center"]

.Tiempos de retorno
image::ticket-mcs-clh-real.png[align="center"]

En las arquitecturas modernas no hay tanta diferencia entre _ticket-lock_ y _array-lock_, de hecho en Intel Xeon esta última es peor. Además, _array-lock_ necesita más espacio -una palabra por proceso- que hay que reservar desde el principio (como en el algoritmo de la panadería), mientras que _ticket-lock_ solo requiere una palabra.

En general _MCS_ y _CLH_ son los más eficientes en tiempo, pero la diferencia no es considerable y como _array-lock_ también requieren más espacio (un nodo por cada proceso activo, aunque la asignación puede ser dinámica y solo cuando se necesitan). Esta es una de las razones por la que _ticket-lock_ sigue siendo el _spinlock_ preferido en el núcleo de Linux. En muchos artículos se afirma que _CLH_ es mejor que _MCS_, aunque en los procesadores probados la diferencia es despreciable y en algunos casos es a peor. La ventaja de _CLH_ es la mayor flexibilidad para gestionar la memoria, puede hacerse en las propias funciones +lock+ y +unlock+ de forma transparente a los procesos.

////

http://www.cs.rice.edu/~vs3/comp422/lecture-notes/comp422-lec19-s08-v1.pdf
http://www.cs.rochester.edu/~scott/papers/1994_IPPS_mprog.pdf

http://www.cs.rochester.edu/research/synchronization/pseudocode/ss.html


Agradecimientos a Marc Pampols

Reader-writer: https://jfdube.wordpress.com/2014/01/03/implementing-a-recursive-read-write-spinlock/
https://jfdube.wordpress.com/2014/01/12/optimizing-the-recursive-read-write-spinlock/

(http://nullprogram.com/blog/2014/09/02/ https://github.com/skeeto/lstack)
Common Pitfalls in Writing Lock-Free Algorithms http://blog.memsql.com/common-pitfalls-in-writing-lock-free-algorithms/

Toward generic atomic operations/The C11 memory model http://lwn.net/Articles/509102/

Ticket implementation https://github.com/karthick18/ticket_spinlock/blob/master/spinlock.h

Lightweight Contention Management for
Efficient Compare-and-Swap Operations http://arxiv.org/pdf/1305.5800.pdf

MCSLocks http://lwn.net/Articles/590243/

Improving ticket spinlocks  http://lwn.net/Articles/531254/

http://ftp.cs.rochester.edu/u/scott/papers/2001_PPoPP_Timeout.pdf
////


=== Recapitulación

Comenzamos con las optimizaciones básicas a _spinlocks_ construidos con las instrucciones de hardware de capítulo anterior. La primera fue agregar un control _local_ a la variable compartida para evitar consumir ciclos de reloj en instrucciones más complejas, esta solución no requiere nada especial ni cambia el estado del proceso. A continuación vimos dos optimizaciones que sí cambian el estado del proceso y son adecuadas cuando se puede permitir que el proceso en el _spinlock_ abandone el procesadorfootnote:[No suele ser el caso en rutinas del núcleo del sistema operativo o gestores de interrupciones.]. Ambas soluciones mejoran mucho la eficiencia, tanto en tiempos de CPU como de retorno.

Luego vimos la implementación de lectores-escritores con _spinlocks_. Este algoritmo es muy común y lo veremos también implementado con las técnicas de capítulos posteriores. Su utilidad se basa en que las actualizaciones de datos son menos frecuentes que las lecturas, interesa relajar las restricciones de exclusión mutua para permitir que haya más de un lector en la sección crítica mientras no haya ningún escritor.

A continuación se introdujo el tema de los _spinlocks_ equitativos (_fair_). Estos aseguran que los procesos entran a la sección crítica en el orden que llegan (FIFO), se puede demostrar formalmente que no se produce inanición (_starvation_).

El primer algoritmo fue _ticket-lock_, basado en las mismas ideas del algoritmo de la panadería. Cada proceso obtiene un _número_ único y creciente que sirve para sincronizar la entrada a la sección crítica mediante una variable de turno que también crece monotónicamente. A continuación extendimos este algoritmo para lectores-escritores que además tiene la propiedad de ser equitativo, no da prioridad a lectores ni escritores.

Finalmente vimos dos algoritmos fundamentales de concurrencia que implementan _lock-free queues_, _MCS_ y _CLH_. Ambos son equitativos basados en colas y escalables, no incrementan la presión sobre el sistema de caché cuando se incrementa el número de procesos. Estos algoritmos funcionan sobre sistemas de caché coherentes pero hay modificaciones que permiten que sean usados en sistemas no coherentes y en arquitecturas NUMA.

A partir del siguiente capítulo veremos construcciones y abstracciones de más alto nivel cuyos objetivos son evitar las esperas activas mediante el bloqueo de los procesos, como así también facilitar la programación de mecanismos de sincronización más sofisticados y complejos que exclusión mutua.
