[[tm]]
== 10. Memoria transaccional

image::jrmora/10-transaccional.jpg[align="center"]

Como la exclusión mutua, la memoria transaccional es un mecanismo de control de concurrencia. Sus objetivos son simplificar la programación y aumentar el paralelismo de los programas concurrentes. Para acceder a registros compartidos se usa el mismo concepto de _transacción_ conocida desde hace tiempo en las bases de datos ACID. Desde el punto de vista del programador, las transacciones se ejecutan secuencialmente y aisladas unas de otras y las complejidades del control de concurrencia son invisibles.

Las transacciones están íntimamente relacionadas con las secciones críticas. En capítulos anteriores estudiamos dos tipos de mecanismos para resolverlas: los _spinlocks_ con espera activa y las soluciones bloqueantes con semáforos y monitores. Pero estas soluciones tienen limitaciones importantes.

=== Limitaciones de la sección crítica

- La exclusión mutua reduce la capacidad de paralelismo. Las secciones críticas deben ser ejecutadas secuencialmente por lo que se reduce la capacidad de ejecutar hilos en otros procesadores.

- Para evitar los cuellos de botella generados por las secciones críticas se implementan _estructuras concurrentes_ (_lock-free structures_) con instrucciones atómicas del procesador (fundamentalmente _CAS_). Pero estas primitivas solo trabajan con una palabra por lo que requieren algoritmos más complejos cuando se debe trabajar con objetos de mayor tamaño.

- Los _spinlocks_ para exclusión mutua producen inversión de prioridades y _efecto convoy_ cuando un proceso en la sección crítica es interrumpido. La inversión de prioridades ocurre cuando otros procesos de mayor prioridad no pueden entrar a la sección crítica; el efecto convoy cuando los procesos en espera se acumulan, aún después de que el proceso interrumpido haya liberado la sección crítica toma un tiempo vaciar la cola de procesos en espera.

- Los interbloqueos son difíciles de evitar si se manipulan muchos objetos. Aunque hay técnicas y reglas conocidas (<<deadlocks>>), con el incremento del número y tamaño de los programas concurrentes el modelo ya no es sustentable (<<Herlihy12>>).

- Los basados en primitivas atómicas no son _componibles_. Los algoritmos de _spinlocks_ son complejos por la dificultad de componer llamadas a múltiples objetos en unidades atómicas. En <<free_lock_stack>> vimos como implementar una pila sin exclusión mutua, pero no se puede eliminar el elemento de una e insertarla en otra atómicamente. Se pueden agregar mecanismos _ad hoc_, como exclusión mutua adicional, pero crean otro cuello de botella.

- Son difíciles de gestionar de manera efectiva, especialmente para la gestión de estructuras complejas o de grandes sistemas. Si se desea más eficiencia y paralelismo hay que trabajar con granularidades pequeñas. Se usan _mutex_ o _spinlocks_ globales para gestionar estructuras sofisticadas (como _hashing_ o árboles balanceados) porque reducir la granularidad de las secciones críticas es una tarea compleja, tediosa, propensa a errores y difícil de validar. Lo que desea el programador es indicar la sección crítica general y que el sistema se encargue de controlar la granularidad.

Todo parece indicar que en el futuro se incrementará el número de núcleos y procesadores y por consiguiente se producirá un crecimiento del número y tamaño de programas concurrentes. Hay un consenso académico y en la industria en que las herramientas actuales tienen demasiadas limitaciones para cubrir las necesidades que se avecinan.

=== Veinte años de historia

Aunque todavía están en su infancia, durante los últimos años se produjo un aumento notable de publicaciones científicas y desarrollos de sistemas de memorias transaccionales. La primera propuesta de usar transacciones en programas concurrentes fue de David Lomet en 1977 (<<Lomet>>) pero no detalló ninguna solución práctica competitiva con los mecanismos de sincronización explícitos (<<Harris>>). La idea cayó en el olvido durante quince años.

En 1993 Maurice Herlihy y Eliot Moss (<<Herlihy93>>) propusieron soluciones de soporte de hardware de transacciones para superar las limitaciones de los _spinlocks_, principalmente la inversión de prioridades, el _efecto convoy_ y los interbloqueos. El mismo año Janice Stone _et al_ (<<Stone>>) propusieron primitivas de hardware atómicas _multipalabra_ conocidas como _Oklahoma Update_. El diseño propuesto está basado en la misma idea de LL/SC (<<llsc>>) pero permite reservar más de una palabra.

En 1995, Nir Shavit y Dan Touitou (<<Shavit>>) demostraron por primera vez el uso práctico de memoria transaccional por software (_STM_). En 2006 Nir Shavit, Dave Dice y Ori Shalev presentaron el algoritmo _Transaction Locking 2_ (_TL2_, <<Dice>>). TL2 sirvió de base para varias librerías de memoria transaccional, entre ellas TinySMT (<<Felber>>). TinySTM es una de las librerías _STM_ más populares y eficientesfootnote:[Uno de sus autores, Torvald Riegel, es también responsable de las librerías _libitm_ que usa GCC.]. El desarrollo de nuevos algoritmos y las optimizaciones de los compiladores hacen que tenga sentido usar memoria transaccional aún sin soporte de hardware.


En los últimos años se ha producido un avance notable en sistemas de memoria transaccional por hardware (_HTM_). En 2007 Sun presentó el procesador UltraSPARC Rock con soporte _HTM_, cancelado en 2009 (<<Chaudhry>>). Los procesadores del supercomputador BlueGene Sequoia incluyeron soporte _HTM_ en 2011. Entre 2012 y 2013, Intel (Haswell) e IBM (con PowerPC y S390) presentaron sus procesadores con _HTM_.


Además de los desarrollos en _STM_ y _HTM_ se hicieron esfuerzos importantes para la estandarización y soporte genérico de memoria transaccional. Hay un borrador para estandarizar las construcciones de _bloques atómicos_ en C y C++ (<<Tabatabai>>). El compilador GCC incluye soporte para _STM_ desde la versión 4.7 y soporte de hardware para procesadores Intel, PowerPC y S390 de la versión 4.8 (<<TransactionGCC>>). Los _mutex_ de las librerías POSIX Threads usan el soporte de hardware desde la versión Glibc 2.18 (2013, <<Kleen>>). El mismo año se empezó a desarrollar soporte para _HTM_ en el núcleo Linux.


[NOTE]
.Transacciones de bases de datos
====
Las bases de datos son capaces de trabajar concurrentemente y en paralelo desde hace años, ejecutan varias consultas simultáneamente siempre que es posible. Obtienen esta eficiencia con un modelo que evita que el programador deba preocuparse de la concurrencia. El corazón del sistema es la transacción, que especifica una semántica de secuencia de operaciones –una composición– como si fuese el único proceso accediendo a la base de datos.

Las operaciones dentro de transacciones se ejecutan concurrentemente y en paralelo, pero las interacciones están limitadas de forma que los resultados no varían si se ejecutan una después de otra. Esta propiedad del modelo se llama _secuencialidad_ (_serializability_) y facilita el trabajo al programador habituado a la programación secuencial.

Las bases de datos tienen las propiedades ACID, por _atomicidad_, _consistencia_, _aislamiento_ (_isolation_) y _durabilidad_:

- _Atomicidad_ significa que las operaciones de una transacción se completan todas o ninguna. Si se _rechaza_ una ejecución no se dejan rastros de los cambios que se hicieron _tentativamente_. Cuando una transacción acaba correctamente se hace el _commit_ haciendo visible los cambios, caso contrario la transacción de _aborta_.

- _Consistencia_ significa que los datos pasan de un estado consistente a otro. Se respetan los invariantes, por ejemplo: el resultado de una transferencia bancaria que generó un ingreso en una cuenta también incluye la extracción desde otra.

- _Aislamiento_ implica que no hay interferencias entre transacciones. Los cambios realizados por las operaciones de una transacción no son visibles ni afectan al resultado de otras en cursofootnote:[Existe la técnica del _dirty read_ que permite que un +select+ vea los resultados parciales de otras transacciones en curso, pero es la excepción y habitualmente hay que seleccionarla al configurar el servidor de base de datos.].

- _Durabilidad_ asegura que si una transacción acaba correctamente (con _commit_) sus datos están almacenados en el dispositivo de almacenamiento persistente.
====


=== Transacciones
Como en bases de datos ACID, una transacción es una serie de instrucciones de acceso a memoria ejecutadas por un único proceso. Las transacciones concurrentes deben ser _secuenciables_: desde el punto de vista del programador parecen ejecutarse secuencialmente. El resultado de la ejecución de dos transacciones concurrentes es equivalente a una ejecución secuencial.

Mientras los _mutex_ y _spinlocks_ son pesimistas, las transacciones son optimistas y pueden ser ejecutadas especulativamente en paralelo. Las transacciones hacen cambios _tentativos_ a objetos, si acaban sin conflictos se hace el _commit_ que hace visible los cambios a los demás procesos.

Si se detecta un conflicto en los datos la transacción se aborta y no se dejan rastros de las modificaciones _tentativas_ que se hicieron a las variables compartidas.

==== Ventajas

Granularidad:: Las transacciones detectan y resuelven con granularidades menores. Se pueden recorrer estructuras complejas (árboles, grafos, tablas de _hashing_, etc.) o manipular muchos objetos sin que el programador deba preocuparse de optimizar la exclusión mutua. Basta especificar las transacciones a niveles más globales, las transacciones se ejecutarán en paralelo y se detectarán los conflictos con granularidad de hasta registros individuales.

Composición:: Las construcciones con transacciones pueden componerse para hacer atómicas un conjunto de operaciones independientes, como eliminar elementos de una estructura y añadirlas a otras. Las diferentes operaciones se incluyen dentro de una misma transacción. Estas operaciones eran imposibles con _spinlocks_ sin mecanismos adicionales más complejos y costosos (como agregar otro _spinlock_).

No producen interbloqueos:: Salvo errores del programador, como esperas activas dentro de una transacción, las transacciones y sus composiciones no producen interbloqueos.

Mayor paralelismo:: Al no requerir exclusión mutua todos los procesos pueden ejecutarse en paralelo en diferentes procesadores.


Pero las transacciones no son la panacea, los programadores aún pueden provocar interbloqueos o definir transacciones imposibles de finalizar sin conflictos.
O incluso olvidarse de hacer el _commit_ de una transacción. Para reducir este tipo de errores se especificaron construcciones sintácticas como los _bloques atómicos_.


==== Funciones y bloques atómicos

Las operaciones básicas para gestión de transacciones:

- Iniciar transacción, +StartTx+.
- Confirmar la transacción (_commit_), +CommitTx+.
- Abortar la transacción actual, +AbortTX+.

Y para acceso a datos:

- Leer, +Type ReadTx(Type *address)+.
- Escribir, +WriteTx(Type *address, Type value)+.

Una transacción simple para la operación sobre el contador de los ejemplos esfootnote:[Los nombres de las funciones son genéricos, uso los mismos que se suelen encontrar en la bibliografía.]:

[source, c]
----
StartTX();
c = LoadTX(&counter);
c += 1;
StoreTX(&counter, c);
CommitTx();
----

Este tipo de construcciones se denominan _transacciones explícitas_. Pero los compiladores pueden ofrecer construcciones de uso más simple para el programador, los _bloques atómicos_:

[source, c]
----
transaction {
    counter += 1;
}
----

Con los bloques se mejora la calidad del código y se facilita la tarea del programador. El compilador es responsable de insertar las llamadas a las funciones de memoria transaccional (_instrumentación_). Un bloque atómico es equivalente a las siguientes funciones explícitas:

[source, c]
----
do {
    StartTx();
    ...
} while (!CommitTx());
----

[NOTE]
====
La construcción con +transaction+ es similar a +synchronized+ en Java o a +atomic+ en C++. Pero mientras estas últimas introducen un _mutex_ que se aplica a otros métodos de la misma instancia, `transaction` es global y permite la ejecución concurrente.
====


Algunos compiladores ya incluyen construcciones sintácticas de bloques, el compilador _Intel C\++ STM Compiler_ (<<IntelSTM>>) y GCC. Para C/C++ se está trabajando en el borrador de la especificación (<<Tabatabai>>), permitirá dos tipos de transacciones: relajadas y más estrictasfootnote:[`__transaction_relaxed` y  `__transaction_atomic` respectivamente.].

==== Bloques atómicos con GCC

Desde la versión 4.7 GCC (2011) permite especificar bloques atómicos con semántica similar a la del borrador de C/C++ (<<TransactionGCC>>). El siguiente ejemplo es la implementación del contador con memoria transaccional (<<tm_mutex_gcc_c, código completo>>)footnote:[Puede usarse también `__transaction_relaxed`, pero con gcc 4.9 no encontré diferencia en el código ensamblador generado.]:

[source, c]
._Mutex_ con GCC
----
for (i=0; i < max; i++) {
    __transaction_atomic {
        counter++;
    }
}
----


==== Gestión de versiones

Los sistemas de memoria transaccional deben gestionar las escrituras tentativas que se hacen en las transacciones, esta tarea se denomina _gestión de versiones_. Hay dos modelos:

Actualización directa (o _eager version management_):: Se modifica directamente en la dirección de memoria original y se mantiene un _undo-log_ para restaurar los valores si la transacción es abortada. Este modelo requiere control de concurrencia pesimista.

Actualización retrasada (_lazy version management_ o _deferred update_):: Las actualizaciones se hacen al momento del _commit_. Las transacciones mantienen un _redo-log_ privado. El _redo-log_ puede ubicarse una copia en memoria, _buffers_ de escritura, líneas de caché de acceso exclusivo, o en registros adicionales (_renamed registers_).

==== Control de concurrencia

Cada transacción mantiene un conjunto de registros _leídos_ (_read-set_) y _escritos_ (_write-set_) que son usados para detectar y solucionar los conflictos. Se diferencian tres eventos puntuales:

1. Ocurrencia: El momento en que dos transacciones hacen operaciones conflictivas sobre las mismas regiones de datos.

2. Detección: Cuando el sistema de memoria transaccional determina que hay un conflicto.

3. Resolución: Cuando el sistema de memoria transaccional toma una acción para evitar el conflicto. Puede abortar o retrasar una de las transacciones.

Los tres eventos pueden ocurrir en diferentes momentos pero siempre en el mismo orden. Hay dos modelos de control dependiendo del momento en que ocurre la detección:

- El _control de concurrencia pesimista_ detecta el conflicto en cuanto se produce, por lo tanto los tres eventos se producen simultáneamente. Al inicio de cada transacción el proceso se _apropia_ de los datos, como en una sección crítica, y los demás no pueden acceder a ellos.

- Con el _control optimista_ los eventos de detección y resolución pueden ocurrir más tarde. Este tipo de control permite que varias transacciones accedan simultáneamente a los mismos datos y avancen aún con conflictos. Esto permite mayor libertad para la resolución, se puede abortar o retrasar a las transacciones conflictivas.

El control optimista permite mayores niveles de concurrencia, pero si la tasa de conflictos es elevada produce ejecuciones inútiles. En estos casos es mejor usar control pesimista.

El control optimista debe considerar otras cuestiones:

- Granularidad del conflicto. Puede tratarse a nivel de palabras, objetos (tamaños superiores o estructuras más complejas) o líneas de caché en implementaciones por hardware.

- El instante de la detección del conflicto:

    * Si se hace al acceder a los datos se denomina _detección temprana_ (_early conflict detection_).
    * El sistema puede hacer validaciones en varios instantes durante la transacción para verificar si hay conflictos.
    * Si se hace en el momento del _commit_ se denomina _detección tardía_ (_lazy conflict detection_).

- El tipo de acceso que es tratado como conflicto. Se puede hacer entre transacciones concurrentes activas (_tentativas_) o entre las activas y las ya finalizadas.


=== Memoria transaccional por software (_STM_)

Los sistemas _STM_ son implementaciones por software que pueden ejecutarse en cualquier procesador. Implican una penalización importante por el control programático que debe hacerse de cada lectura y escritura de un objeto. Sin embargo, los sistemas _STM_ tienen importantes ventajas:

- El software es más flexible que el hardware, evoluciona más rápido y permite implementar una mayor variedad de algoritmos.

- No está limitado por las estructuras de palabras del hardware, puede implementar transacciones a nivel de objetos con estructuras más complejas.

- Naturalmente permiten las transacciones con llamadas explícitas pero son fácilmente integrables en los lenguajes. Estos pueden generar el código necesario (_instrumentación_) para las llamadas a las funciones.

==== Componentes

Los componentes fundamentales de las librerías _STM_ son:

- Descriptor de la transacción. Es la estructura de datos que mantiene la información de estado de cada transacción.

- _Undo-log_ o _redo-log_. Depende del sistema de versiones que use el sistema debe mantener uno u otro.

- Conjuntos de registros leídos (_read-set_) y escritos (_write-set_). Mantienen las direcciones que fueron leídas y escritas, normalmente acompañadas de un número de versión (que puede ser local o global).

- Estructuras comunes. Son los datos necesarios para detectar conflictos entre diferentes transacciones y hacer operaciones atómicas con sus estructuras de datos. Por ejemplo, array de _spinlocks_ para secciones críticas internas, número de versión global, árbol de dependencias globales, etc.


==== Llamadas explícitas

En general las librerías se programan con llamadas explícitas, veremos ejemplos con la librería _tinySMT_ (ya incluidas en el repositorio de Github).

El procedimiento general es inicializar la librería al principio del programa (+stm_init+) y en cada hilo que la usará (+stm_init_thread+). Las transacciones se inician con +stm_start+ y se hace el _commit_ con +stm_commit+. Los ejemplos de la librería incluyen macros de conveniencia para facilitar la programación, en los ejemplos usamos los de inicio (+TM_START+) y fin de transacción (+TM_COMMIT+).

Dentro de las transacciones no se debe acceder directamente a los registros u objetos compartidos, sino que deben usarse las funciones para lectura y escritura. En nuestro caso, se trata de un entero, usamos +stm_load_int+ y +stm_store_int+.

El siguiente es el código resumido para incrementar el contador compartido (<<tm_mutex_tinystm_c, código completo>>):

[source, c]
----
for (i=0; i < max; i++) {
    TM_START(0, 0);         <1>
    c = stm_load_int(&counter);
    c++;
    stm_store_int(&counter, c);
    TM_COMMIT;              <2>
}
----
<1> Un macro de conveniencia que abre un bloque, llama a +stm_start+ y salva el contexto.
<2> Otro macro de conveniencia, llama a +stm_commit+ y cierra el bloque.



==== Instrumentación del compilador

No es práctico programar con funciones explícitas, son propensas a provocar errores de programación. El programador debe preocuparse de insertar las funciones de inicio o fin de transacción y de no acceder directamente a las variables compartidas, sino usar las funciones específicas para leer o almacenar. Cualquier omisión puede provocar fallos graves difíciles de detectar.

Es mucho más conveniente una construcción sintáctica que delimite claramente qué instrucciones son las que están en una transacción y que sea el compilador el responsable de detectar qué accesos necesitan ser controlados. Para ello se definen los _bloques atómicos_, como el siguiente ejemplo (<<tm_mutex_gcc_c, código completo>>):

[source, c]
----
transaction {
    counter += 1;
}
----

El compilador es el responsable de hacer la _instrumentación_ del código. Consiste en detectar el acceso a variables compartidas e insertar las llamadas a las funciones de lectura y escritura de la librería. En el ejemplo anterior el GCC inserta el siguiente código:


[source]
----
call    _ITM_beginTransaction
...
call    _ITM_RU4    <1>
...
call    _ITM_WU4    <2>
...
call    _ITM_commitTransaction
----
<1> Función para leer +counter+, un entero de cuatro bytes.
<2> Función para escribir +counter+.


Las funciones con el prefijo `_ITM` son parte del estándar _Intel Transactional Memory Compiler and Runtime Application Binary Interface_ (<<IntelABI>>) que define las funciones que deben implementarse en las librerías _STM_. El objetivo es que un programa pueda usar diferentes librerías seleccionadas en el momento de la ejecución. Las librerías más populares _STM_ implementan este estándar.

GCC incluye su propia librería de memoria transaccional: _libitm_. Las funciones están implementadas en las librerías _runtime_ y se cargan dinámicamente, pero puede usarse cualquier otra compatible con _ITM_.

=== Memoria transaccional por hardware (_HTM_)

Aunque las librerías _STM_ son muy flexibles imponen una sobrecarga a la ejecución, cada lectura y asignación implica llamadas a funciones que a su vez ejecutan algoritmos de control de versiones y concurrencia. Puede hacerse más eficiente en el hardware aunque estos tienen más limitaciones que las implementaciones por software.

Hay dos tipos básicos de sistemas _HTM_:

Sistemas explícitos:: El procesador tiene instrucciones adicionales de acceso a memoria para indicar qué direcciones deben tratarse como parte de una transacción, por ejemplo +load_transactional+ o +store_transactional+. Estos sistemas dan mayor libertad y flexibilidad al programador pero requieren adaptación de todas las librerías para que usen las nuevas instrucciones. No es la mejor solución si se desea mantener compatibilidad con los programas más antiguos. Las propuestas _Oklahoma Update_ (<<Stone>>) y _Advanced Synchronization Facility_ eran de este tipo, aunque ninguno de ellas llegó a fabricarse.

Sistemas implícitos:: Solo requieren que se indiquen los límites de la transacción, como +tbegin+ y +tend+. Todos los accesos a variables compartidas entre ambas instrucciones son tratados como transaccionales. El primer procesador de este tipo fue el UltraSPARC Rock de Sun. Los procesadores Intel, PowerPC y S390 implementan este mecanismo en sus procesadores con soporte de _HTM_.


==== Intel TSX, IBM PowerPC y S390

En 2012 Intel anunció que su arquitectura Haswell incluiría _HTM_ y comenzó a comercializarla desde 2013 en los procesadores Xeon e i7footnote:[Podéis verificar si tiene soporte con `cat /proc/cpuinfo`, en la línea de +flags+ debería aparecer +hle+ y/o +rtm+.]. BlueGene Q/Sequoia de IBM usa _HTM_ desde 2011, los procesadores de S390 System z desde 2013 y POWER8 con _HTM_ se comercializan desde 2014.

Los sistemas _HTM_ de las tres arquitecturas son similares (_RTM_ en Intel), implementan transacciones implícitas y ofrecen instrucciones casi idénticas:

- Intel: +xbegin+, +xend+, +xabort+, +xtest+.
- PowerPC: +tbegin+, +tend+, +tabort+, +tcheck+.
- S390: +tbegin+, +tend+, +tabort+, +etnd+.

////
[cols="h,m,m,m", options="header"]
|===
|           | Intel     | PowerPC   | S390
| _begin_   | xbegin    | tbegin    | tbegin
| _commit_  | xend      | tend      | tend
| _abort_   | xabort    | tabort    | tabort
| _check_   | xtest     | tcheck    | etnd
|===
////

Desde la versión 4.8 _libitm_ detecta y usa automáticamente las extensiones de _HTM_ de hardware de Intel. Gracias a las similitudes, desde la versión 4.9 también soporta a los procesadores PowerPC e IBM S390. Si _libitm_ detecta soporte de hardware primero intenta la transacción por hardware (el _fastpath_) y si el procesador aborta la transacción la resuelve por software.


==== Detección de conflictos

Para detectar conflictos el procesador debe mantener el conjunto de posiciones de memoria leídas (_read-set_) y modificadas (_write-set_). Con los protocolos modernos de coherencia de caché no es complicado. Cada línea accedida durante una transacción es marcada como _exclusiva_ por el procesador, si además se escribe en ella es etiquetada como _modificada_.

La implementación por hardware tiene limitaciones e impone restricciones. A diferencia de las librerías _STM_ que pueden implementar transacciones de objetos, en hardware solo es posible con bytes y palabras. La cantidad máxima de memoria accedida durante una transacción está limitada por el tamaño de la caché, si el de los datos lo supera la transacción se abortará. La granularidad de la detección de conflictos es de una línea de caché por lo que puede sufrir problemas de <<false_sharing, _false sharing_>>. Es decir, se abortará la transacción si desde otro procesador se modifica una posición diferente pero que comparte línea de caché.

Las transacciones se abortan apenas se detectan conflictos en la caché, por eso los sistemas de hardware son de _detección temprana_. El _rollback_ de una transacción tampoco es un gran problema, desde hace años los procesadores usan mecanismos de actualización retrasada. Para transacciones se pueden usar dos:

- Las líneas de caché modificadas se ponen en modo _write-back_ y no se vuelcan a memoria RAM a menos que la transacción finalice, en caso contrario se marcan como inválidas todas las líneas escritas.

- Se usa _renombrado de registros_. Los procesadores tienen más registros físicos de los usados por los programas, sus _nombres_ son dinámicos (se usan mecanismos de _hashing_). En estos casos los registros usados durante la transacción simplemente se descartan.

Las transacciones también pueden ser abortadas si ocurren cambios de contexto, interrupciones del procesador, llamadas a operaciones de E/S. Para ayudar al software a detectar la razón del aborto devuelven un valor en un registro. Este indica las posibles causas, por ejemplo: error temporal (se puede reintentar), señales, pausa, interrupción, fallo de página, etc.

=== Programación con Intel TSX

_TSX_ es el nombre de las extensiones _HTM_ de Intel para su arquitectura Haswell. Incluye dos interfaces con mecanismos diferentes:

- _Restricted Transactional Memory_ o _RTM_.
- _Hardware Lock Elision_ o _HLE_.

_TSX_ usa la caché L1 de cada núcleo y el protocolo <<mesi_protocol, _MESI_>> para detectar conflictos. La caché L1 tiene 512 líneas y es _8-way_ (8 x 64) con 32 KB en total, pero es compartida en los núcleos con _hyperthreading_ por lo que la capacidad se reduce a la mitad. Cada línea tiene un bit adicional, _T_, para marcar las líneas que contienen direcciones que son parte del conjunto de la transacción activa.

Cuando se lee una variable dentro de una transacción se pone en uno el bit _T_ de su línea de caché y es marcada como _exclusiva_ (ahora está en el _read-set_). Si la variable se modifica se marca su línea de caché como _modificada_ (ahora está en el _write-set_). Si se llega al final de la transacción sin conflictos se ponen los bits _T_ en cero por lo que todas las líneas modificadas son visibles a los demás procesadores.

Si _CPU0_ está en una transacción y desde _CPU1_ se intenta acceder a la misma dirección que una variable de la transacción, el protocolo MESI notificará a la _CPU0_ inmediatamente. Si esa línea de caché está marcada como _modificada_ se aborta la transacción: invalida las líneas involucradas y pone sus bit _T_ en 0. _CPU1_ leerá el valor sin modificar en la memoria RAM. Lo mismo ocurre si _CPU1_ intenta escribir en una dirección que está en el _read-set_ de _CPU0_ (es decir, con _T_ en uno pero sin estar marcada como _modificada_).

La solución es técnicamente simple, eficiente y está integrada en el sistema de caché, pero una transacción que está a punto de finalizar puede ser forzada a abortar por acceso de otra que acaba de comenzar. O incluso por lecturas de variables modificadas desde otras CPU que no están en una transacción.


==== _Hardware Lock Elision_

_HLE_ está basado en el trabajo de Ravi Rajwar y James R. Goodman publicado en 2001 (<<Rajwar>>)footnote:[Posteriormente Intel contrató a Ravi Rajwar.]. La idea es creativa y permite que programas compilados para _HLE_ funcionen en procesadores antiguos o sin soporte de _HTM_.

Los _mutex_ con _spinlocks_ tradicionales, por ejemplo con <<get_and_set_alg, _get&set_>>, tienen el siguiente aspecto:

----
movl    $1, %eax
xchgl	mutex(%rip), %eax   <1>
...
movl    $0, mutex(%rip)     <2>
----
<1> Hace el intercambio con +mutex+, lo pone en 1.
<2> Libera el _mutex_.

_HLE_ provee dos prefijos nuevos, +xaquire+ y +xrelease+. Estos se añaden a las instrucciones de entrada a la sección crítica (+xchgl+ en este caso) y en la salida, como en el siguiente código:

----
movl    $1, %eax
xacquire xchgl  mutex(%rip), %eax
...
movl    $0, %eax
xrelease movl   %eax, mutex(%rip)
----

Cuando el procesador encuentra la operación +xchgl+ con el prefijo +xacquire+ elidefootnote:[Es la traducción de _elision_, un verbo válido en castellano, se dice así a la supresión de vocales o de palabras completas.] la asignación y ejecuta el resto de las instrucciones como una transacción hasta que encuentra +xrelease+. Si detecta conflicto vuelve a ejecutar desde el +xacquire+ pero esta vez sí ejecuta la instrucción +xchgl+.

GCC permite especificar _spinlocks_ con los prefijos _HLE_ con la opción `__ATOMIC_HLE_ACQUIRE` en sus macros atómicos. El código simplificado para el _lock_ y _unlock_ es el siguiente (<<tm_mutex_hle_c, código completo>>):

----
void lock() {
    while(exchange_n(&mutex, 1, __ATOMIC_HLE_ACQUIRE));
}

void unlock() {
     store_n(&mutex, 0, __ATOMIC_HLE_RELEASE);
}
----

Los _opcodes_ de ambos prefijos son los mismos que +repne+ y +repe+ y son ignorados por los procesadores sin soporte _HLE_.

==== _Restricted Transactional Memory_

Se denomina _restringida_ porque no están permitidas todas las instrucciones. Algunas causan el aborto de la transacción: +cpuid+, +pause+, operaciones de punto flotante, MMX, instrucciones que causan cambios de privilegios, etc.

_RTM_ tiene tres funciones fundamentales, +xbegin+ para comenzar la transacción, +xabort+ para abortarla explícitamente y +xend+ para el _commit_. No se asegura _progreso_ (las transacciones podrían abortar siempre) por lo que no puede ser llamada indefinidamente dentro de un bucle, hay que proveer un camino alternativo. Este suele ser la llamada a un _spinlock_ o _mutex_.

El patrón de programación con un _spinlock_ para exclusión mutua es el siguiente (se usan los _intrinsics_ de Intel para GCC):

[source, c]
----
if (_xbegin() == _XBEGIN_STARTED) { <1>
    if (mutex) {
        _xabort(0xff);              <2>
    }
    /* critical section */
    _xend();                        <3>
} else {
    lock();                         <4>
    /* critical section */
    unlock();
}
----
<1> Se verifica si la transacción fue iniciada y finalizó sin conflictos.
<2> Agrega +mutex+ al _read-set_ de la transacción (abortará si se modifica desde otra CPU) y verifica su valor. Si es diferente a cero hay otro proceso en la sección crítica por lo que se aborta inmediatamente.
<3> Hace el _commit_.
<4> Si la transacción fue abortada se usa el camino alternativo con el _spinlock_.

Por claridad, para no repetir código y mantener el mismo estándar de llamadas de secciones críticas se pueden separar en funciones equivalentes a _lock_ y _unlock_. El siguiente es el ejemplo típico:

[source, c]
----
void rtm_lock() {
    if (_xbegin() == _XBEGIN_STARTED) {
        if (! mutex) return;    <1>
        _xabort(0xff);
    }
    lock();                     <2>
}

void rtm_unlock() {
    if (! mutex)
        _xend();
    else
        unlock();               <3>
}
----
<1> Si +mutex+ está en cero puede continuar con la transacción.
<2> Se usará el _spinlock_ porque la transacción fue abortada.
<3> Si +mutex+ es diferente a cero se usó el _spinlock_, hay que liberarlo.


===== Efecto convoy

Aunque el patrón anterior aparece en todos los ejemplos de _RTM_, tiene serios problemas de eficiencia: reproduce y agrava el efecto convoy de los _spinlocks_. Si una transacción aborta en condiciones de alta competencia se produce un efecto cascada que hace fallar a las siguientes.

La probabilidad de que una transacción falle no es baja, siempre ocurrirá en un bucle con mucha competencia, incluso por fallos espurios o insuficiencia temporal de memoria caché. Cuando la transacción se aborta se ejecuta el _spinlock_ sobre +mutex+, las siguientes también abortarán porque +mutex+ no es cero y se acumularán en la cola de procesos del _spinlock_.

Para evitar este efecto hay que reintentar la transacción un número limitado de veces si es factible que pueda acabar sin conflictos. El procesador indica la razón del fallo, incluso da pistas de si vale la pena reintentar (con el código +_XABORT_RETRY+), se puede usar su valor para decidir reintentar la transacción o tomar el camino alternativo.

El siguiente es el código simplificado de cómo queda la función +rtm_lock+ (<<tm_mutex_rtm_c, código completo>>):

[source, c]
----
int c = 0, st = 0;

while (c < 10 && CAN_TRY) {
    if ((st = _xbegin()) == _XBEGIN_STARTED) {
        if (! mutex) return;
        _xabort(0xff);
    }
    c++;
}
lock();
----

Se reintenta la transacción hasta diez veces si se cumple alguna de las siguientes condiciones:

- el valor del estado (+st+) indica que puede reintentarse (`status & _XABORT_RETRY`);
- si se abortó explícitamente por el valor de +mutex+ (`_XABORT_CODE(status) > 0`)
- o si el código de error es 0.


En el siguiente gráfico se puede observar una comparación de tiempos de CPU y retorno del algoritmo de lectores-escritores con _spinlock_, _RTM_ simple y _RTM_ con reintentos (<<tm_rw_rtm_c, código fuente>>) de la transacción.

.Lectores-escritores con y sin reintentos de la transacción
[caption=""]
image::tm_retry.png[align="center"]

La diferencia de tiempos de CPU y retorno son considerables. Para aprovechar la eficiencia de _HTM_ hay que ser muy cuidadosos y analizar las razones del fallo para tomar la decisión de reintentar o pasar a la alternativa de sección crítica.



////

ELIMINADO, JUST TOO MUCH

=== Criterios de corrección _correctness_

- Secuencialidad (Serializability):  Las transaccciones deben ser secuenciables, los resultados deben ser idénticos a si se ejecutan en una secuencia. No requiere que se ejecuten en un orden de tiempo real estricto, pueden intercambiarse el orden.

- Secuencialidad estricta: Si una transacción se completa antes que otra su ejecución secuencial debe ocurrir en el mismo orden.

- Linearizabilidad (Linearizability): La operación de lecturas y escritura de toda la transacción debe aparecer en un momento puntual.

- Instantáneas aisladas (Snapshot isolation): Es más débil que linearizabilidad, permite mayor concurrencia. Las lecturas debe ser linearizables antes que las escrituras.

////



=== Comparación de tiempos

Como en capítulos anteriores, a continuación se muestran un par de comparaciones de tiempos de las técnicas que acabamos de ver. No pretenden ser científicamente rigurosos ni referencia de rendimiento, solo dar una idea de las ventajas de eficiencia que se asegura en la bibliografía en general y en este capítulo en particular.

Para los interesados en comparaciones de rendimiento existe un estándar: _Stanford Transactional Application for MultiProcessing_ (_STAMP_, <<Minh>>). STAMP es un conjunto de programas especialmente diseñados para evaluación y medición de aplicaciones con memoria transaccional.

==== Lectores-escritores
Los algoritmos de lectores-escritores tienen pre y posprotocolos diferentes dependiendo de si el proceso modifica o solo lee registros compartidos. Los programas tienen la siguiente forma:

[source, c]
----
void reader() {
    reader_lock();
    c = counter;
    reader_unlock();
}

void writer() {
    writer_lock();
    counter++;
    writer_unlock();
}
----

Con transacciones no hacen falta protocolos diferentes, basta con indicar que son parte de una transacción y el sistema detectará los conflictos adecuadamente.

[source, c]
----
void reader() {
    transaction {
        c = counter;
    }
}

void writer() {
    transaction {
        counter++;
    }
}
----

Con memoria transaccional debería apreciarse una reducción importante de tiempo comparado con exclusión mutua. El siguiente gráfico muestra los tiempos de retorno (en segundos) de diferentes mecanismos en dos procesadores diferentes, un i5 sin soporte de hardware y en un Xeon con _TSX_.

.Tiempos de ejecución lectores-escritores
[caption=""]
image::tm_rw.png[align="center"]


Las dos barras de la izquierda muestran los tiempos del _spinlock_ básicos como referencia para los demás algoritmos.

Las siguientes son los tiempos con transacciones de software de la librería _tinySTM_ (<<tm_rw_tinystm_c, código fuente>>). En ambos procesadores la reducción de tiempo es importante aún con la sobrecarga de llamadas a funciones.

A continuación con el bloque atómico de GCC (<<tm_rw_transaction_c, código fuente>>) que usa _libitm_. En Xeon se usa el soporte de hardware, en i5 es solo por software. _Libitm_ no es tan eficiente como _tinySTM_ pero la reducción de tiempo sigue siendo importante.

Las dos últimas barras de la derecha son los tiempos de _HLE_ (<<tm_rw_hle_c, código fuente>>) y RTM (<<tm_rw_rtm_c, código fuente>>), solo disponibles en Xeon. _RTM_ dio los mejores tiempos, los de _HLE_ son similares a los del _spinlock_.

En este caso –y en este modelo de procesador– _HLE_ tiene dos problemas:

- Las lecturas de +counter+ generan más transacciones fallidas. Aproximadamente el 50 % de las transacciones se abortan, con _RTM_ no llegan al 0,03 %. Si se elimina la lectura de +counter+ el número de fallos se reduce a aproximadamente 33 %, una tasa todavía elevada.

- Se produce el efecto convoy, al tener un porcentaje elevado de fallos hace que las demás transacciones también fallen porque se modifica el valor de +mutex+.


////
.Tiempos de ejecución STM Intel i5
[caption=""]
image::tm_software.png[align="center"]
////

==== _Mutex_ con estructuras complejas

Otra ventaja de la memoria transaccional es que el programador no se debe preocupar de las granularidades menores en estructuras complejas de datos porque son _detectadas_ automáticamente por el sistema de memoria transaccional. En el siguiente gráfico se muestran los tiempos de incrementos concurrentes a diferentes posiciones de un array de enteros. Como se modifican direcciones diferentes es una simulación simplificada del comportamiento con tablas de _hashing_ y en menor grado de árboles y grafosfootnote:[Los árboles y grafos tienen estructuras más complejas basadas en punteros y asignación dinámica de memoria, sus direcciones son más lejanas por lo que se producen menos _false sharing_.].

Se toman diferentes tamaños desde un array de tamaño 1 (que es equivalente al contador de los ejemplos de este libro) a 4096. Cada proceso incrementa diferentes posiciones que varían uniformemente. Las pruebas fueron hechas sobre un Xeon con soporte _HTM_. El grupo de barras desde la izquierda son idénticas al gráfico anterior, cada barra representa diferentes tamaños del array: 1, 64, 1024 y 4096 posiciones.

.Tiempos de ejecución HTM Intel Xeon
[caption=""]
image::tm_hardware.png[align="center"]

Todos los métodos de memoria transaccional se comportan peor que el _spinlock_ con tamaño uno (equivalente a modificar una única variable). A partir de allí todos mejoran, como era de esperar. El que mejor tiempo es de _RTM_, le siguen el de bloques atómicos del GCC con _libitm_ (usa el soporte de hardware), luego _HLE_ y finalmente _tinySTM_ (es la única que funciona solo por software).

=== Recapitulación

Hay consenso en que las herramientas y mecanismos tradicionales no sirven para un previsible futuro de expansión de las arquitecturas multiprocesadores y programación concurrente y paralela. Por ello el área de investigación en memoria transaccional está muy activa.

El problema es cómo compatibilizar las nuevas aplicaciones con código existente, las transacciones deben coexistir con código no transaccional durante muchos años. Los diseñadores de lenguajes deben implementar nuevas construcciones sintácticas y definir con precisión su semántica (como el tratamiento de excepciones y señales).

Uno de los objetivos es mejorar el rendimiento de las aplicaciones, por lo que la eficiencia juega un papel importante. Los sistemas _STM_ no pueden alcanzar la eficiencia que se puede alcanzar por hardware pero son más maleables y permiten experimentar con algoritmos más complejos.

Por otro lado los fabricantes de procesadores tienen limitaciones en cuanto a los algoritmos que pueden implementar, estos además deben ser validados y probados extensivamente antes de lanzar la producción masiva: no se puede cambiar la arquitectura y crear dependencias y problemas de compatibilidad en el futuro. Esto hace que cuando los procesadores salen al mercado ya son casi obsoletos.

Los procesadores con soporte _HTM_ son todavía jóvenes y una parte pequeña del total, queda por ver cuánto aportan a la eficiencia de las aplicaciones de uso real. De todas formas, hace solo tres años no había procesadores con soporte _HTM_ en el mercado, ahora ya hay tres arquitecturas que seguramente mejorarán mucho en eficiencia en los próximos años.

Es probable que se opte por soluciones híbridas y que los compiladores y librerías _runtime_ sean los responsables de ocultar detalles y asegurar compatibilidad. La librería _libitm_ integrada en GCC es todavía muy joven –con mucho por mejorar– pero ya se aprecian las ventajas de código instrumentado por el compilador que además es capaz de aprovechar el soporte de hardware.
