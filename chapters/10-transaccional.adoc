[[tm]]
== 10. Memoria transaccional

image::jrmora/10-transaccional.jpg[align="center"]

Como la exclusión mutua, la memoria transaccional es un mecanismo de control de concurrencia. Sus objetivos son simplificar la programación y aumentar el paralelismo de los programas cocurrentes. Para acceder a registros compartidos se usa el mismo concepto de _transacción_ conocida desde hace tiempo en las bases de datos ACID. Desde el punto de vista del programador las transacciones se ejecutan secuencialmente y aisladas unas de otras, las complejidades del control de concurrencia quedan ocultos al programador.

Las transacciones están íntimamente relacionadas con la exclusión mutua. En capítulos anteriores estudiamos los dos tipos de mecanismos para resolverla: los _spinlocks_ con primitivas atómicas y las soluciones bloqueantes. Pero ambos tienen problemas: limitaciones importantes como soporte a la programación concurrente cada vez más relevante y de eficiencia para la ejecucion en paralelo en sistemas _SMP_.

=== Los problemas de secciones críticas y _locks_

- La exclusión mutua reduce el nivel de paralelismo, las secciones críticas deben ser ejecutadas secuencialmente por lo que se reduce al capacidad de ejecutar hilos en paralelo.

- Para evitar los cuellos de botella de las secciones críticas se implementan _estructuras concurrentes_ (_lock-free structures_) con instrucciones atomicas. Pero estas primitivas solo trabajan con una palabra, por lo que requieren algoritmos más complejos cuando se deben trabajar con registros de mayor tamaño. Hay algunos temas académicamente todavia no resueltos eficientemente, como las lista de doble entrada con posibilidad de añadir o extraer por ambos extremos.

- Los _spinlocks_ para exclusión mutua producen inversión de prioridades y _efecto convoy_ cuando un proceso es interrumpido por haber acabado su _cuanto_. La inversión de prioridades ocurre cuando otros procesos de mayor prioridad no puedan entrar a la sección crítica. El efecto convoy cuando los procesos en espera se acumulan, aún después de que el proceso interrumpido haya liberado el _lock_ toma un tiempo vaciar la cola de procesos en espera.

- Los interbloqueos son difíciles de evitar si se manipulan muchos objetos. Aunque hay técnicas y reglas conocidas (<<deadlocks>>), con el incremento del número y tamaño de los programas concurrentes el modelo ya no es sustentable (<<Herlihy12>>).

- Los algoritmos de exclusión mutua y basados en primitivas no son _componibles_. Los  algoritmos de _spinlocks_ son complejos por la dificultad de componer llamadas a múltiples objetos en unidades atómicas, pero no se pueden componer. En <<free_lock_stack>> vimos como implementar una pila sin exclusión mutua, pero no se puede eliminar el elemento de una e insertarla en otra atómicamente. Se pueden agregar mecanismos _ad hoc_, como una  exclusión mutua adicional pero crea otro cuello de botella.

- Son difíciles de gestionar efectivamente, especialmente para la gestión de estructuras complejas o de grandes sistemas. Si se desea más eficiencia y paralelismo hay que trabajar con granularidades muy pequeñas. Se usan _mutex_ o _spinlocks_ globales para gestionar estructuras complejas (como _hashing_ o árboles balanceados) por la complicación de trabajar a granularidades más detalladas: no se puede saber de antemano qué ramas del árbol o qué partes de la tabla se modificarán. Lo que desea el programador es indicar cuál es la sección crítica y que el sistema se encargue de controlar la granularidad.

Todo parece indicar que en el futuro se incrementará el número de núcleos y procesadores y por consiguiente se producirá un crecimiento del número y tamaño de programas concurrentes. Hay un consenso académico y en la industria de que los modelos actuales de exclusión mutua tienen demasiadas limitaciones.

Durante los últimos años se produjo un aumento notable de publicaciones científicas y desarrollos de sistemas de memorias transaccionales.


=== Veinte años de historia

Los sistemas de memoria transaccional todavía están en su infancia. La primera propuesta para usar la idea de transacciones fue de David Lomet en 1977 (<<Lomet>>) pero no propuso ninguna solución práctica competitiva con los mecanismos de sincronización explícitos (<<Harris>>). La idea cayó en el olvido durante quince años.

En 1993 Maurice Herlihy y Eliot Moss (<<Herlihy93>>) propusieron soluciones de soporte de hardware de transacciones para superar las limitaciones de los _spinlocks_, principalmente la inversión de prioridaddes, _efecto convoy_ y los interbloqueos. El mismo año, Janice Stone _et al_ (<<Stone>>) propusieron primitivas de hardware atómicas _multi-palabra_ conocidas como _Oklahoma Update_. La propuesta está basada en la misma idea de LL/SC (<<llsc>>) pero permite reservar más de una palabra.

En 1995 Nir Shavit y Dan Touitou (<<Shavit>>) propusieron y demostraron por primera vez el uso práctico de memoria transaccional por software (_STM_). En 2006, Nir Shavit, Dave Dice y Ori Shalev presentaron el algoritmo _Transaction Locking 2_ (_TL2_, <<Dice>>). TL2 sirvió de base para varias librerías de memoria transaccional, entre ellas a TinySMT (<<Felber>>). TinySTM es una de las librerías _STM_ más populares y eficientesfootnote:[Uno de sus autores, Torvald Riegel, es también responsable de las librerías _libitm_ que usa GCC.].

En los últimos años se ha producido un avance notable en sistemas de memoria transaccional por hardware y software. En 2009 Sun presentó las primeras evaluaciones de la memoria transaccional por hardware (_HTM_) del unidades de preproducción de su procesador UltraSPARC Rock. Los procesadores del supercomputador BleeGene incluyeron soporte _HTM_ en 2011. Entre 2012 y 2013 Intel (Haswell) e IBM (con PowerPC y S390) presentaron sus procesadores con _HTM_.

El desarrollo de nuevos algoritmos y la compilación optimizada de los compiladores hace que tenga sentido usar memoria transaccional aún sin soporte de hardware. Además de las librerías _STM_ se está acabando con la definición de la definición del estándar para C y C++ de memoria transaccional (<<Tabatabai>>). El compilador GCC incluye soporte para memoria transaccional de software desde la versión 4.7 y soporte de hardware para procesadores Intel, PowerPC y S390 de la versión 4.8 (<<TransactionGCC>>). Los _mutex_ de las librerías POSIX Threads ya usan el soporte de hardware desde la versión Glibc 2.18 (<<Kleen>>). Desarrolladores del núcleo Linux empezaron a desarrollar soporte de memoria transaccional por hardware desde 2013.


[NOTE]
.Transacciones de bases de datos
====
Las bases de datos son capaces de trabajar concurrentemente y en paralelo desde hace años, ejecutan varias consultas simultáneamente siempre es posible. Obtienen esta eficiencia con un modelo que evita que el programador deba preocuparse de la concurrencia. El corazón del sistema es la transacción, esta especifica una semántica de secuencia de operaciones –una composición– como si fuese el único proceso accediendo a la base de datos.

Las operaciones dentro de transacciones se ejecutan en concurrentemente y en paralelo con otras operaciones, pero las interacciones limitadas de forma que los resultados no varían si se ejecutaron una después de otra. Esta propiedad del modelo se llama _secuencialidad_ (_serializability_) y facilita el trabajo al programador habituado a la programación secuencial.

Las bases de datos tienen las propiedades ACID por _atomicidad_, _consistencia_, _aislamiento_ (_isolation_) y _durabilidad_.

- Atomicidad significa que el conjunto de operaciones de una transacción se completan todas o ninguna. Si se _rechaza_ una ejecución no debe dejar rastros de los cambios que se hizo _tentativamente_. Cuando una transacción acaba correctamente se hace el _commit_ haciendo visible los cambios, caso contrario la transacción de _aborta_.

- Consistencia significa que los datos pasan de un estado consistente a otro. Se respetan los invariantes, por ejemplo, el resultado de una transferencia bancaria que generó un ingreso en una cuenta también incluye la extracción desde otra.

- Aislamiento implica que no hay interferencias entre transacciones. Los cambios realizados por las operaciones de una transacción no son visibles no afectan al resultado de otras en curso.

- Durabilidad asegura que si una transacción acaba correctamente (con _commit_) sus datos están almacenados en el dispositivo de almacenamiento persistente.
====


=== Transacciones
Como en bases de datos ACID, una transacción son una serie de pasos ejecutados por un único proceso. Las transacciones concurrentes deben ser _secuenciables_, desde el punto de vista del programador parecen ejecutarse secuencialmente. El resultado de la ejecución de dos transacciones concurrentes es equivalente a una ejecución secuencial entre ellas.

Mientras los _mutex_ y _spinlocks_ son pesismistas, las transacciones son optimistas y pueden ser ejecutadas en paralelo. Las transacciones son ejecutadas especulativamente, hace cambios _tentativos_ a objetos, si acaban sin conflictos se hace el _commit_ definitivo de los cambios que se hacen visibles a los demás procesos.

Si se detecta un conflicto en los datos la transacción se aborta y no quedan rastros de las modificaciones _tentativas_ que se hicieron a las variables compartidas.

==== Ventajas

Granularidad:: Las transacciones detectan y resuelven con granularidades más pequeñas. Se pueden recorrer estructuras complejas (árboles, grafos, tablas de _hashing_, etc.) o manipular muchos objetos sin que el programador deba preocuparse de optimizar la exclusión mutua. Basta que especifique las transacciones a niveles más elevados, las transacciones se ejecutarán en paralelo y se detectarán los conflictos con granularidades pequeñas.

Composición:: Las construcciones con transacciones pueden componerse para hacer atómicas un conjunto de operaciones independientes. Por ejemplo eliminar elementos de una estructura y añadirlas a otras. Las diferentes operaciones se incluyen dentro de una misma transacción. Estas operaciones eran imposibles con _spinlocks_ sin mecanismos adicionales y más complejos o costosos (como agregar otro _spinlock_).

No producen interbloqueos:: Salvo casos extremos, como esperas activas dentro de una transacción, no producen interbloqueo. Sus composiciones tampoco.

Mayor paralelismo:: La no necesitar exclusión mutua todos los procesos pueden ejecutarse en paralelo en diferemtes procesadores.


Pero las transacciones no son un panacea, los programadores aún pueden provocar  interbloqueos o definir transacciones imposibles de finalizar sin conflictos.
O incluso olvidarse de hacer el _commit_ de una transacción. Para evitar este tipo de errores se especificaron contrucciones sintácticas como los _bloques atómicos_.


==== Funciones y bloques atómicos

Las operaciones básicas para gestión de transacciones:

- Iniciar transacción, +StartTx+.
- Confirmar la transacción (_commit_), +CommitTx+.
- Abortar la transacción actual, +AbortTX+.

Y para acceso a datos:

- Leer, +Type ReadTx(Type *address)+.
- Escribir, +WriteTx(Type *address, Type value)+.

Así una transacción simple para la operación sobre el contador de los ejemplos esfootnote:[Los nombres de las funciones son genéricos, uso los mismos que se suelen encontrar en la bibliografía.]:

[source, c]
----
StartTX();
c = LoadTX(&counter);
c += 1;
StoreTX(&counter, c);
CommitTx();
----

Este tipo de construcciones se denominan _transacciones explícitas_. Pero los compiladores pueden ofrecer construcciones de uso más simple para el programador, los _bloques atómicos_:

[source, c]
----
transaction {
    counter += 1;
}
----

En este caso se mejora la calidad del código y se facilita la tarea del programador. El compilador es responsable de insertar las llamadas a las funciones de memoria transaccional (_instrumentación_). El bloque atómico es equivalente a las siguientes funciones explícitas:

[source, c]
----
do {
    StartTx();
    ...
} while (!CommitTx());
----

[NOTE]
====
La construcción con +transaction+ es similar a +synchronized+ en Java o a +atomic+ en C++. Pero mientras estas últimas introducen un _mutex_ que se aplica a otros métodos de la misma instancia, `transaction` es global y permite la ejecución concurrente.
====


Algunos compiladores ya incluyen construcciones sintácticas de bloques, el compilador _Intel C\++ STM Compiler_ (<<IntelSTM>>) y GCC. Para C/C\++ se está trabajando en el borrador de la especificación (<<Tabatabai>>), permitirá dos tipos de transacciones: relajadas  y más estrictasfootnote:[`__transaction_relaxed` y  `__transaction_atomic` respectivamente.].

==== Bloques atómicos con GCC

Desde la versión 4.7 GCC (2011) permite especificar bloques atómicos con semántica similar a la del borrador de C/C++ (<<TransactionGCC>>). El siguiente ejemplo es la implementación del contador con memoria transaccional (<<tm_mutex_gcc_c, código completo>>)footnote:[Puede usarse también `__transaction_relaxed`, pero con gcc 4.9 no encontré diferencia en el código ensamblador generado.]:

[source, c]
._Mutex_ con GCC
----
for (i=0; i < max; i++) {
    __transaction_atomic {
        counter++;
    }
}
----


==== Gestión de versiones

Los sistemas de memoria transaccional deben gestionar las escrituras tentativas que se hacen en las transacciones, la _gestión de versiones_. Hay dos modelos:

- Actualizacón directa (o _eager version management_): se modifica directamente en la dirección de memoria original y se mantiene un _undo-log_ para restaurar los valores si la transacción es abortada. Este modelo requiere el control de concurrencia pesimista.

- Actualización retrasada (_lazy version management_ o _deferred update_): las actualizaciones se hacen al momento del commit. Las transacciones mantienen un _redo-log_  privado. El _redo-log_ puede ubicarse una copia en memoria, _buffers_ de escritura, líneas de caché de acceso exclusivo, o en registros adicionales (_renamed registers_).

==== Control de concurrencia

Cada transacción mantiene un conjunto de registros _leídos_ (_read-set_) y _escritos_ (_write-set_) que son usados para detectar y solucionar los conflictos. Se diferencian tres eventos:

1. Ocurrencia: Ocurre un conflicto cuando dos transacciones hacen operaciones conflictivas sobre las mismas regiones de datos, por ejemplo dos escrituras.

2. Detección: El conflicto es detectado cuando el sistema de memoria transaccional determina que hay un conflicto.

3. Resolución: El conflicto se resuelve cando el sistema de memoria transaccional toma una acción para evitar el conflicto. Puede abortar o retrasar una de las transacciones.

Los tres eventos pueden ocurrir en diferentes momentos pero siempre en el mismo orden. hay dos modelos de control dependiendo del momento en que ocurre la detección:

- El _control de concurrencia pesimista_ detecta el conflicto en cuanto se produce, por lo tanto los tres eventos se producen al mismo tiempo. Cada transacción se apropia de los datos, como en una sección crítica, y las demás no pueden acceder a ellos.

- Con el _control optimista_ los eventos de detección y resolución pueden ocurrir más tarde. Este tipo de control permite que varias transacciones accedan simultáneamente a los mismos datos y por lo tanto avanzar en su ejecución simultáneamente hasta que el conflicto es detectado. Esto permite mayor libertad para la resolución, se puede abortar o retrasar a las transacciones conflictivas.

El control optimista es el más usado porque permite mayores niveles de concurrencia. Pero si la tasa de conflictos es elevada produce ejecuciones inútiles, en casos como este es mejor usar control pesimista para impedir que las transacciones sigan avanzando. También se pueden usar técnicas mixtas.

El control optimista debe considerar otras cuestiones:

- Granularidad del conflicto. Puede tratarse a nivel de palabras, objetos (tamaños superiores o estructuras más complejas) o líneas de caché (en implementaciones por hardware).

- El instante de la detección del conflicto:

    * Si se hace al acceder a los datos se denomina _detección temprana_ (_early conflict detection_).
    * El sistema puede hacer validaciones en varios instantes durante la transacción para verificar si hay conflictos.
    * Si se hace en el momento del _commit_ se denomina _detección tardía_ (_lazy conflict detection_).

- El tipo de acceso que es tratado como conflicto. Se puede hacer entre transacciones concurrentes activas (_tentativas_) o entre las activas y las ya finalizadas.





=== Memoria transaccional por software (_STM_)

Los sistemas _STM_ son implementaciones por software que pueden ejecutarse en cualquier procesador. Implican una penalización importante por el control que debe hacer en cada lectura y escritura, además de las validaciones antes de hacer el _commit_. Sin embargo los _STM_ tienen importantes ventajas

- El software es más flexible que el hardware, evoluciona más rápido y permite implementar una mayor variedad de algoritmos.

- No está limitado por las estructuras de palabras del hardware, puede implementar transacciones a nivel de objetos con estructuras más complejas.

- Naturalmente permiten las transacciones con llamadas explícitas pero son fácilmente integrables en los lenguajes. Estos pueden generar el código necesario (_instrumentación_) para las llamadas a las funciones.

Los componentes fundamentales de las librerías _STM_ son:

- Descriptor de la transacción. Es la estructura de datos que mantiene la información de estado de cada transacción.

- _Undo-log_ o _redo-log_. Depende del sistema de versiones que use el sistema debe mantener uno u otro.

- Conjuntos de registros leídos (_read-set_) y escritos (_write-set_): mantienen las direcciones que fueron leídas y escritas, normalmente acompañadas de un número de versión (que puede ser local o global).

- Estructuras comunes. Son los datos necesarios para detectar conflictos entre diferentes transacciones y hacer operaciones atómicas con sus estructuras de datos. Por ejemplo,  array de _spinlocks_ para secciones críticas internas, número de versión global, árbol de dependencias gobales, etc.


==== Llamadas explícitas

En general las librerías se programan con llamadas explícitas. Veremos el ejemplo con la librería _tinySMT_ (están incluidas en el repositorio de Github).

El procedimiento es iniciar las librerías al inicio del programa (+stm_init+) y al inicio de cada hilo que las usará (+stm_init_thread+). Se inician las transacciones con +stm_start+ y se hace el _commit_ con +stm_commit+. Los ejemplos de la librería tienen ejemplos de macros de conveniencia para facilitar la programación, usamos los de inicio (+TM_START+) y fin de transacción (+TM_COMMIT+).

Dentro de las transacciones no se deben acceder directamente a los registros u objetos compartidos, deben usar las funciones para lectura y escritura. En ese caso como se trata de un entero usamos +stm_load_int+ y +stm_store_int+.

El siguiente es el código para el contador (el <<tm_mutex_tinystm_c, código completo>>):

[source, c]
----
for (i=0; i < max; i++) {
    TM_START(0, 0);         <1>
    c = stm_load_int(&counter);
    c++;
    stm_store_int(&counter, c);
    TM_COMMIT;              <2>
}
----
<1> Un macro de conveniencia que abre un bloque, llama a stm_start y salva el contexto.
<2> Otro macro de conveniencia, llama a +stm_commit+ y cierra el bloque.



==== Instrumentación del compilador

No es práctico programar con funciones explícitas, mejor hacerlo en bloques (<<tm_mutex_gcc_c, código completo>>):

[source, c]
----
transaction {
    counter += 1;
}
----

El compilador puede hacer la _instrumentación_ del código. Consiste en detectar dónde se leen y escriben variables compartidas e insertar las llamadas a las funciones de la librería. En el ejemplo el GCC insertará el siguiente código:


[source]
----
call    _ITM_beginTransaction
...
call    _ITM_RU4    <1>
...
call    _ITM_WU4    <2>
...
call    _ITM_commitTransaction
----
<1> Función para leer +counter+, un entero de cuatro bytes.
<2> Función para escribir +counter+.


Esas funciones son parte del estándar _ABI_ (_Application Binary Interface_) _Intel® Transactional Memory Compiler and Runtime Application Binary Interface_ (<<IntelABI>>) que define las funciones de librerías _STM_. El objetivo es que un programa ejecutable pueda usar diferentes librerías seleccionadas en el momento de la ejecución. Las librerias más populares _STM_ implementan este estándar.

GCC incluye su propia librería de memoria transaccional: _libitm_. Las funciones están implementadas en las librerías _runtime_ y se cargan dinámicamente, pero puede usarse cualquier otra compatible con _ITM_.

=== Memoria transaccional por hardware (_HTM_)

Aunque _STM_ son muy flexibles tienen mucha sobrecarga, cada lectura y asignación implica llamadas a funciones que a su vez ejecutan algoritmos complejos. Puede hacerse más eficiente en el hardware, aunque está por ahora mucho más limitado que el software. hay dos tipos básicos de sistemas _HTM_:

Sistemas explícitos:: El procesador tiene instrucciones adicionales de acceso a memoria que indican que dichas direcciones deben tratarse como parte de una transacción, por ejemplo +load_transactional+ o +store_transactional+. Este tipo de sistemas da mayor libertad y flexibilidad al programador, pero requiere adaptación de todas las librerías para el cambio de las instrucciones. No es una buena solución si se desea mantener compatibilidad. Las propuestas de _Oklahoma Update_ (<<Stone>>) y _Advanced Synchronization Facility_ eran de este tipo, aunque ninguno de ellos llegó a fabricarse.

Sistemas implícitos:: Este tipo de procesador solo requiere que se indiquen los límites de la transacción, como +tbegin+ y +tend+. Todos los accesos entre ambas instrucciones son tratados como transaccionales. El primer diseño de procesador de este tipo fue Rock de Sun, cuya fabricación en serie fue cancelada. Los procesadores Intel, PowerPC y S390 implementan este mecanismos en sus procesadores lanzados recientemente.

Sistemas híbridos:: En estos sistemas el procesador implementa instrucciones para ayudar a acelerar a sistemas _STM_.


==== Intel TSX, IBM PowerPC y S390

En 2012 Intel anunció que su arquitectura Haswell incluiría _HTM_, se comercializa desde 2013 en los procesadores Xeon e i7footnote:[Podéis verificar si tiene soporte con `cat /prco/cpuinfo`, en la línea de +flags+ debería aparecer +hle+ y/o +rtm+.]. BlueGene Q/Sequoia de IBM usa _HTM_ desde 2011, los procesadores de S390 System z desde 2013 y POWER8 con HTML se comercializa desde 2014.

El sistema _HTM_ de las tres arquitecturas son muy similares (_RTM_ en Intel), son sistemas de transacciones implícitos y ofrecen instrucciones muy similares:

- Intel: +xbegin+, +xend+, +xabort+, +xtest+.
- PowerPC: +tbegin+, +tend+, +tabort+, +tcheck+.
- S390: +tbegin+, +tend+, +tabort+, +etnd+.

////
[cols="h,m,m,m", options="header"]
|===
|           | Intel     | PowerPC   | S390
| _begin_   | xbegin    | tbegin    | tbegin
| _commit_  | xend      | tend      | tend
| _abort_   | xabort    | tabort    | tabort
| _check_   | xtest     | tcheck    | etnd
|===
////

Desde la versión 4.8 _libitm_ usa las extensiones de _HTM_ de hardware de Intel. Gracias a las similitudes entre sus sistemas e instrucciones, desde la versión 4.9 también soporta a los procesadores PowerPC e IBM S390. Si detecta soporte de hardware primero intenta la transacción con el procesador (el _fastpath_), si este no pudo finalizarla la resuelve por software.


==== Detección de conflictos

Para detectar conflictos el procesador debe mantener el conjunto de posiciones de memorias leídas (_read-set_) y modificadas (_write-set_). Con las protocolos de coherencia de caché modernos no es complicado, cada línea de caché de donde se lee o se escribe una posición es marcada como exclusiva para el procesador donde se ejecuta la transacción. Este debe mantener qué líneas de caché fueron solo leídas y cuáles escritas.

La implementación por hardware tiene limitaciones e impone restricciones. A diferencia de _STM_ que puede implementar transacciones de objetos, en hardware solo con bytes y palabras. La cantidad máxima de memoria accedida durante una transacción está limitada por el tamaño de la caché, si se supera su tamaño la transacción se abortará. La granularidad de la detección de conflictos es de una línea de caché por lo que puede sufrir problemas de <<false_sharing, _false sharing_>> (se abortará la transacción si desde otro procesador se modifica una posición diferente pero que está en la misma línea de caché de una variable en la transacción).

Las transacciones se abortan en cuanto se detecten conflictos en la caché, por eso los sistemas de hardware son de _detección temprana_. El _rollback_ de una transacción no es tampoco un gran problema en procesadores modernos. Los procesadores usan actualización retrasada con dos mecanismos:

- Las líneas de caché modificadas se ponen en modo _write-back_ y no se vuelcan a memoria RAM a menos que la transacción finalice, en caso contrario sencillamente se marcan como inválidas todas las líneas escritasfootnote:[Intel no publicó detalles de su arquitectura TSX pero se sabe que usa la caché L1 de cada núcleo como _buffer privado_ y en la documentación se explica que no se puede poner la caché en modo _write-back_.].

- Se usa _renombrado de registros_. Los procesadores tienen más registros físicos de los usados por los programas, sus _nombre_ son dinámicos (se usan mecanismos de _hashing_). En estos casos los registros usados durante la transacción simplemente se descartan.

Las transacciones también pueden ser abortadas si ocurren cambios de contexto, interrupciones del procesador, llamadas a operaciones de E/S. Para ayudar al software a detectar la razón del aborto devuelven un valor en un registro, este indica posibles causas, por ejemplo: error temporal (se puede reintentar), señales, pausa, interrupción, fallo de página, etc.

=== Programación con Intel TSX

_TSX_ es el nombe de las extensiones _HTM_ de Intel para su arquitectura Haswell. Incluye dos interfaces con mecaninismos diferentes:

- _Restricted Transactional Memory_ o _RTM_.
- _Hardware Lock Elision_ o _HLE_.

_TSX_ usa la caché L1 de cada núcleo y el protocolo <<mesi_protocol, _MESI_>> para detectar conflictos. La caché L1 tiene 512 líneas y es _8-way_ (8 x 64), esta caché es compartida en las CPU con _hypethreading_ por lo que la capacidad se reduce a la mitad. Cada línea tiene un bit adicional, _T_, para marcar las líneas que contienen direcciones que son parte del conjunto de la transacción activa.

Cuando se lee una variable dentro de una transacción se pone en uno el bit _T_ de su línea de caché y se la marca como _exclusiva_, ahora está en el _read-set_. Si la variable se modifica se marca su línea de caché como _modificada_, ahora está en el _write-set_. Si la se ejecuta +xend+ se llegó al final de la transacción sin conflicto, se hace el _commit_ poniendo los bits _T_ en cero. Ahora todas la líneas modificadas son visibles a los demás procesadores.

Si CPU0 está en una transacción y desde CPU1 se intenta acceder a la misma dirección que una variable de la transacción, el protocolo MESI notificará a CPU0. Si esa línea de caché está marcada como _modificada_ CPU0 detecta el conflicto y aborta la transacción: invalida las líneas involucradas y pone sus bit _T_ en 0. CPU1 leerá el valor que sin modificar que estaba en memoria RAM. Lo mismo ocurre si CPU1 intenta escribir a una dirección que está en el _read-set_ de CPU0 (es decir, con _T_ en uno pero sin estar marcada como _modificada_).

La solución es sencilla y está integrada en el sistema de caché, pero una transacción que está a punto de finalizar puede ser forzada a abortar por acceso de otra que acaba de comenzar. O incluso por lecturas de variables modificadas desde otras CPU que no están en una transacción.


==== _Hardware Lock Elision_

_HLE_ está basado en el trabajo de Ravi Rajwarfootnote:[Posteriormente Intel contrató a Ravi Rajwar.] y James R. Goodman publicado en 2001 (<<Rajwar>>). La idea es creativa, sencilla y permite que los programas compilados para _HLE_ funcionen en procesadores antiguos.

Los _mutex_ con _spinlocks_, por ejemplo con <<get_and_set_alg, _get&set_>> tienen el siguiente aspecto:

----
movl    $1, %eax
xchgl	mutex(%rip), %eax   <1>
...
movl    $0, mutex(%rip)     <2>
----
<1> Hace el intercambio con +mutex+, lo pone en 1.
<2> Libera el _mutex_.

_HLE_ provee dos prefijos nuevos, +xaquire+ y +xrelease+. Estos prefijos se agregan a las instrucciones de entrada a la sección crítica (+xchgl+ en este caso) y en la salida, como en el siguiente código:

----
movl    $1, %eax
xacquire xchgl  mutex(%rip), %eax
...
movl    $0, %eax
xrelease movl   %eax, mutex(%rip)
----

Cuando el procesador ejecuta la primera vez la asignación a +xchgl+ y encuentre el prefijo +xacquire+ elidefootnote:[Es la traducción de _elision_, un verbo válido en castellano, se dice así a la supresión de vocales o de palabras completas.] la asignación y ejecuta como una transacción hasta el +xrelease+. Si hay conflicto vuelve a ejecutar desde el +xacquire+ pero esta vez asignando la instrucción +xchgl+.

GCC incluye la opción `__ATOMIC_HLE_ACQUIRE` para sus macros atómicos. El código simplificado para el _lock_ y _unlock_ es el siguiente (<<tm_mutex_hle_c, código completo>>):

----
void lock() {
    while(exchange_n(&mutex, 1, __ATOMIC_HLE_ACQUIRE));
}

void unlock() {
     store_n(&mutex, 0, __ATOMIC_HLE_RELEASE);
}
----

Los _opcodes_ de ambos prefijos son los mismos que +repne+ y +repe+, que son ignorados por los procesadores sin soporte _HLE_.

==== _Restricted Transactional Memory_

Se denomina _restringido_ porque no están permitidas todas las instrucciones, algunas causan el aborto de la transacción, como +cpuid+, +pause+, operaciones de punto flotante o MMX, instrucciones que causan cambios de privilegios, etc.

_RTM_ usa tres funciones, +xbegin+ para comenzar la transacción, +xabort+ para abortarla explícitamente y +xend+ para el _commit_. No se asegura _progreso_ (las transacciones podrían abortar siempre) por lo que no se puede hacer un bucle infinito, hay que proveer un camino alternativo. Este suele ser la llamada a un _spinlock_ o _mutex_ para asegurar exclusión mutua.

El patrón de programación con un _spinlock_ para exclusión mutua es el siguiente (usando los _intrinsics_ de Intel para GCC):

[source, c]
----
if (_xbegin() == _XBEGIN_STARTED) { <1>
    if (mutex) {
        _xabort(0xff);              <2>
    }
    /* critical section */
    _xend();                        <3>
} else {
    lock();                         <4>
    /* critical section */
    unlock();
}
----
<1> Se verifica si la transacción fue iniciada y finalizó sin conflictos.
<2> Agrega +mutex+ al _read-set_ de la transacción (abortará si se modifica desde otra CPU) y verifica su valor, si es diferente a cero hay otro proceso en la sección crítica por lo que se aborta inmediatamente.
<3> Hace el _commit_.
<4> Si la transacción fue abortada se usa el camino alternativo con el _spinlock_.

Por claridad, no repetir código y para mantener las mismas llamadas que para _mutex_ se pueden separar en funciones equivalentes a _lock_ y _unlock_.

[source, c]
----
void rtm_lock() {
    if (_xbegin() == _XBEGIN_STARTED) {
        if (! mutex) return;    <1>
        _xabort(0xff);
    }
    lock();                     <2>
}

void rtm_unlock() {
    if (! mutex)
        _xend();
    else
        unlock();               <3>
}
----
<1> Si +mutex+ está en cero puede continuar con la transacción.
<2> Se usará el _spinlock_ porque la transacción fue abortada.
<3> Si +mutex+ es diferente a cero se usó el _spinlock_, hay que liberarlo.


===== Efecto convoy

Aunque el patrón anterior aparece en todos los ejemplos de uso de _RTM_ tiene serios problemas de eficiencia. Reproduce el efecto convoy de los _spinlocks_.

La probabilidad de que una transacción falle no es baja, ocurrirá siempre en un bucle con mucha competencia. Incluso por fallos espurios o insuficiencia temporal de memoria caché. Cuando eso ocurre se ejecuta la entrada con _spinlock_, las siguientes transacciones también abortarán porque +mutex+ no es cero y se acumulará la cola de procesos que abortaron sus transacciones.

Para evitar este efecto hay que verificar el código de error de la transacción y reintentarla un número limitado de veces. El procesador indica la razón del fallo, incluso da pistas de si vale la pena reintentar (con el código +_XABORT_RETRY+).

El siguiente es el código simplificado de cómo queda la función de entrada con _RTM_:

[source, c]
----
void rtm_lock() {
    int c = 0, st = 0;

    while (c < 10 && CAN_TRY) {
        if ((st = _xbegin()) == _XBEGIN_STARTED) {
            if (! mutex) return;
            _xabort(0xff);
        }
        c++;
    }
    lock();
}
----

En el <<tm_mutex_rtm_c, código de ejemplo>> se puede ver el código completo. Se reintenta la transacción hasta 10 veces si el valor del estado (+st+) indica que puede reintentarse, si se abortó explícitamente por el valor de +mutex+ o si el código de error es 0.


En el siguiente gráfico se puede observar una comparación de tiempos de CPU y retorno del algoritmo de lectores-escritores con _spinlock_, _RTM_ simple y _RTM_ con reintentos (<<tm_rw_rtm_c, código fuente>>) de la transacción.

.Lectores-escritores con y sin reintentos de la transacción
[caption=""]
image::tm_retry.png[align="center"]

La diferencia de tiempos de CPU y retorno son considerables. Para aprovechar la eficiencia de _HTM_ hay que ser muy cuidadoso. Las transacciones pueden abortar por muchos motivos además de conflictos de datos, hay que verificar cuál fue la razón para tomar la decisión de reintentar o pasar a la alternativa de _spinlocks_ o _mutex_.



////
En paralelismo no hay mecanismos de abstracción y composición. Composición es la capacidad de juntar dos entidades para forma una más compleja.
////




==== Composición

Mover un objeto de una cola a otra de forma atómica es imposible con monitores, sin embargo es trivial con transacciones.

atomic {
    x = q0.deq();
    q1.enq(x);
}


----
void push(node **head, node *e) {
    __transaction_atomic {
        e->next = *head;
        *head = e;
    }
}

node *pop(node **head) {
    node *old_head;

    __transaction_atomic {
        old_head = *head;
        if (old_head) {
            *head = old_head->next;
        }
    }
    return old_head;
}
----





////

=== Criterios de corrección _correctness_

- Secuencialidad (Serializability):  Las transaccciones deben ser secuenciables, los resultados deben ser idénticos a si se ejecutan en una secuencia. No requiere que se ejecuten en un orden de tiempo real estricto, pueden intercambiarse el orden.

- Secuencialidad estricta: Si una transacción se completa antes que otra su ejecución secuencial debe ocurrir en el mismo orden.

- Linearizabilidad (Linearizability): La operación de lecturas y escritura de toda la transacción debe aparecer en un momento puntual.

- Instantáneas aisladas (Snapshot isolation): Es más débil que linearizabilidad, permite mayor concurrencia. Las lecturas debe ser linearizables antes que las escrituras.




Limitaciones de los bloques:
Problema del deadlock como en barreras

volatile bool flagA = false;
volatile bool flagB = false;
// Thread 1 // Thread 2
atomic {
    while (!flagA); // 1.1 flagA = true;
    flagB = true; // 1.2 while (!flagB);
}

Single-Lock Atomicity (SLA) for Atomic Blocks

Los problemas de llamadas de sistemas, E/S y transacciones externas



Singh developed a library of join patterns using atomic blocks in STM-Haskell [294].T

////







=== Tiempos

.Tiempos de ejecución lectores-escritores
[caption=""]
image::tm_rw.png[align="center"]


.Tiempos de ejecución STM Intel i5
[caption=""]
image::tm_software.png[align="center"]


.Tiempos de ejecución HTM Intel Xeon
[caption=""]
image::tm_hardware.png[align="center"]


=== Recapitulación

La investigación en el área de memoria transaccional está muy activa.

Es una nueva abstracción de programación, hay elaboradas técnicas de sincronización como +retry+ y +orElse+.

Los diseñadores de lenguajes necesitan implementar nuevas construcciones sintácticas y definir con precisión su semántica.

El problema es como hacer coexistir con código existente, las transacciones deben coexistir con código no transaccional durante muchos años.

La eficiencia juega un papel importante, STM no puede alcanzar las eficiencia que se puede alcanzar por hardware, deben ejecutar más instrucciones y hacer llamadas que perjudican a la predicción. Pero es más maleable y permite experimentar con algoritmos más complejos.


Por otro lado los fabricantes de procesadores tienen limitaciones en cuanto a los algoritmos que pueden implementar y que deben ser validados y probados extensaivamente antes de fabricar, no se puede cambiar la arquitectura y crea dependencia y problemas de compatibilidad en el futuro. Lo que hace que ya sean obsoletos al salir.

Lo más probable es que la solución continúe por soluciones híbridas y que los compiladores y _runtimes_ sean los responsables de ocultar los detalles a los programadores.
