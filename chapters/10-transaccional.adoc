== 10. Memoria transaccional

Como la exclusión mutua, la memoria transaccional es un mecanismo de control de concurrencia. El objetivo es simplificar la programación y la eficiencia de programas concurrentes aumentando el paralelismo. Para acceder a registros compartidos los programadores usan el concepto de _transacción_ conocida desde hace tiempo en las bases de de datos ACID.

Desde el punto de vista del programador las transacciones se ejecutan como secuencialmente y de forma aislada. Las complejidades del control de concurrencia quedan ocultos al programador.


=== Los problemas de secciones críticas y _locks_

Las transacciones están muy relacionadas con la exclusión mutua. Vimos dos tipos de mecanismos para resolverla, los _spinlocks_ con primtivas atómicas y las soluciones bloqueantes. Ambos tienen problemas de eficiencia y de programación.

- La exclusión mutua reduce en nivel de paralelismo, las secciones críticas deben ser ejecutadas secuencialmente por lo que se reduce al capacidad de ejecutar hilos en paralelo.

- Para evitar los cuellos de botella de las secciones críticas se implementan _estructuras concurrentes_ (_lock-free structures_) con instrucciones atomicas del procesador. Pero estas primitivas solo trabajan con una palabra por lo que requieren algoritmos más complejos cuando se deben trabajar con registros mayores o con un mayor número de ellos. Hay algunos temas académicamente todavia no resueltos eficientemente, como las lista de doble entrada con posibilidad de añadir o extraer por ambos extremos.

- Los _spinlocks_ para exclusión mutua producen inversión de prioridades y _efecto convoy_ cuando un proceso es interrumpido por haber acabado su _cuanto_. La inversión de prioridades ocurre cuando otros procesos de mayor prioridad no puedan entrar a la sección crítica. El efecto convoy cuando se acumulan los procesos en espera se acumulan, aún después que el proceso interrumpido haya liberado el _lock_ toma un tiempo vaciar la cola de listos.

- Los interbloqueos son difíciles de evitar si se manipulan muchos objetos. Aunque hay técnicas y reglas conocidas (<<deadlocks>>), con el incremento del número y tamaño de los programas concurrentes el modelo ya no es sustentable (<<Herlihy12>>).

- Los algoritmos de exclusión mutua y basados en primitivas no son _componibles_. Los  algoritmos de _spinlocks_ son complejos por la dificultad de componer llamadas a múltiples objetos en unidades atómicas, pero no se pueden componer. En spinlocks <<free_lock_stack>> vimos como implementar una pila sin exclusión mutua, no se puede eliminar el elemento de una e insertarla en otra atómicamente. Se pueden agregar mecanismos _ad hoc_, como una  exclusión mutua adicional pero crea otro cuelo de botella.

- Son difíciles de gestionar efectivamente, especialmente para la gestión de estructuras complejas o de grandes sistemas. Si se desea más eficiencia y paralelismo hay que trabajar con granularidades muy pequeñas. Se usan _mutex_ o _spinlocks_ globales para gestionar estructuras complejas como hashing o árboles balanceados por la complicación de trabajar a granularidades más detalladas, no se puede saber de antemano qué ramas del árbol o qué partes de la tabla se modificarán. Lo que desea el programador es indicar cuál es la sección crítica y que el sistema se encargue de controlar la granularidad.

El futuro parece ser un mayor aumento de núcleos y procesadores y por consiguiente un crecimiento de los programas concurrentes. Hay un consenso académico y en la industria de que los modelos actuales de exclusión mutua tienen demasiadas limitaciones. El los últimos años se produjo un aumento notable de publicaciones científicas y desarrollos de sistemas de memorias transaccionales.


=== Orígenes

Los sistemas de memoria transaccional todavía están en su infancia. La primera propuesta para usar la idea de transacciones fue de David Lomet en 1977 (<<Lomet>>) pero no propuso ninguna solución práctica competitiva con los mecanismos de sincronización explícitos (<<Harris>>). La idea cayó en el olvido durante quince años.

En 1993 Maurice Herlihy y Eliot Moss (<<Herlihy93>>) propusieron soluciones para soporte de hardware de transacciones para superar las limitaciones de los _spinlocks_, principalmente la inversión de prioridaddes, efecto convoy y los interbloqueos. El mismo año Janice Stone _et al_ (<<Stone>>) propusieron primitivas de hardware atómicas _multi-palabra_ (_Read-and-Reserve/Write-if-Reserved_) conocidas como _Oklahoma Update_. La propuesta está basada en la misma idea de LL/SC (<<llsc>>) pero a diferencia es esta permite reservar más de una palabra.

En 1995 Nir Shavit y Dan Touitou (<<Shavit>>) propusieron y demostraron por primera vez una implementación de memoria transaccional por software. En 2006, Nir Shavit con Dave Dice y Ori Shalev presentaron el algoritmo _Transaction Locking 2_ (_TL2_, <<Dice>>). TL2 sirvió de base para varias librerías de memoria transaccional, entre ellas a TinySMT (<<Felber>>). TinySTM es una de las librerías más populares y eficientes actualmentefootnote:[Uno de sus autores, Torvald Riegel, es también responsable de las librerías _libitm_ que usa GCC.].

En los últimos años se ha producido un avance notable en sistemas de memria transaccional por hardware y software. Entre 2012 y 2013 Intel (Haswell) e IBM (con PowerPC y S390) presentaron sus procesadores con soporte de memoria transaccional por hardware (_HTM_).

En software también se está avanzando rápidamente. El desarrollo de nuevos algoritmos y la compilación optimizada de los compiladores hace que tenga sentido usar sistemas de transacciones aún sin soportre de hardware. Además de las librerías de memoria transaccional por software (_STM_) se está acabando con la definición de la definición del estándar para C y C++ de memoria transaccional (<<Tabatabai>>). El compilador GCC incluye soporte para memoria transaccional de software desde la versión 4.7 y soporte de hardware para procesadores Intel, PowerPC y S390 de la versión 4.8 (<<TransactionGCC>>). Los _mutex_ de las librerías POSIX Threads ya usan el soporte de hardware desde la versión Glibc 2.18 (<<Kleen>>). Desarrolladores del núcleo Linux empezaron a desarrollar soporte de memoria transaccional por hardware desde 2013.


[NOTE]
.Transacciones de bases de datos
====
Las base de datos son capaces de trabajar concurrentemente y en paralelo desde hace años, ejecutan varias consultas simultáneamente siempre es posible. Obtienen esta eficiencia con un modelo que evita que el programador deba preocuparse de la concurrencia. El corazón del sistema es la transacción, esta especifica una semántica de secuencia de operaciones –una composición– como si fuese el único proceso accediendo a la base de datos.

Las operaciones dentro de transacciones se ejecutan en concurrentemente y en paralelo con otras operaciones, pero las interacciones limitadas de forma que los resultados no varían si se ejecutaron una después de otra. Esta propiedad del modelo se llama _secuencialidad_ (_serializability_) y facilita el trabajo al programador habituado a la programación secuencial.

Las bases de datos tienen las propiedades ACID por _atomicidad_, _consistencia_, _aislamiento_ (_isolation_) y _durabilidad_.

- Atomicidad significa que el conjunto de operaciones de una transacción se completan todas o ninguna. Si se _rechaza_ una ejecución no debe dejar rastros de los cambios que se hizo _tentativamente_. Cuando una transacción acaba correctamente se hace el _commit_ haciendo visible los cambios, caso contrario la transacción de _aborta_.

- Consistencia significa que los datos pasan de un estado consistente a otro. Se respetan los invariantes, por ejemplo, el resultado de una transferencia bancaria que generó un ingreso en una cuenta también incluye la extracción desde otra.

- Aislamiento implica que no hay interferencias entre transacciones. Los cambios realizados por las operaciones de una transacción no son visibles no afectan al resultado de otras en curso.

- Durabilidad asegura que si una transacción acaba correctamente (con _commit_) sus datos están almacenados en el dispositivo de almacenamiento persistente.
====

////
La popularización de los _multicores_ ha hecho renacer el interés por estas técnicas. Ambas son muy similares pero tienen sus diferencias. Las bases de datos involucran acceso a disco, las transacciones en memoria involucran comunicación de mensajes entre los diferentes procesadores y sistemas de cache.
////


=== Transacciones

Las operaciones básicas para gestión de transacciones:

- Iniciar transacción, +StartTx+.
- Confirmar la transacción, +CommitTx+.
- Abortar la transacción actua, +AbortTX+.

Y para acceso a datos:

- Leer, +Type ReadTx(Type *address)+.
- Escribir, +WriteTx(Type *address, Type value)+.

Así una transacción simple para la operación sobre el contador de los ejemplos esfootnote:[Los nombres de las funciones son genéricos, uso los mismos que se suelen encontrar en la bibliografía.]:

[source, c]
----
StartTX();
c = LoadTX(&counter);
c += 1;
StoreTX(&counter, c);
CommitTx();
----

Este tipo de construcción se denomina _transacciones explícitas_. Pero los compiladores pueden tener construcciones de uso más simple para el programador, los _bloques atómicos_:

[source, c]
----
transaction {
    counter += 1;
}
----

En este caso se mejora la calidad del código y se facilita la tarea del programdor. El compilador es responsable de insertar las llamadas a las funciones de memoria transaccional. El bloque atómico es equivalente a las siguientes funciones explícitas:

[source, c]
----
do {
    StartTx();
    ...
} while (!CommitTx());
----

[NOTE]
====
La construcción con la palabra clave +transaction+ es similar a +synchronized+ en Java o a +atomic+ en C\++. Pero mientras estas últimas introducen un _mutex_ que se aplica a otros métodos de la misma instancia, +transaction+ es global y permite la ejecución concurrente.
====


Algunos compiladores ya incluyen construcciones sintácticas como esa, como el compilador _Intel C\++ STM Compiler_ (<<IntelSTM>>). Para C/C\++ se está trabajando en el borrador de la especificación (<<Tabatabai>>), permitirá dos tipos de transacciones: relajadas (`__transaction_relaxed`) y más estrictas (`__transaction_atomic`).

==== Bloques atómicos con GCC

Desde la versión 4.7 GCC (2011) permite especificar bloques atómicos con semántica similar a la del borrador de C/C++ (<<TransactionGCC>>). El siguiente ejemplo es la implementación del contador con memoria transaccional (<<tm_mutex_gcc_c, código completo>>)footnote:[Puede usarse también `__transaction_relaxed`, pero con gcc 4.9 no encontré diferencia en el código ensamblador generado.]:

[source, c]
._Mutex_ con GCC
----
for (i=0; i < max; i++) {
    __transaction_atomic { <1>
        counter++;
    }
}
----

El compilador agregará las llamadas explícitas a funciones de las librería de memoria transaccional _libitm_. En el fragmento siguiente se ven las llamadas de inicio y fin de transacción como las de lectura y escritura del entero de cuatro bytes:

[source]
----
call    _ITM_beginTransaction
...
call    _ITM_RU4
...
call    _ITM_WU4
...
call    _ITM_commitTransaction
----

La librería _libitm_ está incluida en GCC, las funciones son parte de las librerías compartidas del _runtime_ de gcc, no se incluyen en el programa compilado. Esta librería incluye una implementación de memoria transaccional por software compatible con el ABI de Intel. Permite implementar otros algoritmos vía _plugins_ y seleccionar cuál usar al momento de al ejecución. Desde la versión 4.8 soporta y detecta en tiempo de ejecución la memoria transaccional por hardware de Intel, PowerPC e IBM 390.


=== Implementación

==== Gestión de versiones

- Eager version management [227] o direct update, se modifica directamente en la memoria y se mantiene un undo-log. Requiere que se use control de concurrencia pesimista.

- Lazy version management o _deferred update_ porque las actualizaciones se hacen al momento del commit. Las transacciones mantienen su _redo-log_ privado (en un buffer).

=== Control de concurrencia

Ocurre un conflicto cuando dos transacciones hacen operaciones conflictivas sobre las mismas regiones de datos, por ejemplo dos escrituras.

El conflicto es detectado cuando el sistema de memoria transaccional determina que hay un conflicto.

El conflicto se resuelve cando el sistema de memoria transaccional toma una acción para evitar el conflicto. Puede abortar o retrasar una de las transacciones.

Los tres eventos -ocurrencia del conflicto, la detección y resolución– pueden ocurrir en diferentes momentos pero siempre en el mismo orden.

EL _control de concurrencia pesimista_ detecta el conflicto en cuanto se produce, por lo tanto los tres eventos se producen al mismo tiempo. Cada transacción se apropia de los datos, como en una sección crítica, y las demás no pueden acceder a ellos.

Con el _control optimista_ los eventos de detección y resolución pueden ocurrir más tarde. Este tipo de control permite que varias transacciones accedan simultáneamente a los mismos datos y por lo tanto avanzar en su ejecución simultáneamente hasta que el conflicto es detectado. Esto permite mayor libertad para la resolución, se puede abortar o retrasar a las transacciones conflictivas.

El control optimista es el más usado porque permite mayores niveles de concurrencia. Pero si la tasa de conflictos es elevada produce ejecuciones inútiles, en casos como este es mejor usar control pesimista para impedir que las transacciones sigan avanzando. También se pueden usar técnicas mixtas.

El control optimista debe considerar otras cuestiones:

- Granularidad del conflicto. Puede tratarse a nivel de palabras, objetos (tamaños superiores o estructuras más complejas) o líneas de caché (en implementaciones por hardware).

- El instante de la detección del conflicto. Se se hace al acceder a los datos se denomina _detección temprana_ (_early conflict detection_). Si se en el momento del _commit_ se denomina _detección tardía_ (_lazy conflict detection_).

- El tipo de acceso que es tratado como conflicto. Puede hacer solo entre transacciones concurrentes activas o entre las activas y las ya finalizadas.









Como las transacciones permiten actualizaciones a diferentes ubicaciones eliminan la necesidad de comparaciones múltiples en los spinlocks.





Las transacciones son ejecutadas especulativamente, hace cambios tentativos a objetos, si acaban sin conflictos se hace el _commit_ definitivo. Si no, se aborta. Las transacciones pueden ser anidadas, son útiles porque pueden ser abortadas sin abortar al padre.

Los _mutex_ son pesismistas, las transacciones optimistas y tentativas.
En paralelismo no hay mecanismos de abstracción y composición. Composición es la capacidad de juntar dos entidades para forma una más compleja.


[source, c]
----
for (i=0; i < max; i++) {
    TM_START(0, 0);         <1>
    c = stm_load_int(&counter);
    c++;
    stm_store_int(&counter, c);
    TM_COMMIT;              <2>
}
----
<1> Un macro de conveniencia que abre un bloque, llama a stm_start y salva el contexto.
<2> Otro macro de conveniencia, llama a +stm_commit+ y cierra el bloque.



==== Composición

Mover un objeto de una cola a otra de forma atómica es imposible con monitores, sin embargo es trivial con transacciones.

atomic {
    x = q0.deq();
    q1.enq(x);
}


----
void push(node **head, node *e) {
    __transaction_atomic {
        e->next = *head;
        *head = e;
    }
}

node *pop(node **head) {
    node *old_head;

    __transaction_atomic {
        old_head = *head;
        if (old_head) {
            *head = old_head->next;
        }
    }
    return old_head;
}
----






==== Sistemas
A simulator is available for ASF, a proposed AMD64 architecture extension for bounded-size transactions [61]. This is based on PTLSim, providing a detailed, cycle-accurate full-system simulation of a multi-core system

TL2 (<<Dice>>)

CTL
Deuce STM provee métodos atómicos para Java.
////
JVSTM is a Java library that implements a multi-versioned approach to STM that includes
mechanisms for partial re-execution of failed transactions
The Sun C++ compiler with Transactional Memory supports a range of STM back-ends, including TL2 [83], SkySTM [188], HyTM [78] and PhTM [193].The compiler is available in binary format, but the runtime system and additional TM implementations are available as source code by request from the Sun Labs Scalable Synchronization Research Group. http://research.sun.com/scalable/
TinySTM is a word-based STM implementation available from the University of Neuchatel. It is based on the LSA algorithm [262]. A Java LSA implementation is also available. http://tmware.org
Implementations of TL2 [83] and subsequent algorithms are available for use with Tanger (an earlier version of DTMC). http://mcg.cs.tau.ac.il/projects
TxOS is a prototype version of Linux that extends the OS to allow composition of system calls into atomic, isolated operations [243]. TxOS supports transactional semantics for a range of resources, including the file system, pipes, signals, and process control. It runs on commodity hardware. http://txos.code.csres.utexas.edu
////



=== Criterios de corrección _correctness_

- Secuencialidad (Serializability):  Las transaccciones deben ser secuenciables, los resultados deben ser idénticos a si se ejecutan en una secuencia. No requiere que se ejecuten en un orden de tiempo real estricto, pueden intercambiarse el orden.

- Secuencialidad estricta: Si una transacción se completa antes que otra su ejecución secuencial debe ocurrir en el mismo orden.

- Linearizabilidad (Linearizability): La operación de lecturas y escritura de toda la transacción debe aparecer en un momento puntual.

- Instantáneas aisladas (Snapshot isolation): Es más débil que linearizabilidad, permite mayor concurrencia. Las lecturas debe ser linearizables antes que las escrituras.




Limitaciones de los bloques:
Problema del deadlock como en barreras

volatile bool flagA = false;
volatile bool flagB = false;
// Thread 1 // Thread 2
atomic {
    while (!flagA); // 1.1 flagA = true;
    flagB = true; // 1.2 while (!flagB);
}

Single-Lock Atomicity (SLA) for Atomic Blocks

Los problemas de llamadas de sistemas, E/S y transacciones externas

Transacción son una serie de pasos ejecutados por un único proceso. Deben ser secuenciables, parecen ejecutarse secuencialmente en un orden de una a la vez.

Singh developed a library of join patterns using atomic blocks in STM-Haskell [294].T




=== Software

////
• Software is more flexible than hardware and permits the implementation of a wider variety of
more sophisticated algorithms.
• Software is easier to modify and evolve than hardware.
• STMs can integrate more easily with existing systems and language features, such as garbage
collection.
• STMs have fewer intrinsic limitations imposed by fixed-size hardware structures, such as
caches.

////

En software, versionID, global lock, blocking & nonblocking



.Programación con tinySMT
[source, c]
----
TM_INIT_THREAD;

for (i=0; i < max; i++) {
    TM_START(0, 1);
    c = TM_LOAD(&counter[position]);
    c++;
    TM_STORE(&counter[position], c);
    TM_COMMIT;
}

TM_EXIT_THREAD;
----




=== Hardware

==== Transacciones explícitas

- Optimistic Synchronization, similar al LL/SC.
- Herlihy and Moss HTM: load-transactional, store-transactional, and load-transactional-exclusive
- Oklahoma Update: Operación atómica sobre varios registros.

////
Advanced Synchronization Facility. Recently, the Advanced Synchronization Facility (ASF) proposal [61] from Advanced Micro Devices takes a similar approach to the explicit HTM systems discussed so far. It introduces a SPECULATE instruction to begin a transaction, along with a COMMIT instruction to mark the end. Control returns implicitly to the SPECULATE instruction if the speculative region aborts, setting the processor flags to indicate that this has occurred. Simple flattened nesting is supported; speculation continues until the outermost COMMIT occurs. ASF proposes the use of a LOCK prefix to be added to memory accesses that should be performed transactionally. In the implementation proposal, ASF proposes the use of dedicated registers, similar to Oklahoma Update, to perform a multi-word compare-and-swap-like operation.
////


////
IMPLICITLY TRANSACTIONAL HTM SYSTEMS

- Rock HTM. Rock HTM is an implicitly transactional HTM designed for a modern processor from Sun. However, Rock HTM requires the level two (L2) cache to track all store addresses inside the transaction.

- Speculative Lock Elision. to roll back register state, The SLE implementation uses the store buffer to hold updates performed transactionally


With speculative lock elision (SLE), critical sections execute speculatively with TM-like techniques being used to dynamically detect conflicts between them. If there is a conflict between speculative critical sections then one or other of the critical sections can be re-executed, or the implementation can fall back to non-speculative execution and actually acquire the lock in question. Conflicts between speculative and non-speculative critical sections can be detected by having speculative sections monitor that the locks they acquire are currently available.

<<Rajwar>>

las ejecuciones son especulativas, los cambios son tentativos, si se completa la transacción se hace el _commit_.



SOFTWARE CONTROLLED CACHE COHERENCE

RTM
FlexTM
////

Programmable Data Isolation (PDI) Con este sistema el software tiene el control de qué direcciones de memoria participan en la transacción y deben ser controlados por el sistema de cache. Se requieren dos intrucciones TLoad y TStore.

Este sistema requiere



Restricted Transactional Memory: xbegin, xend, xabort, xtest.

IBM Power PC, Transactional Memory, tbegin, tend, tabort, tcheck

IBM S390 tbegin, tend, tabort, etnd




=== Intel
Intel:
Intel microprocessors based on the Haswell microarchitecture



==== Hardware lock elision
Hardware Lock Elision: xaquire/xrelease, usan los mismo prfijos que REPNE/REPE y sin ignorados si no se soporta.

Si falla vuelve a ejecutar sin eludir el mutex.



----
movl    $1, %eax
xchgl	mutex(%rip), %eax
...
movl    $0, %eax
----

----
movl    $1, %eax
xacquire xchgl  mutex(%rip), %eax
...
movl    $0, %eax
xrelease movl   %eax, mutex(%rip)
----


----
void lock() {
    while(exchange_n(&mutex, 1, __ATOMIC_ACQUIRE|__ATOMIC_HLE_ACQUIRE));
}

void unlock() {
     store_n(&mutex, 0, __ATOMIC_RELEASE|__ATOMIC_HLE_RELEASE);
}
----


==== RTM

Siempre debe proveer un camino alternativo.
Restricted Transactional Memory: xbegin, xend, xabort, xtest.





[source, c]
----
for (i=0; i < max; i++) {
    if (_xbegin() == _XBEGIN_STARTED) {
        if (mutex) {
            _xabort(1);
        }
        counter[position]++;
        _xend();
    } else {
        lock();
        counter[position]++;
        unlock();
    }
}
----


GCC:





https://gcc.gnu.org/onlinedocs/gcc-4.8.4/gcc/x86-specific-memory-model-extensions-for-transactional-memory.html#x86-specific-memory-model-extensions-for-transactional-memory
The i386 architecture supports additional memory ordering flags to mark lock critical sections for hardware lock elision. These must be specified in addition to an existing memory model to atomic intrinsics.


__transaction_atomic {
    count++;
}


=== Tiempos

.Tiempos de ejecución lectores-escritores
[caption=""]
image::tm_rw.png[align="center"]


.Tiempos de ejecución STM Intel i5
[caption=""]
image::tm_software.png[align="center"]


.Tiempos de ejecución HTM Intel Xeon
[caption=""]
image::tm_hardware.png[align="center"]


=== Recapitulación

La investigación en el área de memoria transaccional está muy activa.

Es una nueva abstracción de programación, hay elaboradas técnicas de sincronización como +retry+ y +orElse+.

Los diseñadores de lenguajes necesitan implementar nuevas construcciones sintácticas y definir con precisión su semántica.

El problema es como hacer coexistir con código existente, las transacciones deben coexistir con código no transaccional durante muchos años.

La eficiencia juega un papel importante, STM no puede alcanzar las eficiencia que se puede alcanzar por hardware, deben ejecutar más instrucciones y hacer llamadas que perjudican a la predicción. Pero es más maleable y permite experimentar con algoritmos más complejos.


Por otro lado los fabricantes de procesadores tienen limitaciones en cuanto a los algoritmos que pueden implementar y que deben ser validados y probados extensaivamente antes de fabricar, no se puede cambiar la arquitectura y crea dependencia y problemas de compatibilidad en el futuro. Lo que hace que ya sean obsoletos al salir.

Lo más probable es que la solución continúe por soluciones híbridas y que los compiladores y _runtimes_ sean los responsables de ocultar los detalles a los programadores.
