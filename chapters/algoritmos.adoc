[[algorithms]]
== Algoritmos de exclusión mutua

En este capítulo estudiaremos la solución al problema de la exclusión mutua para dos procesos y luego para 2 o más procesos.

Empezaremos analizando los problemas de algoritmos simples para dos procesos hasta llegar a la primera solución, el _algoritmo de Dekker_ de 1963 footnote:[Theodorus Jozef  Dekker es un matemático holandés nacido en 1927, su algoritmo se considera el primero que solucionó problemas de procesos concurrentes.]. Luego veremos una solución equivalente pero más sencilla desarrollada por Peterson <<Peterson>> en 1981. Finalmente estudiaremos la solución para N procesos, el _algoritmo de la Panadería_ de Leslie Lamport (<<Lamport>>).

Estos algoritmos no se usan por varios motivos, uno de ellos es que no funcionan en las arquitecturas de procesadores modernos ya que estos reordenan las instrucciones (_out of order execution_) para optimizar la ejecución lo que obliga a usar _barreras de memoria_ (_memory barriers_) que se explican en el capítulo siguiente (<<barriers>>). Tampoco se usan porque consumen mucha CPU al usar _espera activa_, además existen otras primitivas que eliminan los problemas mencionados y que explico en otros capítulos: _spinlocks_, semáforos, monitores y paso de mensajes.

El objetivo de estudiar estos algoritmos y su evolución hasta la solución correcta es aprender a reconocer y razonar sobre los problemas de los algoritmos concurrentes, conocer las reglas fundamentales para el diseño de los algoritmos, cómo probar que son correctos y aprender la terminología básica y sus aplicaciones:

- esperas activas (_busy wait_),
- interbloqueos (_deadlocks_),
- inanición (_starvation_),
- bloqueos activos (_livelocks_),
- etc.

Este conocimiento no tiene un interés puramente académico, además de comprender cómo se implementan los mecanismos y abstracciones de más alto nivel en los diferentes lenguajes y sistemas os ayudará a detectar y razonar sobre los problemas de concurrencia y condiciones de carreras de vuestros programas y hasta de consultas a bases de datos.

=== Memoria compartida

En todos los algoritmos y técnicas que analizamos en este libro asumimos que nuestros programan tienen acceso a memoria compartida, es decir, podemos usar variables cuyos valores serán accesibles directa e inmediatamente por los demás procesos. Es decir, se dice que nuestros algoritmos son del *tipo de memoria compartida*.

[NOTE]
.Algoritmos distribuidos
====
El extremo opuesto son los sistemas donde no se tiene acceso a memoria compartida, se denominan _algoritmos distribuidos_. Los sistemas distribuidos también deben resolver problemas de _concurrencia_, _sincronización_ y _consenso_ pero sus técnicas son más complejas al no disponer de variables compartidas por lo que el intercambio de datos debe hacerse exclusivamente por _pasos de mensajes_, que están sujetos a errores por pérdida, ordenamiento, _timeouts_, modificaciones, etc. Aunque hay que resolver problemas similaresfootnote:[Como la exclusión mutua, uno de los más conocidos -aunque no el más óptimo- es el conocido _token ring_.] y se basan en los mismos conceptos que la concurrencia de memoria compartida su soluciones son diferentes y más complejas no es el objetivo de este libro.
====

=== Convenciones de programación

Consideramos que los programas tienen _secciones críticas_ y _resto del código_. No podemos modificar el programa dentro de las secciones críticas ni nos interesa lo que se hace en el _resto_. De este último tampoco tenemos información del tiempo que tarda o cómo se ejecuta, suponemos que el tiempo que cada proceso está en la sección crítica es finito.

En las secciones críticas los procesos acceden a variables o recursos compartidos y que requieren que se asegure exclusión mutua con las mismas secciones críticas de otros procesos. Nuestra responsabilidad será desarrollar los algoritmos que se insertarán antes de la sección crítica (_pre-protocolo_ o _entrada de la sección crítica_) y después de la misma (_post_protocolo_ o _salida de la sección crítica_).


.Inicialización de variables globales
----
        turno = 1
        estados = [0, 0]
----

.Programa que ejecuta cada proceso
----
while True:
    # resto del código
    #
    entry_critical_section() <1>
    critical_section() <2>
    exit_critical_section() <3>
    #
    # resto del código
----
<1> Entrada a sección crítica o pre-protocolo. Habitualmente se usa `lock()`.
<2> La sección crítica, por ejemplo `counter += 1`.
<3> La salida de la sección crítica, post-protocolo, o `unlock()`.


=== Solución para dos procesos

Vamos a intentar solucionar primero el problema de concurrencia más sencillo. Lo haremos en varios intentos con complejidad creciente y asegurándonos que cumplan las condiciones de <<six_requisites>>.

El algoritmo es simétrico, es decir se ejecuta el mismo en ambos procesos identificados por `0` y `1` footnote:[Recuerda que en informática siempre se cuenta desde cero, es muy cómodo y práctico.]. En vez de duplicar el código nos centraremos en uno de ellos, el `0` o _P0_. Para el proceso P0 el _otro_ proceso es el `1` (o _P1_). Obviamente, el algoritmo de P1 será igual al de P0 pero con los valores `0` y `1` intercambiados.

Como generalización se suele usar `i` para identificar al propio proceso y `j` para identificar a los otros. Más adelante usaremos la misma convención, como ahora sólo tratamos con dos procesos usaremos `0` y `1` y nos centraremos desde el punto de vista del proceso P0.


==== Primer intento
La idea fundamental es que la variable entera `turn` nos va a indicar qué proceso puede entrar a la sección crítica. Esta variable es atómicafootnote:[Más adelante estudiaremos las propiedades de las variables atómicas, por ahora es suficiente indicar que en este tipo de variables el valor leído es siempre el último escrito.] y puede tomar sólo los valores `0` y `1`, cada uno de ellos indica de quién es el _turno_ para entrar. La inicializamos con cero pero puede tomar cualquiera de los dos valores.


----
        turn = 0
----

El siguiente es el código. El primer `while` es la _entrada a la sección crítica_ y lo que hace es esperar a que sea el turno del proceso. En este caso esperará en el bucle mientras `turn` sea diferente a `0`.


[NOTE]
.Espera activa
====
Esta espera en el `while` _sin hacer nada_ y solo verificandofootnote:[Habitualmente llamado _polling_.]  el valor de una variable se denomina *_espera activa_* (_busy waiting_). Es una característica indeseable porque consume CPU pero muchas veces inevitable cuando no se pueden usar otras primitivas... por ejemplo para implementa esas primitivas. En estos casos se los llama _spinlocks_, el capítulo <<spinlocks>> describe algoritmos más eficientes con instrucciones por hardware.
====

----
while turn != 0:
  pass

critical_section()

turno = 1
----

Cuando la variable `turn` sea `0` P0 podrá entrar a su sección crítica, al salir de ella ejecutará la _salida de sección crítica_ que consiste sólo en dar el turno a P1. Ya os habréis dado cuenta del problema, pero aún así y por ser la primera vez lo analizaremos en detalle comprobando si se cumplen los requisitos de <<six_requisites>>.

Asegurar exclusión mutua:: Es fácil comprobar que la cumple. La variable `turn` solo puede tomar uno de entre dos valores. Si los dos procesos están en la sección crítica significa que `turn` valía cero y uno simultáneamente, sabemos que es imposiblefootnote:[Es imposible aunque se ejecuten en paralelo en procesadores diferentes, la asignación de enteros es atómica en los procesadores, al final sólo se almacenará 0 *o* 1.].

No interferencia:: Supongamos que P0 entra a su sección crítica por primera vez, al salir hace `turn = 1` y al poco tiempo pretende volver a entrar. Como el turno es de P1 tendrá que esperar a que éste entre a su sección crítica para entrar a continuación. Es decir, la entrada de P0 está _interferida_ por el otro proceso cuando éste ni siquiera tiene intenciones de entrar porque está en el _resto del código_ footnote:[O incluso ni siquiera se está ejecutando.]. Sólo por esta razón ya debemos descartar este algoritmo, pero sigamos analizando las siguientes reglas.

Sin esperas infinitas:: Por la anterior se produce espera infinita si el proceso `1` no entra a la sección crítica.

Entrada inmediata:: Si `turn` vale `1` pero este último está en el _resto del código_ y no podrá entrar. Tampoco se cumple.

Sin suposiciones de velocidad relativa:: Hemos supuesto que ambos procesos entrarán alternativamente a la sección crítica, es decir que su velocidad relativa es _similar_. Tampoco la cumple.


El problema de este algoritmo es que obliga a una *_alternancia exclusiva_* que provoca espera infinitas.


==== Segundo intento

Si el problema del anterior es que la variable `turn` exigía alternancia exclusiva se puede solucionar con un array. Cada posición del mismo indica si el proceso correspondiente está (`True`) o no (`False`) dentro de la sección crítica. Cuando un proceso desea entrar verifica el estado del otro, si no está en la sección crítica pone `True` en su posición del array y continúa (entrando a la sección crítica).

----
        states = [False, False]


while states[1]:
    pass
states[0] = True

critical_section()

states[0] = False

----

Este algoritmo no asegura la condición principal: exclusión mutua.

Basta con probar que ambos valores de `states` son verdaderos. Puede ocurrir, las instrucciones del `while` footnote:[El `while` es traducido a una serie de instrucciones que involucan un `if`.] y la asignación posterior no son operaciones atómicas (o _indivisibles_), el proceso puede ser interrumpido entre ellas, como en la siguiente secuencia de ejecución de instrucciones, a la izquierda las de P0 y a la derecha las de P1.

  P0                    P1
  ¿states[1]? -> False
                        ¿states[0]? -> False
                        states[1] = True
                        ...
  states[0] = True
  ...
              BOOOM!

P0 verifica el estado de P1, sale del bucle porque es `states[1]` falso e inmediatamente es interrumpido. P1 hace la misma verificación, sale del bucle, pone su estado en verdadero y entra a la sección crítica. Mientras está en ella es interrumpido y se ejecuta P1 que también entra a la sección crítica.

==== Tercer intento

El problema del algoritmo anterior es que un proceso verifica el estado del otro antes de cambiar su propio estado. La solución parece obvia: si se asigna el estado propio antes de verificar el otro aseguraremos que no se llegue a la sección crítica si el otro proceso ya está en ella.

----
states[0] = True
while states[1]:
    pass

critical_section()

states[0] = False
----

Es sencillo demostrar que sí cumple el primer requisito de exclusión mutua, si los dos desean entrar más o menos simultáneamente el primero que ejecute la asignación a `states` será el que pueda entrar. También cumple el requisito de _no interferencia_ y el de _entrada inmediata_, si P1 está en el resto del código entonces `states[1]` será falso, por lo que no interfiere con P0 y éste podrá entrar y salir varias veces sin interferencia ni esperasfootnote:[Lo que implica que tampoco estamos haciendo suposiciones de velocidad relativa entre ellos.].

El gran problema es que no cumple la regla de _sin esperas infinitas_, de hecho el algoritmo genera un _interbloqueo_ si se da la siguiente secuencia de instrucciones:


  P0                    P1
  states[0] = True
                        states[1] = True
                        ¿states[0]? -> True
  ¿states[1]? -> True
  ...
                   DEADLOCK!


P0 asigna su estado, se interrumpe y se ejecuta P1, en la entrada de la sección crítica cambia su estado y luego verifica el de P0. Como da verdadero no saldrá del `while` hasta que P0 cambie su estado falso. Pero P0 tampoco saldrá del bucle hasta que P1 cambie su estado. Como sólo se pueden cambiar después de salir de la sección crítica ninguno de ellos podrá continuar.

Es la perfecta definión de una ley de Kansas de principios del siglo XX (<<railroad>>)footnote:[Aunque hay que aclarar que la puso un Senador porque no quería que se aprobase la ley por lo que insertó esta regla estúpida para que sus colegas detuviesen el proceso al verla. Pero fue aprobada.]:

[quote]
Cuando dos trenes se encuentran en un cruce de vías cada uno deberá detenerse completamente y ninguno deberá continuar hasta que el otro se haya ido.


==== Cuarto intento

Se puede romper el interbloqueo que se genera en el caso de la _condición de carrera_ explicada previamente cambiando temporalmente el estado del proceso a falso e inmediatamente volver a ponerlo en verdadero. Así se abrirá una _ventana temporal_ para que alguno de los procesos pueda continuar:

----
states[0] = True
while states[1]:
    states[0] = False <1>
    states[0] = True  <2>

critical_section()

states[0] = False
----
<1> Cede el paso a otro.
<2> Restaura el estado antes de volver a verificar en el `while`.

Si ambos procesos entran _simultáneamente_ al bucle de entrada en algún momento, por ejemplo, P1 pondrá a falso `states[1]` y se interrumpirá por lo que P0 podrá entrar a su sección crítica. P1 cambiará `states[1]` otra vez a verdadero y volverá a quedar esperando en el bucle, pero P0 ya estará en la sección crítica y cuando salga pondrá su estado a falso y P1 podrá entrar.

[NOTE]
====
Pensarás que se puede hacer algo entre <1> y <2> para aumentar la probabilidad de que el otro pueda entrar, por ejemplo bloqueando al proceso unos pocos milisegundosfootnote:[Una idea, _exponential backoff_, lo <<exponential_backoff, vemos más adelante>>.] con un `sleep()` o incluso cediendo el procesadorfootnote:[`sched_yield()` en Linux.]. Una técnica así puede servir para mejorar el rendimiento -si no hubiese otra solución mejorfootnote:[Las hay, a partir del siguiente algoritmo todos son mejores, podéis olvidaros de éste una vez que lo hayáis entendido.]-, pero formalmente son equivalentes. Además, dado que son muy pocas las instrucciones atómicas del procesador involucradas -unas diez- que la probabilidad de que uno de ellos se interrumpa justo después de asignar falso es bastante elevada y por la velocidad de los procesadores ocurriría en pocos nanosegundos.
====

Vamos a analizar si cumple los requisitos:


Exclusión mutua::

En ese caso es algo más difícil la demostración ya que no podemos recurrir al caso simple de que una variable tenga un valor u otro, o que el array `states` no tenga ambos valores en verdadero ya que es posible que así sea y haya exclusión mutua. Hay dos casos:

    . P0 entra a su sección crítica antes que P1 verifique el valor de `states[0]`, en este caso no hay problemas, P1 quedará en la espera activa y P0 saldrá de su sección crítica y P1 podrá entrar.
    . Se produce una condición de carrera como la comentada previamente. En este caso para que uno pueda entrar el otro proceso debe haberse interrumpido justo después de <1>, cuando continúe su ejecución volverá o poner su estado en verdadero por lo que volverá a esperar en el bucle hasta que el otro proceso haya salido.

No interferencia::

Si un proceso está en el resto del código, su estado será falso por lo que el otro podrá entrar sin esperar.

Sin esperas infinitas::

Prácticamente (y _formalmente_ por estadísticas) no se producen esperas infinitas aunque no se puede asegurar que se produzcan en un número de _pasos_ definido. Este fenómeno se denomina *_bloqueo activo_* (_livelock_), sabemos que en algún momento uno de ellos saldrá del bloque pero mientras tanto ambos procesos cambian valores de una variable sin hacer nada útil.
+
Otro problema, para demostrar que no se producen esperas infinitas hay que demostrar que si un proceso desea entrar a la sección crítica lo hará en un número finito de _entradas y salidas_ de otros procesos. Supongamos que P0 y P1 desean entrar, entra P1 y P0 queda esperando. Para asegurar que P0 no espera indefinidamente deberíamos demostrar que si P1 sale de la sección crítica y pretende volver a entrar lo hará después de P0. Esto no lo podemos demostrar, aunque _prácticamente_ sabemos que en algún momento lo hará. Los algoritmos y primitivas de exclusión mutua de este tipo de denominan *_débiles_* (_weak_)footnote:[En el siguiente capítulo veremos que las instrucciones de hardware son también débiles, como algunos tipos de semáforos y monitores.].

Entrada inmediata::
Si uno de los procesos no desea entrar a la sección crítica su estado estará en falso, por lo que el otro podrá entrar inmediatamente y sin espera.

Sin suposiciones de velocidad relativa::
Salvo el problema del _livelock_ y la _debilidad_, no se hacen suposiciones sobre las velocidades relativas de acceso a la sección crítica.


Aunque este algoritmo tiene problemas estamos muy cerca de una solución correcta que cumple con todos los criterios.

==== Algoritmo de Dekker

El problema del algoritmo anterior reside en la indefinición dentro del bucle, es muy fácil solucionarlo con la variable `turn` como en el primer intento. En caso que haya esa competencia en el bucle (el _livelock_) será esta variable la que decidirá inmediatamente qué proceso podrá entrar a la sección crítica.

El algoritmo queda de la siguiente forma:

----
        states = [False, False]
        turn   = 0

states[0] = True
while states[1]:
    if turn == 1:
        states[0] = False
        while turn != 0: <1>
            pass
        states[0] = True

critical_section()

states[0] = False
turn = 1 <2>

----
<1> P0 esperará si no es su turno, su estado se mantendrá en falso y P1 podrá entrar a la sección crítica.
<2> Cuando un proceso sale de su sección crítica cede el turno al otro, si ese estaba esperando en <1> podrá continuar.

Sólo en el caso que haya competencia será turno la que decidirá, el proceso diferente al valor de `turn` quedará esperando hasta que el otro haya salido de la sección crítica y le asigne su turno.

Este algoritmo cumple todos los requisitos de los algoritmos de exclusión mutua, ya *podemos demostrar* que no produce esperas infinitas, en ningún caso:

. Si P1 desea entrar a la sección crítica y P0 ya está en ella, P1 quedará esperando. Cuando P0 salga pondrá `turn = 1` por lo que el siguiente en entrar será P1 aunque P0 intente volver a entrar inmediatamente.

. En caso que ambos procesos intenten entrar simultáneamente y lleguen a la comparación de `turn`, uno de ellos (y solo uno) entrará a la sección crítica sin espera adicional, ejecutará la comparación una única vez.

. Cuando salga el proceso que haya entrado primero dará el turno al que quedó esperando como en el caso #1.

Este algoritmo funciona perfectamente pero todavía puede ser mejorado.

[[peterson]]
==== Algoritmo de Peterson

En 1981, cuando no hacía falta encontrar una solución algorítmica para dos procesosfootnote:[Recordad que ya había soluciones más prácticas para 2 o más procesos, como las instrucciones por hardware.] pero como espectacular ejercicio mental <<Peterson>> obtuvo un algoritmo más sencillo y simple de entender.

Las variables son las mismas y la idea fundamental no cambia, sólo el orden en que se ejecutan. Además de ahorrar instrucciones de procesador es mucho más sencillo de comprender:

----
        states = [False, False]
        turn   = 0

states[0] = True
turn = 1 <1>
while states[1] and turn == 1: <2>
    pass:

critical_section()

states[0] = False
----
<1> _Cede_ el turno al otro proceso.
<2> Espera si el estado del otro es verdadero y es su turno.

Como ya hemos analizado en detalles cinco algoritmos con los seis requisitos me limitaré a demostrar que se cumplen las tres fundamentales (<<em_requisites>>):

Exclusión mutua::
La demostración formal se relativamente sencilla. Para que haya dos procesos en la sección crítica y por la condición `states[j] and turn == j` se tienen que cumplir una de las siguientes condiciones condiciones:

    a. Que `states` sea `[False, False]`: es imposible porque los procesos que desean entrar antes asignan `True` a su posición.
    b. Que el último que desea entrar sea P0 y  `states` sea `[True, True]` y que `turn` sea 0. Es imposible porque antes de la comparación P0 hizo `turn = 1`. La inversa se aplica si P1 es el último en pretender entrar.
    c. Si los dos procesos desean entrar más o menos simultáneamente (es una condición de carrera) y que `turn` valga cero y uno simultáneamente. También imposible. En este caso el que entrará primero es el primero de los dos que haya ejecutado `turn = x`.


Libre de interbloqueos::

No se pueden producir porque si existe una condición de carrera en la entrada el valor de `turn` decidira qué proceso podrá continuar y cuál esperar. Si un proceso desea entrar lo hará inmediatamente porque el valor de `states` para el otro proceso será falso.

Libre de inanición::

El proceso que desea entrar primero cede turno al otro, por lo tanto si hay un proceso que ejecutó entró antes al bucle de comparación es el primero que entrará. Si este mismo sale y vuelve a intentar entrar habiendo otro esperando le cederá el turno. Así se demuestra que cualquier proceso tendrá que esperar como máximo a que el otro salga una vez de la sección crítica, luego le tocará el turno indefectiblemente.



=== Solución para N procesos: algoritmo de la panaderia

Los algoritmos anteriores resuelven la exclusión mutua solo para dos procesos, no son de extrema utilidad para cualquier sistema informático diseñado en los últimos 50 años. La solución más simple conocida la publicó Leslie Lamport en 1974 (<<Lamport>>), se lo conoce como el _algoritmo de la panadería_ (_bakery algorithm_) por su similitud a los clientes de una panaderíafootnote:[Para que se comprenda mejor la idea quizás en España deberíamos llamarle _de la oficina de Correos_.] sacan un número para saber el orden en que serán atendidos.

La implementación básica de la idea es la siguiente:

----
        number  = [0, ..., 0] <1>

number[i] = 1 + max(number) <2>
for j in range(0, N): <3>
    while number[j] > 0
        and number[j] < number[i]: <4>
        pass

critical_section()

number[i] = 0
----
<1> El tamaño del array debe ser igual al número máximo de procesos que pueden acceder a una sección crítica.
<2> La función max() retorna el mayor número que encuentra en el array `number`.
<3> Se recorre todo el array para verificar el número de los demás procesos.
<4> Esperará en el bucle si el proceso _j_ tiene un número menor al mío (_i_).

La idea es sencilla. Cada proceso tiene asociado un identificador entero que lo usa acceder al array `number` footnote:[Es la misma idea que usamos para dos procesos, solo que ahora pueden ser números iguales o mayores que cero.]. El proceso que desea entrar obtiene el siguiente número y lo almacena en su posición en el array. Si no hay nadie en la sección crítica su número será 1. Si hay ya uno será 2, pero si hay otro proceso esperando en el bucle `for j...` su número será 3, etc. El número seleccionado indicará el orden de entrada de los procesos.

Pero no es tan sencillo, son procesos independientes que ejecutan una serie de instrucciones y pueden ser interrumpidos en cualquier momento, por ejemplo cuando recorren el array. Supongamos que P0 está ejecutando `max()` y justo antes de almacenar su número se interrumpe y se ejecuta P1. Éste acaba, el máximo retornado es 0 y almacenará 1 en `number[1]`. Inmediatamente se ejecuta P1 y coge el mismo número que P1. El estado del `number` es el siguiente:

    [1, 1, 0, ..., 0]

Es decir, podemos tener números duplicados. La solución es usar el id de cada proceso para _desempatar_ en caso que hayan seleccionado el mismo número:

----
number[i] = 1 + max(number)
for j in range(0, N):
    while number[j] > 0
        and (number[j] < number[i] or
        (number[j] == number[i] <1>
         and j < i)):
        pass:

critical_section()

number[i] = 0
----
<1> La nueva condición, si ambos números son iguales y el id del otro (es decir el valor de _j_) es menor que _i_ entonces también deberá esperar.


[NOTE]
.Requisito de identificadores únicos
====
Como habréis notado en todos los algoritmos cada proceso necesita un identificador único. Como queda claro en este algoritmo, además deben tener una relación de precedencia, i.e., debe ser un conjunto ordenado. Ambos requisitos son indispensables para las soluciones de exclusión mutua y la mayoría de algoritmos distribuidos.
====


Todavía no hemos resuelto el problema. Puede ocurrir que cuando P1 haya llegado al bucle `for j...` el proceso P0 todavía no haya almacenado su número en `number[0]` y vea los siguientes valores:

    [0, 1, 0, ..., 0]

La condición `number[0] > 0` será falsa y P1 entrará a la sección crítica. Momentos después P0 almacena su número:

    [1, 1, 0, ..., 0]

Cuando verifique el número de P1 ambos tendrán el mismo (0) pero la siguiente condición

    number[1] == number[0] and 0 < 1

es falsa por lo que P0 también entrará a la sección crítica, no asegura exclusión mutua.

Para evitar que ocurra habrá que poner un mecanismo para impedir que el proceso que desea entrar no avance si el proceso contra el que está por comparar su número todavía lo está seleccionando. Para ello añadimos otro array, `choosing`, que indicará si el proceso todavía no almacenó su número.

----
        choosing = [False, ..., False] <1>
        number   = [0, ..., 0]


choosing[i] = True <2>
number[i]   = 1 + max(number)
choosing[i] = False <3>
for j in range(0, N):
    while choosing[j]: <4>
        pass
    while number[j] > 0
        and (number[j] < number[i] or
        (number[j] == number[i]
         and j < i)):
        pass

critical_section()

number[i] = 0
----
<1> El array tiene la misma dimensión que `number`.
<2> Se indica que se está por entrar a la sección de selección de número.
<3> Se indica que ya se acabó la selección.
<4> Si el proceso _j_ está seleccionando se le espera porque podría corresponderle el turno.

////
Separador para que no lo incluya en el lista anterior :-O
////

Exclusión mutua::

Para que dos procesos estén en la sección crítica tiene que ocurrir que ambos tengan el mismo número. Pero el uso del ID único y con relación de precedencia asegura que en estos casos siempre habrá uno de ellos que será el _menor_ y el único que saldrá del último bucle.
+
Para que un segundo proceso (P2) entre a la sección crítica después si hay un proceso (P1) en ella debe cumplirse que el número de P2 es menor que P1. No puede ocurrir, si P1 esta en la sección crítica habrá ejecutado `while choosing[2]` y pueden darse uno de ambos casos:

- Si salió del bucle es porque P2 ya salió de la selección, por tanto su número será comparado en el siguiente bucle y habrá entrado P2 antes que P1.

- Si P2 todavía no entró a la selección de número entonces por `number[2] = 1 + max(number)` seleccionará un número mayor al de P1.

+
La exclusión mutua se cumple.

Libre de interbloqueos::

El peor de los casos es una condición de carrera donde todos los procesos pretendan entrar simultáneamente seleccionando todos el mismo número. En este caso siempre habrá un único proceso _menor_ que podrá entrar a la sección crítica. Cuando este salga podrá entrar el siguiente con el ID más bajo, y así sucesivamente y en el orden de IDs hasta que entrarán todos.

Libre de inanición::

Si un proceso entra y pretende volver a entrar cogerá un número mayor de los que ya están esperando, por lo que esos entrarán antes. No se puede dar el caso que un proceso quede esperando indefinidamente. Si _n_ procesos desean entrar simultáneamente como máximo tendrán que esperar que entren _n-1_ procesos.

=== Recapitulación

En este capítulo hemos analizado las soluciones algorítmicas al problema más importante de concurrencia. Pero lo más importante que espero haber logrado transmitir es la complejidad y matices a la hora de diseñar algoritmos concurrentes, necesitamos pensar de una forma muy diferente a la secuencial estricta que estamos acostumbrados.

Hemos visto qué requisitos han de cumplir las soluciones de exclusión mutua y las hemos demostrado analíticamente sin entrar en detalles de notaciones formales y académicas.
