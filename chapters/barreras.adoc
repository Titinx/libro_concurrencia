== La realidad del hardware moderno

No quería hacer tan largo el capítulo anterior y me pareció que este tema merecía un capítulo independiente. Aunque los algoritmos anteriores son formalmente correctos *no funcionarán* en la mayoría de procesadores modernos. No deberías decepcionarte, el objetivo fue estudiar los algoritmos y aprender a reconocer y solucionar los problemas inherentes de la programación concurrente. No es la intención que los uses directamentefootnote:[En <<hardware>> aprenderás cómo se puede solucionar mejor el problema con instrucciones de hardware si es que tienes que recurrir a ellas.].

Para que lo veáis, programé el algoritmo de Peterson y ejecuté el programa de la misma forma que en el capítulo anterior (<<counter_times>>)footnoteref:[paciencia, Ten un poco de paciencia, el código está en el libro, ya enlazo la solución correcta un poco más adelante.]:

----
$ time ./counter_peterson 
Counter value: 9879533 Expected: 10000000

real	0m0.598s
user	0m1.189s
sys	0m0.000s
----

Además del incremento notable de tiempo de CPU (0.017s en la ejecución sin el algoritmo de Peterson) el resultado sigue siendo erróneo.


No es ningún secreto que los procesadores modernos ya no garantizan que los programas se ejecuten en el mismo _orden de secuencias_ del programafootnote:[Por defecto, más adelante veremos que se puede hacer bajo demanda, pero tiene un coste importante.], es decir no aseguran _consistencia secuencial_ de acceso a memoria. Una forma habitual de verificar si una arquitectura asegura dicha consistencia secuencial es ejecutar el algoritmo de Peterson (<<counter_peterson_c>>, por ejemplo funciona correctanente en la Raspberry Pi con procesasor ARM6).

Hay tres razones fundamentales que pueden afectar a la violación de la consistencia secuencial:

* Optimizaciones del compilador
* Cache de RAM en multiprocesadores
* Ejecución fuera de orden

=== Optimizaciones del compilador

Los compiladores pueden optimizar el código de varias formas, desde cambiar el orden de ejecución hasta usar registros como almacenamientos temporales (_buffer_) antes de escribir variables a memoria. Para evitar que se cambie el orden de ejecución de lecturas y escrituras de variables compartidas en Cfootnote:[Tiene una semántica similar en C++ y Java, en este último es para evitar que se mantengan copias no sincronizadas en objetos usados en diferentes hilos] se puede usar la palabra clave `volatile` en su declaración, por ejemplo:

	volatile int counter = 0;


Los ejemplos anteriores fueron compilados sin optimizaciones importantes del compilador, y aún con `volatile` los algoritmos no funcionan. La causa es otra.

=== Cache de RAM en multiprocesadores

El acceso a la memoria RAM toma hasta cientos de ciclos de reloj del procesador, para reducir estas diferencias los procesadores usan una jerarquía de hasta tres niveles (L1, L2 y L3) de memoria cache. L1 suele estar integrado en el chip de la CPU, L2 tiene mayor capacidad y de menor velocidad de acceso. En los procesadores más modernos L1 y L2 están integrados en cada uno de los núcleos y L3 es compartido por los demás núcleos en el mismo chip.

Cada cache almacena un bloque o _línea_ de la memoria RAM, cada uno de ellas suelen tener de 64 a 256 bytes consecutivos. Cuando el procesador accede a una posición de memoria se carga toda la línea correspondiente y las siguientes accesos se hacen directamente a la cache gracias al efecto de localidad de los programas. Si un línea de cache fue modificada se marca como tal y luego es copiada a la memoria RAM.

[NOTE]
====
Para traducir de una dirección de memoria física a la línea correspondiente de la cache se usan métodos similares a las de `[número de página, desplazamiento]` de las páginas de memoria RAM. Se usan varios mecanismos de _asociación_. Desde el _direct mapping_ donde la asociación entre conjuntos de direcciones de memoria RAM y una línea correspondiente está predeterminada a sistemas de _hashing_ y asociativas usando _memoria direccionable por contenido_.
====

El problema es mantener las cache coherentes con varios núcleos o procesadores. Dependiendo de la arquitectura ésta puede o no garantizar _coherencia de cache_. La buena noticia es que la mayoría de procesadores la garantizan.

==== Coherencia de cache en multiprocesadores

Los sistemas de multiprocesadores están conectados por una compleja red que comunica entre ellos, popularmente conocida como _front side buffer_. Dependiendo del fabricante esta red puede ser del tipo _bus_ donde los datos se transfieren por un bus compartido o arquitecturas más sofisticadas que permiten comunicaciones más rápidas y con mayor ancho de banda como la _QuickPath_ de Intel que comunica cada núcleo o procesador con cada uno de los demás.


[[quickpath]]
.Arquitectura QuickPath de Intel (imagen de _An Introduction to the Intel QuickPath Interconnect, January 2009_)
image::intel-quickpath.png[height=400, align="center"]

Para mantener la consistencia entre las diferentes copias de cacue se usa un algoritmo como MESI (por _Modified_, _Exclusive_, _Shared_ e _Invalid_) o derivadosfootnote:[Por ejemplo MESIF en Intel, F por _forward_.]. Cada línea tiene uno de esos cuatro estados, cada cache _escucha_ permanentemente al bus (_snoop_) y cambia el estado de la línea dependiendo de las operaciones que hace el procesador y lo que recibe de los demás vía el _bus_ de comunicaciones.

Cuando un procesador lee de la memoria y carga en cache el estado se marca como _exclusive_. Si otro procesador lee la misma línea se le envía una copia y se marca su estado como _shared_. Si el procesador modifica una línea cuyo estado es _shared_ ésta se marcada como _modified_ para que sea posteriormente copiada a RAM y se envía un mensaje para que los demás procesadores marquen su copia como inválida. Si otros procesadores desean acceder a datos correspondientes a la misma línea envían un mensaje a todos para que el que tenga una copia válida (en estado _exclusive_ o _modified_) le envíe la última copia, caso contrario accede a la memoria RAM para obtener la copia.

Este mecanismo asegura la consistencia de cache y no es el responsable de que los algoritmos de exclusión mutua no funcionen pero lo expliqué porque tiene implicaciones importantes para el rendimiento de las aplicaciones concurrentes en sistemas con múltiples procesadores.

[IMPORTANT]
.El problema del acceso a variables compartidas
====
Si dos hilos de ejecución que se ejecutan en procesadores o núcleos diferentes acceden a las mismas zonas de memoria la ejecución es mucho menos eficiente. Por *cada modificación* de las variables almacenadas en la misma línea obliga a que los procesodores envíen mensajes de multidifusión (_broadcast_) hacia los otros procesadores para que invaliden su entrada. Lo que provoca que estos envíen mensajes para cada acceso a las mismas variables y esperen el resultado de la copia válida.
====

El código de <<counter_local_c>> es similar al contador original <<counter_c>> con la única diferencia que la suma se hace sobre una variable local en cada hilo (i.e. no compartidas) y sólo se incrementa la global al final del bucle. 

----
// The global variable
int local_counter = 0;

for (i=0; i < max; i++) {
	local_counter += 1; 
}

// Add to the shared variable
counter += local_counter;
----

Podéis comparar los tiempos en un sistema con al menos dos núcleos y veréis que el que usa variables locales consume menos del 50% de tiempo de CPU.

[TIP]
====
Si se va a iterar muy frecuentemente (_spinning_) sobre variables es mejor asegurarse que no compartan líneas de cache, por ejemplo por usar las mismas direcciones o posiciones cercanas en un array. Si es posible es mejor hacerlo con variables _distantes_ (por ejemplo locales de cada hilo) para evitar el efecto conocido como _false sharing_ que obliga al intercambio de mensajes en el _front side bus_ afectando así a todo el rendimiento del programa.
====

=== Ejecución fuera de orden

El caso más habitual es que tengáis varios núcleos en un único chip, en este caso el problema es la ejecución fuera de orden (_out of order execution_) o _ejecución dinámica_. 





Los algoritmos anteriores no funcionarán porque los procesadores reordenan las instrucciones con el objeto de optimizar la ejecución ahorrando ciclos de reloj. Por ejemplo porque ya tiene valores cargados en registros. Se usan mecanismos de _dependencias causales_ o _débiles_ (_weak dependencies_).

Supongamos que tenemos un programa con las siguientes instrucciones:

	a = x
	b = y
	c = a * 2

El procesador puede ejecutarlas en diferentes secuencias sin que afecte al resultado, por ejemplo:

	a = x
	c = a * 2
	b = y

o

	b = y
	a = x
	c = a * 2


Detecta que la asigación a `c` la puede hacer antes que `b`, o a la de `b` antes que a `a` porque no hay dependencias entre ellas. Esto funciona perfectamente en procesos independientes, pero si estos modifican las variables pueden ocasionar problemas. Tomemos el algoritmo correcta más sencillo, [[peterson]], cuya entrada a la sección crítica es

----
states[0] = True
turn = 1
while states[1] and turn == 1:
	pass:
----

El procesador no tiene en cuenta que las variables son modificadas por otros procesos, incluso no encuentra la dependencia entre `states[0]` y `states[1]`, para el procesador son dos variables independientes que no tienen dependencia en _esta secuencia_. Por lo que es factible que las ejecute en el siguiente ordenfootnote:[Estoy exagerando, recordad que esas instrucciones son de alto nivel y que cada una de ellas son varias instrucciones de procesador, pero creo que la analogía es razonable y se entiende mejor.]:

----
turn = 1
while states[1] and turn == 1:
	pass:
states[0] = True

¡¡¡BUUUM!!!
----

Por supuesto eso haría que el algoritmo de exlusión mutua fallase. 

///
///

=== Barreras de memoria

Para hacer que el algoritmo funcione correctanente debemos especificar _barreras_ (_fences_ o _barriers_) al ordenador para impedir que ejecute ciertas instrucciones en el orden equivocado. Una intrucción de *barrera general* indica al procesador:

. Antes de continuar deben ejecutarse todas las operaciones de lectura y escritura que están antes la barrera.

. Ninguna operación de lectura o escritura posterior a la barrera deben ejecutarse antes que esta.

Aunque en el código de ejemplo no hay dependencias detectables entre ellas, supongamos que deseamos que la asignación de `c` sea siempe posterior a la asignación de `a`y `b`. Debemos insertar una barrera entre ellas:

	a = x
	b = y
	BARRIER()
	c = a * 2

Esto forzará a que ambas asignaciones y lecturas de `x` e `y` se hegan antes de la asignación a `c` lo que sólo permitirá ls siguiente alternativa además de la secuencia original:

	b = y
	a = x
	BARRIER()
	c = a * 2

Para hacer que el algoritmo de Peterson funcione debemos insertar una barrera entre la asignación de `states` y `turn` y el while que verifica el turno y el estado del otro proceso:

----
states[0] = True
turn = 1
BARRIER()
while states[1] and turn == 1:
	pass:
----

Así el código ya funcionará correctamentefootnoteref:[paciencia].

[NOTE]
====
Hay diferentes tipos de barreras y varían entre arquitecturas. Las tres típicas son la general, la de lecura y la de escritura. La primera es la que acabamos de ver, la de lectura se aplican sólo a las operaciones de lectura y la última sólo a las de escrituras.

También hay variaciones, como las _acquire_ y _release_. Si estáis interesados en aprender más sobre ellas y cómo afectan al desarrollo del núcleo Linux, un buen enlace para comenzar <<Barriers>>.
====

==== Cómo usar las barreras
Los procesadores con ejecución fuera de orden no se popularizaron hasta mediados de 1990 (con la introducción del procesador Power1) por la complejidad que significa. Las diferencias entre arquitecturas hicieron que cada una de ellas incluyese diferentes tipos de barreras por lo que no existen instrucciones estándares y mucho menos instrucciones espefícas en los lenguajes de programación de alto nivel.

Afortunadamente esos problemas los solucionan los _builtin macros_ de los compiladores, por ejemplo los de operaciones atómicas del compilador GCC: <<Atomics>>. El compilador define macros que usamos como funciones normales dentro del programa, luego el compilador inserta el código ensamblador correspondiente para cada arquitectura. Veréis que hay bastantes _macros atómicos_, algunos de ellas las analizaremos y usaremos en el siguiente capítulo, por ahora nos interesa el que inserta una barrera: ___sync_synchronize()_.

Lo único que debemos hacer es insertar la _llamada_ tal como en el siguiente fragmento de entrada a la sección crítica del código completo en C: <<counter_peterson_c>>.

[source,c]
----
void lock(int i) {
	int j =  (i + 1) % 2;

	states[i] = 1;
	turn = j;
	__sync_synchronize();
	while (states[j] && turn == j);
}
----

Y la ejecución si es correcta y lo que esperábamos:

----
$ time ./counter_peterson 
Counter value: 10000000 Expected: 10000000
real	0m0.616s
user	0m1.230s
sys	0m0.000s
----


En ese punto del programa el GCC las siguientes instrucciones para las diferentes arquitecturas:

.Intel 64 bits
----
	mfence
----

.Intel 32 bits
----

	lock orl	$0, (%esp)
----


.Arm de 32 bits (Raspberry Pi)
----
	mcr     p15, 0, r0, c7, c10, 5
----

<<<<


