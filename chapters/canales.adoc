[[channels]]
== Canales

Las construcciones de programación concurrente estudiadas hasta ahora (algoritmos, _spinlocks_, semáforos y monitores) requieren memoria compartida, ahora veremos otro donde no se comparte memoria sino que se pasa la información mediante _mensajes_. Los mensajes se envían atómicamente a través de canales, estos requieren de al menos un proceso remitente y un receptor.

Hay dos tipos de comunicaciones:

Comunicación sincrónica:: En este tipo de comunicación se requiere que ambos procesos estén sincronizados (_rendevouz_), el remitente se bloquea hasta que el receptor esté listo para recibir. Y viceversa, el receptor se bloquea hasta que el remitente envíe el mensaje.

Comunicación asincrónica:: Alternativamente se puede permitir que el remitente envíe el mensaje y continúe su ejecución sin esperar a que el receptor lo reciba. La comunicación asincrónica requiere que el canal tenga un _buffer_ para almacenar los mensajes (frecuentemente llamado buzón o _mailbox_). La capacidad del _buffer_ depende del canal de comunicación, si no hay receptores o estos consumen mensajes a menor ritmo con el tiempo el _buffer_ se llenará y hará que los remitentes se bloqueen.

Hay dos tipos de especificar el destinatario (_addressing_):

- Indentificando explícitamente al proceso receptor como en Erlang, se indica el _PID_ del receptor.

- Indentificando al canal, como en Go. El canal puede admitir operaciones de uno o varios procesos en cada extremo.

Además los canales pueden ser de tipo estático (como en Go) o de tipos dinámicos (como en Erlang). Los canales de comunicación pueden asegurar la entrega de mensajes en mismo orden de envío (canales FIFO) o pueden entregarlos en orden arbitrario. Unos pueden asegurar la recepción de cada mensaje (_reliable_, como es el caso de canales en sistemas de memoria compartida), otros pueden descartar mensajes (_best-effort_).

=== _CSP_

El concepto de canales como mecanismo de sincronización entre procesos fue introducido por Hoare en su artículo seminalfootnote:[De lectura muy recomendada, uno de los artículos de _ciencias de la computación_ que más me impactó. En solo doce páginas introduce y unifica formal y elegantemente conceptos importantes que dieron origen a varios lenguajes y tecnologías innovadoras.] _Communicating Sequential Processes_ (<<Hoare>>). En él definió un lenguaje formal, _CSP_, para describir la interacción entre procesos genéricos independientes -no comparten memoria- cuya única forma de comunicación y sincronización en el paso _mensajes_ a través de canales (_puertos_ en el original). La entrada de un proceso es la salida de otro proceso, ambos procesos se ejecutan en paralelo pero se sincronizarán en la entrada/salida. Definió dos operadores, +?+ para indicar la entrada de un proceso y +!+ para la salida.

Ejemplos:

Leer desde el proceso _XY_ y almacenarlo en el par de variables _x, y_:

    XY?(x, y)

Enviar el contenido de _x_ e _y_ al proceso _DIV_:

    DIV!(x, y)


El primer lenguaje que se desarrolló con este modelo fue Occam (1983) de David May (con la colaboración de Hoare) para INMOS, los fabricantes de los procesadores _Transputer_. Con el tiempo de diseñaron una rama de lenguajes siguiendo este modelo: Erlang (Armstrong, Virding y Williams, 1986), Newsqueak (Rob Pike, 1988), Concurrent ML (John Reppy, 1993),  Alef (Phil Winterbottom, 1995) y Limbo (Dorward, Pike y Winterbottom, 1996). Erlang es el que más éxito ha tenido y sigue siendo muy usado para sistemas concurrentesfootnote:[La mayoría de los lenguajes modernos tienen algún tipo de soporte de canales o sincronización por mensaje, si no es una construcción sintáctica del lenguaje lo hacen vía clases o librerías].

.Erlang
****
Erlang fue diseñado en Ericcson para sus sistemas con alta disponibilidad y concurrencia. No comparte estado entre los diferentes hilos de ejecución, como _CSP_ implementa canales con mensajes como única forma de comunicación. A diferencia de _CSP_, Erlang usa mensajes asincrónicos que se almacenan en _buzones_ desde donde son recogidos por la especificación de patrones en el receptor (similar a los _guard commands_ de Dijkstra, también parte de _CSP_). Por todas estas características se dice que Erlang sigue el modelo de _actores_ (<<Agha>>).
****

=== Canales en Go

En 2010 Google publicó la primera versión estable del lenguaje Go diseñado por Robert Griesemer, Rob Pike, y Ken Thompson. Go incluye dos mecanismos para facilitar la programación concurrente y la ejecución en paralelo en múltiples procesadores,

Hilos ligeros o _goroutines_:: Las llamadas a funciones precedidos por la instrucción +go+ hacen que éstas se ejecuten de forma asincrónica, como un hilo independiente. No son hilos nativos del sistema operativo sino una pequeña pila de tamaño variable gestionada y planificada (_scheduling_) internamente por las librerías _runtime_, su coste de creación es muy bajo. Independientemente de las _goroutines_ también puede crear hilos nativos para sacar provecho a los diferentes procesadores. El número de hilos nativos se define con +runtime.GOMAXPROCS+, la planificación y ejecución de las _goroutines_ en los diferentes hilos nativos se hace de forma automática y transparente al programador.


Canales:: Los canales son objetos de primer orden, pueden ser pasados como argumentos en funciones, _goroutines_ e incluso en mensajesfootnote:[Por ello se dice que Go también implementa el modelo _cálculo-π_.]. La implementación de canales está directamente inspirado de _CSP_ y con ideas ya usadas en Newsqueak y Limbo, diseñados también por Rob Pike. Por defecto los canales son sincrónicos como en _CSP_ pero también pueden ser asincrónicos definiendo un _buffer_ de tamaño mayor que cero (por defecto es cero). Los canales sin de tipo estático, se define el tipo cuando se crean, pueden ser tipos nativos o cualquier estructura o tipo definido por el programador. La operación de envío o recepción es mensajes es siempre del tipo +recipiente *<-* origen+, donde +recipiente+ y +origen+ pueden ser indistintamente canales o variables.

La siguiente línea crea un canal de tipo entero:

    ch := make(chan int)

El canal +ch+ tiene _buffer_ cero por lo que será un canal sincrónico, si se desea un canal asincrónico solo hay que especificar el tamaño del _buffer_ en el segundo argumento de +make+:

    ch := make(chan int, 256)

Enviar el contenido de una variable a un canal:

    ch <- message

Leer un mensaje de un canal y almacenarlo en la variable +message+:

    message = <- ch

Leer un mensaje de un canal y descartar su valor:

    <- ch

El anterior es el patrón de sincronización en los ejemplos en Go de capítulos anteriores con el canal +done+ para hacer que el programa principal espere por la la finalización de las _goroutines_:

[source, go]
----
func run(done chan bool) {
    ...
    done <- true
}

func main() {
    done := make()
    go run(done)
    <-done
}
----

Dado que ambos implementan variantes del model _CSP_ y gestionan los _hilos ligeros_ de forma muy similar, es inevitable -y habitual- la comparación entre Erlang y Go, pero ambos derivan de ramas históricas diferentes de _CSP_ y tienen algunas diferencias claves:

- En Erlang como en el _CSP_ originalfootnote:[Aunque Hoare planteó la alternativa atractiva (sic) aunque equivalente de nombrar o etiquetar a los canales.] se especifica al proceso receptor, en Go al canal. Cualquier proceso o número de estos puede recibir o enviar del mismo canal.

- En Erlang se puede enviar diferentes tipos de mensajes a cada proceso, estos se depositan en un _buzón_ y son recogidos según las reglas especificadas ( _guard commands_) en el receptor. Los canales en Go son de tipos estático y la entrega de mensajes es siempre en orden FIFO.

- Erlang sigue el modelo de _actores_, no se permite la compartición de memoria entre los diferentes hilos (_share nothing_ forzado). Aunque en Go se recomienda que toda compartición se haga mediante mensajes es posible compartir datos vía variables globales (como hemos visto en los ejemplo de capítuloes anteriores) o incluso pasando punteros en los mensajes.

El siguiente ejemplo de Erlang define una función anónima que recibe un mensaje y lo imprime. El programa crea un nuevo _hilo ligero_ con +spawn+ y almacena su identificación en +Pid+, posteriormente le envía el mensaje +Hello+ (con el símbolo +!+ como en _CSP_ original de Hoare):

[source, erlang]
----
Pid = spawn(fun() ->
          receive Message ->
            io:format("Message: ~s", [Message])
          end
      end).

Pid ! "Hello".
----

El siguiente es el programa equivalente en Go.

[source, go]
----
channel := make(chan string)
go func() {
    fmt.Println("Message:", <-channel)
}()

channel <- "Hello"
----

Los algoritmos son equivalentes, como lo son ambos lenguajes, la diferencias fundamentales son la especificación del destinario del mensaje y que en Erlang no hay que crear explícitamente el canal, cada proceso tiene un _buzón_ en el que reciben todos los mensajes.

=== Barreras

Las <<sync_barrier, barreras de sincronización>> nos servirán como ejemplo perfecto para aprender a usar los canales como mecanismos de sincronización.

==== Barreras binarias
Una <<sync_barrier, barrera>> para dos procesos es, al igual que con semáforos, un ejemplo sencillo para implementar con mensajes. Dos procesos, A y B, deben coordinarse. A no debe pasar de un punto hasta que B haya llegado, y viceversa. Con semáforos usamos dos para hacerlo, con camales es muy similar, necesitamos dos. La primera idea suele ser que cada proceso envíe un mensaje a su canal en cuanto llegue al punto de suncronización y luego esperar por la recepción de un mensaje del canal del otro proceso. Por ejemplo:

[source,go]
----
    ch_a = make(chan bool)
    ch_b = make(chan bool)

A                   B

...                 ...
ch_a <- true        cha_b <- true
<-ch_b              <-ch_a
...                 ...
----

El código anterior es erróneo, produce un interbloqueo, el _runtime_ de Go interrumpirá el programa completo y avisará del _deadlock_. Es un error habitual cuando no se tiene experiencia con sincronización con canales no tomar en cuenta que ambos canales son sincrónicos por lo que tanto +A+ como +B+ al intentar enviar el mensaje quedan bloqueados hasta que el otro pueda recibirlo. Pero <<railroad_quote, ninguno de ellos podrá continuar>> hasta que el otro haya recibido el mensaje.

El interbloqueo se produce por una razón muy similar a la que <<deadlock_philosophers, vimos con filósofos>>, se produce una espera circular. Para evitarla hay que hacer que las ejecuciones sean asimétricas, que uno de ellos reciba primero el mensaje del otro y luego envíe el propio. Por ejemplo (<<barrier_2p_sync_go, código>>):

[source,go]
----
A                   B

ch_a <- true        <-ch_a
<-ch_b              cha_b <- true
----

Para evitar las soluciones asimétricas hay que recurrir a canales asincrónicos para evitar que un proceso quede bloqueado cuando envíe el mensaje. Por defecto los canales tienen _buffer_ 0, por lo tanto son sincrónicos. Pero se puede especificar el tamaño del _buffer_, en ese caso es suficiente con tamaño 1 (<<barrier_2p_async_go, código>>):

[source,go]
----
    ch_a = make(chan bool, 1)
    ch_b = make(chan bool, 1)

A                   B

ch_a <- true        ch_b <- true
<-ch_b              <-ch_a
----

Como ambos canales ahora son asincrónicos y con _buffer_ de un elemento los procesos no se bloquearán si al enviar no hay ningún elemento. Desde el punto de vista de sincronización la idea es similar al valor de los semáforos. Si un semáforo vale cero bloqueará al primer _wait_, pero si es uno el proceso que haga el primer _wait_ podrá continuar (como se hace con los semáforos usados como _mutex_). En los ejmplos de sincronización de este capítulo y en aplicaciones reales se recurre mucho a usar sincrónicos o asincrónicos con _buffer_ de tamaño uno.

==== Barreras generales

Para este algoritmofootnote:[No sé si alguien lo diseñó o publicó antes, no lo he visto, lo escribí desde cero para este libro.] aprovecharemos las dos capacidades de los mensajes: sincronización y comunicación. En los soluciones con semáforos usábamos dos de ellos para llevar la cuenta de los procesos que faltaba por llegar a la meta y los que ya habían salido para comenzar la segunda fase. Usaremos también dos canales con el mismo objetivo pero no usaremos variables compartidas, el contador estará almacenado en un mensaje que se irá pasando entre los procesos, cada uno lo recogerá, actualizará y volverá a enviar (<<barrier_go, código>>).

Usaremos dos canales de tipo entero, +arrival+ y +departure+ y una variable +n+, esta última es estática, solo se inicializa con el número de procesos que se sincronizarán en con la barrera. Definimos la estructura +Barrier+ esos campos:


[source,go]
----
type Barrier struct {
    arrival   chan int
    departure chan int
    n         int
}
----

Y una función constructora que inicializará ambos canales y el valor de +n+:

[source,go]
----
func NewBarrier(value int) *Barrier {
    b := new(Barrier)
    b.arrival = make(chan int, 1)
    b.departure = make(chan int, 1)
    b.n = value

    b.arrival <- value  <1>
    return b
}
----
<1> Se deja un mensaje en el canal con el número de procesos que faltan por llegar.

Los dos canales tienen un _buffer_ de tamaño uno pero sólo uno de ellos, +arrival+, contiene un mensaje con el número de proceso que deben llegar, inicialmente el número de proceso que se sincronizarán. La función +Barrier+ tiene dos partes:

1. Llegadas: Se usa el canal +arrival+, inicialmente con un mensaje con el total de procesos que faltan por llegar. Cuando un proceso llega lee el mensaje, verifica el valor, si quedan procesos por llegar lo decrementa y vuelve a enviar el mensaje al mismo canal. Si es el último en llegar no depositará el mensaje en +arrival+ sino en +departure+ con el total de procesos que se sincronizan en la barrera.

2. Salidas: Los procesos que llegan intentan leer un mensaje de +departure+ y quedarán bloqueados hasta que llegue el último. Cuando éste deposite un mensaje podrá desbloquearse uno, verificará el valor, si quedan procesos por salir decrementará su valor y depositará nuevamente el mensaje +departure+ para que puedan continuar los demás. El último en salir enviará un mensaje a +arrival+ para que el ciclo vuelva a comenzar.


[source,go]
----
func (b *Barrier) Barrier() {
    var v int

    // part 1
    v = <-b.arrival         <1>
    if v > 1 {
        v--
        b.arrival <- v      <2>
    } else {
        b.departure <- b.n  <3>
    }

    // part 2
    v = <-b.departure       <4>
    if v > 1 {
        v--
        b.departure <- v    <5>
    } else {
        b.arrival <- b.n    <6>
    }
}
----
<1> Se bloquea hasta que puede leer un mensaje desde +arrival+, el mensaje contiene el número de procesos que quedan por llegar.
<2> Si todavía quedan procesos por llegar decrementa el contador y vuelve a poner el mensaje en +arrival+.
<3> Si llegaron todos deposita un mensaje en +departure+ para que los procesos puedan empezar a continuar la siguiente fase.
<4> Quedan bloqueados hasta que el último que llegue envíe un mensaje al canal.
<5> Si todavía quedan procesos por salir (bloqueados en +departure+) decrementa el contador y vuelve a poner el mensaje.
<6> Si llegaron todos pone el mensaje con el número inicial de procesos en el canal de llegada.

Como la recepción y envío son operaciones atómicas no hace falta recurrir a ningún método de exclusión mutua. Además como es un único mensaje los siguientes procesos quedarán bloqueados hasta que el anterior vuelva a depositar un mensaje en el canal.

=== Productores-consumidores

Los canales son inherentemente productores-consumidores, no hay que hacer nada especial. Los mensajes son los elementos que se añaden o quitan del _buffer_, éste está definido por el _buffer_ asignado al canal. Si el canal no tiene _buffer_ la comunicación es sincrónica, los productores siempre se bloquean hasta que un consumidor esté preparado para recibir. Si por el contrario se le asigna un buffer funciona exactamente como el modelo de productores-consumidores que resolvimos con semáforos o monitores.

La interacción es así de sencilla (<<producer_consumer_go, código>>):

[source,go]
----
    buffer := make(chan string, BufferSize)


func consumer() {
    for {
        element := <-buffer
        ...
    }
}

func producer() {
    for {
        element := produce()
        buffer <- element
    }
}
----

Si el buffer del canal está lleno los productores se bloquearan hasta que los productores eliminen mensajes. Si el canal está vacío los consumidores quedarán bloqueados hasta que los productores añadan nuevos elementos.

Este tipo de sincronización es muy útil y muy usada. Mientras que en otros lenguajes hay que implementar mecanismos basados en semáforos o monitores en los lenguajes basados en _CSP_ es una forma natural de interacción entre los diferentes procesos.

[[channels_mutex]]
=== Mutex

La implementación de un _mutex_ con mensajesfootnote:[El paquete +sync+ de Go tiene una implementación +Mutex+ que es más eficiente, usa los semáforos implementados a nivel de librería en el +runtime+ (https://golang.org/src/runtime/sema.go), el lenguaje implementa su propio _scheduler_ y usa técnicas de _spin/park_ similares a los usados por los monitores en la máquina virtual de Java.] también es muy sencilla (<<channel_mutex_go, código>>), inicialmente se crea un canal con capacidad 1 y se deposita un mensaje vacío (no hace falta compartir datos) que representa un _permiso_ para entrar a la sección crítica.

[source,go]
----
    m := make(Mutex, 1)
    m <- Empty{}
----

Para entrar a la sección crítica se lee del canal, como hay un mensaje en el _buffer_ podrá continuar inmediatamente, el siguiente proceso se bloqueará al no tener mensaje que recibir. El proceso que sale de la sección crítica deposita nuevamente un mensaje vacío que permitirá que entre otro o desbloqueará al primer proceso bloqueado.

[source,go]
----
func Lock() {
    <-m
}

func Unlock() {
    m <- Empty{}
}
----


Los canales también bloquean si se intenta enviar un mensaje y el _buffer_ está lleno. El algoritmo de exclusión mutua puede ser implementado a la inversa, un mensaje representaba a un _permiso_ pero se puede hacer que éste se represente por espacio libre en el _buffer_. En este caso no hace falta depositar un mensaje en la inicialización, en el _lock_ se envía un mensaje y en el _unlock_ se recibe.


[source,go]
----
    m := make(Mutex, 1)

func Lock() {
    m <- Empty{}
}

func Unlock() {
    <-m
}
----

=== Semáforos

Para semáforos generales se puede usar la misma idea que con la primera versión del _mutex_ (<<channel_semaphore_go, código>>), cada mensaje representa un permiso. Solo hace falta una cola a la que hay que iniciar con tantos mensajes como el valor inicial del semáforo:

[source,go]
----
func NewSem(value int) Sem {
    s := make(Sem, 256)
    for i := 0; i < value; i++ {
        s <- Empty{}
    }
    return s
}
----

La operación _wait_ simplemente lee un mensaje y _signal_ envía uno vacío:

[source, go]
----
func (s Sem) Wait() {
    <-s
}

func (s Sem) Signal() {
    s <- Empty{}
}
----

El problema con la solución anterior es la dimensión del _buffer_ del canal, su tamaño debe ser igual al número máximo de permisos del semáforo, es decir el valor máximo de su valor, caso contrario las operación de _signal_ también se bloquearían si se llena. Si no se requieren valores elevados es una solución razonable, si no hay que buscar otra solución que no requiera que la dimensión del canal dependa del valor del semáforo.

Una solución de este tipo requeriría, como en los algoritmos de barreras o productores-consumidores, de una cola para mantener un mensaje con el valor actual del semáforo (+value+) y otra cola para bloquear en _wait_ si el semáforo toma un valor negativo (+queue+). La solución no es muy diferente a la simulación de <<monitors_semaphores, semáforos con monitores>> o la implementación de un <<futex_semaphore, semáforo simple con FUTEX>>. En el primer caso usamos la cola de la variable de condición para bloquear a los procesos, en el segundo la cola del FUTEX. Para la siguiente solución usaremos el canal +queue+ para mantener a la cola de bloqueados.

La estructura e inicialización es la siguiente (<<channel_semaphore2_go, código>>):

[source, go]
----
type Sem struct {
    value chan int
    queue chan Empty
}

func NewSem(value int) Sem {
    var s Sem
    s.value = make(chan int, 1)
    s.queue = make(chan Empty)
    s.value <- value            <1>
    return s
}
----
<1> El canal +value+ se inicializa con un mensaje que almacena el valor del semáforo.

Los algoritmos de las operaciones _wait_ y _signal_ eson prácticamente idénticos a la <<semaphore_definition, definición de semáforos>>. La diferencia es que en vez de una variable compartida usamos un mensaje para almacenar el valor.

La función +Wait+ es lee el mensaje con el valor del semáforo, lo decrementa y vuelve a depositar el mensaje en el canal. Si el valor del semáforo es menor que cero se bloqueará en el canal +queue+ hasta que otro proceso haga un _signal_.

[source, go]
----
func (s Sem) Wait() {
    v := <-s.value
    v--
    s.value <- v
    if v < 0 {
        <-s.queue
    }
}
----

+Signal+ es la inversa, incrementa el valor del semáforo, si el resultado es menor o igual que cero hay procesos esperando un mensaje en el canal +queue+ por lo que enviará un mensaje para que se despierte el siguiente.

[source, go]
----
func (s Sem) Signal() {
    v := <-s.value
    v++
    s.value <- v
    if v <= 0 {
        s.queue <- Empty{}
    }
}
----

Puede parecer que aparecerán _condiciones de carrera_ porque el envío y recepción en +queue+ se hacen luego de enviar el mensaje pero si la variable local +v+ es menor que cero el proceso debe esperar un mensaje en +queue+. El proceso que hace el _signal_ espera que se haga así y enviará siempre el mensaje correspondiente.

Pero el algoritmo puede optimizarse con una breve modificación en el canal +queue+. Si un proceso en _wait_ ejecuta `s.value <- v` y se interrumpe, el proceso que hace el _signal_ se bloqueará momentáneamente en `s.queue <- Empty{}` porque el canal es sincrónico y no podrá continuar hasta que el primero ejecute `<-s.queue`. Se soluciona haciendo que el canal +queue+ tenga un _buffer_ pequeño, por ejemplo `s.queue = make(chan Empty)`. No cambia el algoritmo, sigue siendo correcto pero la diferencia es notablefootnote:[En el ejemplo de incrementar el contador los tiempos se reducen hasta cuatro veces.].


=== Filósofos cenando
La solución natural con canales asincrónicos es definir un array de tantos canales como tenedores (<<channel_philosophers_go, código>>), en la inicialización se deposita un mensaje en cada uno de ellos indicando su disponibilidad:

[source, go]
----
var forks [Philosophers]chan Empty

for i := range forks {
    forks[i] = make(chan Empty, 1)
    forks[i] <- Empty{}
}
----

Para tomar los tenedores cada filósofo lee de sus canales correspondientes. Si el tenedor está disponible habrá un mensaje y podrá continuar, caso contrario se quedará bloqueado hasta que sea liberado. Para evitar el interbloqueo (ya analizados en la <<dining_philosophers, solución con semáforos>>) evitamos la espera circular haciendo que siempre se tome primero el tenedor con el menor identificador:


[source,go]
----
func pick(id int) {
    if id < right(id) {
        <-forks[id]
        <-forks[right(id)]
    } else {
        <-forks[right(id)]
        <-forks[id]
    }
}
----

Para liberar los tenedores es suficiente con enviar un mensaje a sus canales. Si hay otros filósofos esperando por ello se desbloquearán, si no quedarán almacenados en el _buffer_.

[source, go]
----
func release(id int) {
    forks[id] <- Empty{}
    forks[right(id)] <- Empty{}
}
----

==== Con canales sincrónicos

El algoritmo anterior solo funciona con canales asincrónicos, de no ser así ni la inicialización funcionaría porque se bloquearía al ejecutar el primer `forks[i] <- Empty{}` . En el modelo _CSP_ (<<Hoare>>) los canales son sincrónicos y Hoare propuso una soluciónfootnote:[Aunque produce interbloqueo, lo avisa en el mismo artículo.].

[[philosophers_hoare]]
.Filósofos en _CSP_
image::hoare_philosophers.png[height="180", align="center"]

La solución es en realidad muy sencilla (<<channel_philosophers_sync_go, código>>), hay que hacer como propone el modelo _CSP_, crear un proceso adicional para cada tenedor (+fork+). Los filósofos no requieren de ningún cambio en su algoritmo. Cada proceso +fork+ no requiere de ninguna computación adicional, solo recibe y envía mensajes por el canal correspondiente a su tenedor:

.Proceso para el tenedor _i_
[source,go]
----
func fork(i int) {
    for {
        forks[i] <- Empty{}
        <-forks[i]
    }
}
----

[NOTE]
====
Al tratarse de canales sincrónicos se puede invertir el orden de envío y recepción de mensajes, para tomar los tenedores los filósofos enviarán un mensaje y al soltarlos reciben uno. El proceso +fork+ debe invertir también sus operaciones:

    for {
        forks[i] <- Empty{}
        <-forks[i]
    }

De esta forma -es equivalente- el programa queda idéntico a la solucion propuesta por Hoare con CSP (<<philosophers_hoare>>).
====

Los procesos comunicados por canales asincrónicos pueden ser convertidos, tal como acabamos de hacer, a uno equivalente con canales sincrónicos. La solución general es añadir nuevos procesos que suplanten las capacidades de los canales con buffer. En el caso de los filósofos fue añadir un nuevo proceso para cada tenedor para convertirlo en una comunicaciones entre procesos _filósofos_ y otros _tenedores_, tal como propone el modelo _CSP_.

Todos los algoritmos de este capítulo que requieren de canales con _buffer_ pueden ser adaptados para funcionar con sincrónicos. Por ejemplo, para el <<channel_mutex_go, código>> de simulación de _mutex_ se requieren muy pocos cambios. La función [pseudo] constructora del +Mutex+ con canales asincrónicos crea un canal con _buffer_ 1 y deposita un mensaje:


[source,go]
----
func NewMutex() Mutex {
    m := make(Mutex, 1)
    m <- Empty{}
    return m
}
----

Dado que no podemos hacerlo con canales sincrónicos se requiere otro proceso que actúe de forma similar al +fork+ de los filósofos. Se puede hacer que el propio constructor inicie el nuevo proceso sin necesidad de modificar la implementación de las otras funciones (<<channel_mutex_sync_go, código completo>>):footnote:[Uso función anónima con clausura, de lectura y comprensión más sencilla.]

[source,go]
----
func NewMutex() Mutex {
    m := make(Mutex)
    go func() {         <1>
        for {
            m <- Empty{}
            <-m
        }
    }()
    return m
}
----
<1> Se lanza una _goroutine_, la función es anónima y aprovecha de la clausura para hacer referencia al mismo canal +m+.

==== Solución óptima
La solución anterior (ya la analizamos <<dining_philosophers_semaphores, con semáforos>>) no asegura que puedan comer todos los filósofos que podrían hacerlo. Se puede implementar una solución óptima similar a la de semáforos pero adaptada a canales (<<channel_philosophers_provider_go, código completo>>).

En vez de solicitar los tenedores individualmente habrá un proceso _proveedor_ (+provider+) para toda la mesa, este proceso tendrá un único canal (sincrónico) para recibir los mensajes de todos los filósofos. Estos le enviarán mensajes indicando si quieren tomar o soltar los tenedores. El proveedor verificará el estado de los filósofos vecinos, si ambos palillos están libres le responderá con un mensaje para que continúe. Si alguno de sus vecinos está comiendo no le responderá inmediatamente sino cuando sus vecinos hayan dejado de comer.

El mensaje de filósofos al proveedor será una estructura que indicará el índice el filósofo, el estado (+Hungry+ si desea comer y +Thinking+ si es para liberar los palillos) y el canal individual del filósofo (también sincrónico) para recibir la respuesta del proveedorfootnote:[Go permite enviar descriptores de canales en los mensajes por lo que no hace falta que estos sean parte del estado global, cada filósofo crea el suyo y lo pasa el proveedor en el mensaje.].

[source, go]
----
type Request struct {
    id     int
    status int
    c      chan Empty
}
----

Cuando un filósofo desea comer envía un mensaje al canal del proveedor con su identificación (+i+), su propio canal (+myCh+) y el estado +Hungry+. A continuación espera la respuesta del proveedor en su canal.

[source, go]
----
provider <- Request{id: i, c: myCh, status: Hungry}

<-myCh
----

Cuando libera los palillos envía otro mensaje similar pero con el estado +Thinking+.

[source, go]
----
provider <- Request{id: i, c: myCh, status: Thinking}
----

El proveedor mantiene un array que mantiene el estado de los filósofos y su canal de comunicación. Inicialmente cada posición es una copia de la estructura +Request+ que recibió en el mensaje. El proceso está en un bucle infinito recibiendo mensajes desde su canal +provider+. Cuando recibe un mensaje lo copia al array de estado y verifica el estado, si es +Hungry+ llama a la función +canEat+, esta función responderá con un mensaje al canal del filósofo si puede comer. Si el estado es +Thinking+ significa que deja los tenedores por lo que se llama a la función +canEat+, una vez para cada vecino por si querían comer y están esperando.

[source, go]
----
for {
    m := <-provider
    philo[m.id] = m
    switch m.status {
    case Hungry:
        canEat(m.id)
    case Thinking:
        canEat(left(m.id))
        canEat(right(m.id))
    }
}
----

La función +canEat+ es idéntica a la de la solución óptima con semáforosfootnote:[De nuevo aparecen las similitudes de sincronización entre semáforos y canales.] (<<philosophers_2_py, código Python>>) sólo que en vez de señalizar un semáforo responde con un mensaje al canal del filósofo. La función verifica el estado de los vecinos a izquierda y derecha del filósofo indicado en el argumento (+i+), si ninguno de los vecinos está comiendo entonces le permite continuar enviando un mensaje al canal correspondiente.

[source, go]
----
func canEat(i int) {
    r := right(i)
    l := left(i)
    if philo[i].status == Hungry &&
        philo[l].status != Eating &&
        philo[r].status != Eating {
        philo[i].status = Eating
        philo[i].c <- Empty{}
    }
}
----



////
π calculus
////


////
gofmt  -w -tabs=false -tabwidth=4


http://www.slideshare.net/dabeaz/an-introduction-to-python-concurrency (para ver lo de mensajes)
////
