[[channels]]
== Canales

Todas las construcciones de programación concurrente de capítulos anteriores -algoritmos, _spinlocks_, semáforos y monitores- requieren y solo sirven para sistemas de memoria compartida. Los canales no tienen este requisito, además de sincronización sirven para comunicación entre procesos mediante el intercambio de _mensajes_. Estos se envían a través de las operaciones atómicas _send_ y _receive_ entre procesos remitentes (_sources_) y receptores (_receivers_).

Según el comportamiento de las operaciones _send_ y _receive_ se definen dos tipos de comunicaciones:

Comunicación sincrónica:: En este tipo de comunicación se requiere que ambos procesos estén sincronizados (_rendevouz_), el remitente se bloquea en el _send_ hasta que el receptor esté listo para recibir. Y viceversa, el receptor se bloquea hasta que el remitente envíe el mensaje.

Comunicación asincrónica:: Alternativamente se puede permitir que el remitente envíe el mensaje y continúe su ejecución sin esperar a que el receptor lo reciba. La comunicación asincrónica requiere que el canal tenga un _buffer_ para almacenar los mensajes (también llamado buzón o _mailbox_). La capacidad del _buffer_ depende del canal de comunicación, si no hay receptores o estos consumen mensajes a menor ritmo el _buffer_ acabará llenándose y hará que los remitentes se bloqueen.

Aunque hay sistemas con canales que admiten _multidifusión_ (_broadcast_) en general los mensajes tienen destinatarios, hay dos formas básicas de especificar a los receptores (_addressing_):

- Indentificando explícitamente al proceso receptor, como en Erlang donde se indica el _PID_ del receptor.

- Indentificando al canal. En estos casos el canal puede admitir solo un remitente y receptor (también llamado _pipe_, un servicio estándar en Unix) o no poner restricciones al número de procesos en cada extremo (como en Go).

Los canales pueden ser de tipo estático (como en Go) o de tipos dinámicos (como en Erlang). Los canales de comunicación pueden asegurar la entrega de mensajes en mismo orden de envío (canales FIFO) o pueden entregarlos en orden arbitrario. Unos pueden asegurar la recepción de cada mensaje (_reliable_, lo habitual en sistemas de memoria compartida), otros pueden descartar mensajes (_best-effort_) por errores de transmisión.

=== _CSP_

El concepto de canales como mecanismo de sincronización entre procesos fue introducido por Hoare en su artículo seminalfootnote:[De lectura muy recomendada, uno de los artículos de _ciencias de la computación_ más relevantes. En solo doce páginas introduce y unifica formal y elegantemente conceptos importantes que dieron origen a varios lenguajes y tecnologías innovadoras.] _Communicating Sequential Processes_ (<<Hoare>>). En él definió un modelos formal, _CSP_, para describir la interacción entre procesos genéricos independientes -no comparten memoria- cuya única forma de comunicación y sincronización en el intercambio de _mensajes_. La entrada de un proceso es la salida de otro proceso, ambos procesos se ejecutan asoncrónicamente y posiblemente en paralelo pero se sincronizarán en la entrada/salida. _CSP_ define dos operadores entre procesos, +?+ para indicar la entrada de un proceso (equivalente a _receive_) y +!+ para la salida (_send_).

Ejemplos:

Leer desde el proceso _XY_ y almacenar el contenido en las variables _x, y_:

    XY?(x, y)

Enviar el contenido de _x_ e _y_ al proceso _DIV_:

    DIV!(x, y)


El primer lenguaje que se desarrolló con este modelo fue occam (1983) de David May (con la colaboración de Hoare) para INMOS, los fabricantes de los procesadores _Transputer_. Con el tiempo de diseñaron una rama de lenguajes siguiendo este modelo: Erlang (Armstrong, Virding y Williams, 1986), Newsqueak (Rob Pike, 1988), Concurrent ML (John Reppy, 1993),  Alef (Phil Winterbottom, 1995) y Limbo (Dorward, Pike y Winterbottom, 1996). Erlang es el que más éxito ha tenido y sigue siendo muy usado para sistemas concurrentesfootnote:[La mayoría de los lenguajes modernos tienen algún tipo de soporte de canales o sincronización por mensaje, si no es una construcción sintáctica del lenguaje lo hacen vía clases o librerías].

.Erlang
****
Erlang fue diseñado en Ericcson para sus sistemas concurrentes de alta disponibilidad. No comparte estado entre los diferentes hilos de ejecución, como _CSP_ implementa canales con mensajes como única forma de comunicación. La comunicación en Erlang es asincrónica, los mensajes se depositan en _buzones_ desde donde son recogidos por la especificación de patrones en el receptor (similar a los _guard commands_ de Dijkstra, también parte de _CSP_). Por todas estas características se dice que Erlang sigue el modelo de _actores_ (<<Agha>>).
****

=== Canales en Go
En 2010 Google publicó la primera versión estable del lenguaje Go diseñado por Robert Griesemer, Rob Pike, y Ken Thompson. Go incluye dos mecanismos para facilitar la programación concurrente y la ejecución en paralelo en múltiples procesadores,

[NOTE]
====
Go es un lenguaje libre, moderno, implementa el modelo _CSP_ con canales, sus operaciones y la creación de hilos ligeros son construcciones sintácticas. Ademas permite la ejecución en paralelo especificando cuántos hilos nativos del sistema operativo (_threads_) pueden crearse. Estas características favorecen la especificación compacta y legible de los algoritmos que estudiaremos en este capítulo, por ello todos los ejemplos están en Go.
====

Hilos ligeros (o _green threads_):: Las llamadas a funciones precedidos por la instrucción +go+ -llamadas _goroutines_- hacen que éstas se ejecuten de forma asincrónica, como un hilo independiente. No son hilos nativos del sistema operativo sino una pequeña pila de tamaño variable gestionada y planificada (_scheduling_) internamente por las librerías _runtime_, su coste de creación es muy bajo. Independientemente de las _goroutines_ también puede crear hilos nativos para ejecución en paralelo. El número de hilos nativos se define con +runtime.GOMAXPROCS+, la planificación y ejecución de las _goroutines_ en los diferentes hilos nativos se hace de forma automática y transparente al programador.


Canales:: Los canales son objetos de primer orden, pueden ser pasados como argumentos en funciones, _goroutines_ y hasta en mensajesfootnote:[Por ello se dice que Go también implementa el modelo _cálculo-π_.]. La implementación de canales está directamente inspirado de _CSP_ y con ideas ya usadas en Newsqueak y Limbo, diseñados también por Rob Pike. Por defecto los canales son sincrónicos como en _CSP_ pero también pueden ser asincrónicos si se les especifica un tamaño de _buffer_ mayor que cero. Los canales son de tipo estático definidos al momento de su creación, pueden ser tipos nativos o cualquier estructura o tipo definido por el programador. La operación de envío o recepción es mensajes es siempre de la forma +recipiente *<-* origen+, donde +recipiente+ y +origen+ pueden ser indistintamente canales o variables.

La siguiente línea crea un canal de tipo entero:

    ch := make(chan int)

El canal +ch+ tiene _buffer_ cero por lo que será un canal sincrónico, si se desea un canal asincrónico solo hay que especificar el tamaño del _buffer_ en el segundo argumento de +make+:

    ch := make(chan int, 256)

Enviar el contenido de una variable a un canal:

    ch <- message

Leer un mensaje de un canal y almacenarlo en la variable +message+:

    message = <-ch

Leer un mensaje de un canal y descartar su valor:

    <-ch

En los ejemplos en Go de capítulos anteriores se usó el patron anterior con el canal +done+ para hacer que el programa principal espere por la finalización de las _goroutines_:

[source, go]
----
func run(done chan bool) {
    ...
    done <- true
}

func main() {
    done := make()
    go run(done)
    <-done
}
----

Dado que ambos implementan variantes del model _CSP_ y gestionan los _hilos ligeros_ de forma muy similar, es inevitable -y habitual- la comparación entre Erlang y Go. Aunque implementan el modelo _CSP_ derivan de ramas históricas diferentes, sus diferencias claves son:

- En Erlang como en _CSP_ originalfootnote:[Aunque Hoare planteó la alternativa atractiva (sic) aunque equivalente de nombrar o etiquetar a los canales.] se especifica al proceso receptor, en Go al canal. Cualquier proceso o número de estos puede recibir o enviar del mismo canal.

- En Erlang se pueden enviar diferentes tipos de mensajes a cada proceso, estos se depositan en un buzón y son recogidos según las reglas especificadas (_guard commands_) en el receptor. Los canales en Go son de tipos estático y la entrega de mensajes es siempre en orden FIFO.

- Erlang sigue el modelo de _actores_, no se permite la compartición de memoria entre los diferentes hilos (_share nothing_ forzado). Aunque en Go se recomienda que toda compartición se haga mediante mensajes es posible compartir datos vía variables globales (como hemos visto en los ejemplo de capítuloes anteriores) o incluso pasando punteros en los mensajes.

El siguiente ejemplo de Erlang define una función anónima que recibe un mensaje y lo imprime. El programa crea un nuevo hilo ligero con +spawn+ y almacena su identificación en +Pid+, posteriormente le envía el mensaje +Hello+ (con el símbolo +!+ como en _CSP_ original de Hoare):

[source, erlang]
----
Pid = spawn(fun() ->
          receive Message ->
            io:format("Message: ~s", [Message])
          end
      end).

Pid ! "Hello".
----

El siguiente es el programa equivalente en Go.

[source, go]
----
channel := make(chan string)
go func() {
    fmt.Println("Message:", <-channel)
}()

channel <- "Hello"
----

Los programas son equivalentes y muy similares, las diferencias fundamentales son la especificación del destinario del mensaje y que en Erlang no hace falta la creación explícita del canal.

=== Barreras

Las <<sync_barrier, barreras de sincronización>> son un buen ejemplo para introducir el uso de canales como mecanismos de sincronización.

==== Barreras binarias
Una <<sync_barrier, barrera>> para dos procesos es, al igual que con semáforos, un ejemplo sencillo para implementar con mensajes. Dos procesos, _A_ y _B_, deben coordinarse. _A_ no debe pasar de un punto hasta que _B_ haya llegado, y viceversa. Con semáforos usamos dos para hacerlo, con canales es similar, necesitamos dos. La primera idea suele ser que cada proceso envíe un mensaje a su canal en cuanto llegue al punto de suncronización y luego esperar por la recepción de un mensaje del canal del otro proceso. Por ejemplo:

[source,go]
----
    ch_a = make(chan bool)
    ch_b = make(chan bool)

A                   B

...                 ...
ch_a <- true        cha_b <- true
<-ch_b              <-ch_a
...                 ...
----

El código anterior es erróneo, produce un interbloqueo, el _runtime_ de Go interrumpirá el programa completo y avisará del _deadlock_. Es un error habitual cuando no se tiene experiencia con sincronización con canales: no tomar en cuenta que ambos canales son sincrónicos por lo que tanto _A_ como _B_ se bloquean al enviar el mensaje y ninguno de ellos podrá continuar hasta que el otro haya recibido el mensaje (<<railroad_quote>>).

El interbloqueo se produce la espera circular, muy similar a la que analizamos con el interbloqueo de los filósofos (<<deadlocks>>). Se puede evitar haciendo que las operaciones no sigan el mismo orden, uno de los procesos recibe primero el mensaje del otro y luego envíe el propio. Por ejemplo (<<barrier_2p_sync_go, código>>):

[source,go]
----
A                   B

ch_a <- true        <-ch_a
<-ch_b              cha_b <- true
----

Para evitar las soluciones asimétricas hay que recurrir a canales asincrónicos. Por defecto los canales tienen _buffer_ 0, por lo tanto son sincrónicos. Pero se puede especificar el tamaño del _buffer_, en ese caso es suficiente con tamaño 1 (<<barrier_2p_async_go, código>>):

[source,go]
----
    ch_a = make(chan bool, 1)
    ch_b = make(chan bool, 1)

A                   B

ch_a <- true        ch_b <- true
<-ch_b              <-ch_a
----

Como ambos canales ahora son asincrónicos y con _buffer_ de un elemento los procesos no se bloquearán si al enviar no hay ningún elemento. Desde el punto de vista de sincronización la idea es similar al valor o _número de permisos_ de los semáforos. Si un semáforo vale cero bloqueará al primer _wait_, pero si es uno el proceso que haga el primer _wait_ podrá continuar (como se hace con los semáforos usados como _mutex_). En los ejemplos de sincronización de este capítulo -y en aplicaciones reales- es habitual recurrir a canales sincrónicos o asincrónicos con _buffer_ de tamaño uno.

==== Barreras generales

Para este algoritmofootnote:[No sé si alguien lo diseñó o publicó antes, no lo he visto, lo escribí desde cero para este libro.] aprovecharemos las dos capacidades de los mensajes: sincronización y comunicación. En los soluciones con semáforos usábamos dos de ellos para contabilizar los procesos que faltan por llegar a la meta y los que ya habían salido para comenzar la siguiente fase. También usaremos dos canales con el mismo objetivo pero en vez de variables compartidas -sujetas a los problemas de condiciones de carrera- el contador estará almacenado en un mensaje que se irá copiando entre procesos, cada uno lo recogerá, actualizará y volverá a enviar (<<barrier_go, código>>).

Se requieren dos canales de tipo entero, +arrival+ y +departure+, y una variable +n+, esta última es estática, solo se inicializa con el número de procesos que se sincronizarán en con la barrera. Definimos la estructura +Barrier+ con estos tres components:


[source,go]
----
type Barrier struct {
    arrival   chan int
    departure chan int
    n         int
}
----

Y una función constructora que inicializará ambos canales y el valor de +n+:

[source,go]
----
func NewBarrier(value int) *Barrier {
    b := new(Barrier)
    b.arrival = make(chan int, 1)
    b.departure = make(chan int, 1)
    b.n = value

    b.arrival <- value  <1>
    return b
}
----
<1> Se deja un mensaje en el canal con el número de procesos que faltan por llegar.

Los dos canales tienen _buffer_ de tamaño uno pero sólo uno de ellos, +arrival+, contiene un mensaje con el número de procesos que deben sincronizarse. La función de sincronización +Barrier+ tiene dos partes bien diferenciadas:

1. Llegadas: Se opera sobre el canal +arrival+, inicialmente con un mensaje con el total de procesos que faltan por llegar. Cuando un proceso llega recibe el mensaje, verifica el valor, si quedan procesos por llegar lo decrementa y vuelve a enviar el mensaje al mismo canal. Si es el último en llegar no depositará el mensaje en +arrival+ sino en +departure+ con el total de procesos que se sincronizan en la barrera.

2. Salidas: Los procesos que llegan intentan leer un mensaje de +departure+ y quedarán bloqueados hasta que llegue el último. Cuando éste deposite un mensaje se despertará uno de los bloqueados y verificará el valor, si quedan procesos por salir decrementará su valor y depositará nuevamente el mensaje +departure+ para que puedan continuar los demás. El último en salir enviará un mensaje a +arrival+ para que el ciclo vuelva a comenzar.


[source,go]
----
func (b *Barrier) Barrier() {
    var v int

    // part 1
    v = <-b.arrival         <1>
    if v > 1 {
        v--
        b.arrival <- v      <2>
    } else {
        b.departure <- b.n  <3>
    }

    // part 2
    v = <-b.departure       <4>
    if v > 1 {
        v--
        b.departure <- v    <5>
    } else {
        b.arrival <- b.n    <6>
    }
}
----
<1> Se bloquea hasta que puede leer un mensaje desde +arrival+, el mensaje contiene el número de procesos que quedan por llegar.
<2> Si todavía quedan procesos por llegar decrementa el contador y vuelve a poner el mensaje en +arrival+.
<3> Si llegaron todos deposita un mensaje en +departure+ para que los procesos puedan empezar a continuar la siguiente fase.
<4> Quedan bloqueados hasta que el último que llegue envíe un mensaje al canal.
<5> Si todavía quedan procesos por salir (bloqueados en +departure+) decrementa el contador y vuelve a poner el mensaje.
<6> Si llegaron todos pone el mensaje con el número inicial de procesos en el canal de llegada.

Como la recepción y envío son operaciones atómicas no hace falta recurrir a ningún método de exclusión mutua. Además, como es un único mensaje los siguientes procesos quedarán bloqueados hasta que el anterior vuelva a depositar un mensaje en el canal lo que asegura  que no se produzcan condiciones de carrera como ocurre con variables compartidas (hace falta asegurar exclusión mutua explícitamente).

=== Productores-consumidores

Los canales son productores-consumidores por diseño, no hay que hacer nada especial. Los mensajes son los elementos que se añaden o quitan del _buffer_, éste está definido por el _buffer_ asignado al canal. Si el canal no tiene _buffer_ la comunicación es sincrónica, los productores siempre se bloquean hasta que un consumidor esté preparado para recibir. Si por el contrario se le asigna un buffer funciona exactamente como el modelo de productores-consumidores que resolvimos con semáforos o monitores.

La interacción es así de sencilla (<<producer_consumer_go, código>>):

[source,go]
----
    buffer := make(chan string, BufferSize)

func consumer() {
    for {
        element := <-buffer
        ...
    }
}

func producer() {
    for {
        element := produce()
        buffer <- element
    }
}
----

Si el buffer del canal está lleno los productores se bloquearan hasta que los productores eliminen mensajes. Si el canal está vacío los consumidores quedarán bloqueados hasta que los productores añadan nuevos elementos.

Este tipo de sincronización es muy útil. Mientras en otros lenguajes hay que implementar mecanismos basados en semáforos o monitores, en los lenguajes basados en _CSP_ es una forma natural de interacción entre procesos.

[[channels_mutex]]
=== Mutex
La implementación de _mutex_ con mensajesfootnote:[El paquete +sync+ de Go tiene una implementación +Mutex+ que es más eficiente, usa los semáforos implementados a nivel de librería en el +runtime+ (https://golang.org/src/runtime/sema.go), el lenguaje implementa su propio _scheduler_ y usa técnicas de _spin/park_ similares a los usados por los monitores en la máquina virtual de Java.] también es sencilla (<<channel_mutex_go, código>>), inicialmente se crea un canal con capacidad 1 y se deposita un mensaje vacío (no hace falta compartir datos) que representa un _permiso_ para entrar a la sección crítica.

[source,go]
----
    m := make(Mutex, 1)
    m <- Empty{}
----

En la entrada de la sección crítica se lee del canal, como hay un mensaje en el _buffer_ podrá continuar inmediatamente, el siguiente proceso se bloqueará al no tener mensaje que recibir. El proceso que sale de la sección crítica deposita nuevamente un mensaje vacío que permitirá que entre otro o desbloqueará al primer proceso bloqueado.

[source,go]
----
func Lock() {
    <-m
}

func Unlock() {
    m <- Empty{}
}
----


Los canales también bloquean si se intenta enviar un mensaje y el _buffer_ está lleno. El algoritmo de exclusión mutua puede ser implementado a la inversa, un mensaje representaba a un _permiso_ pero se puede hacer que éste se represente por espacio libre en el _buffer_. En este caso no hace falta depositar un mensaje en la inicialización, en el _lock_ se envía un mensaje y en el _unlock_ se recibe.


[source,go]
----
    m := make(Mutex, 1)

func Lock() {
    m <- Empty{}
}

func Unlock() {
    <-m
}
----

=== Semáforos

Para semáforos generales se puede usar la misma idea que con la primera versión anterior de _mutex_ (<<channel_semaphore_go, código>>), cada mensaje representa un permiso. Solo hace falta una cola a la que hay que iniciar con tantos mensajes como el valor inicial del semáforo:

[source,go]
----
func NewSem(value int) Sem {
    s := make(Sem, 256)
    for i := 0; i < value; i++ {
        s <- Empty{}
    }
    return s
}
----

La operación _wait_ lee un mensaje y _signal_ envía uno vacío:

[source, go]
----
func (s Sem) Wait() {
    <-s
}

func (s Sem) Signal() {
    s <- Empty{}
}
----

El problema de esta solución es la dimensión del _buffer_ del canal, su tamaño debe ser igual al número máximo de permisos del semáforo (el valor máximo de su valor), de lo contrario las operaciones _signal_ también se bloquearán si está lleno. Si no se requieren valores elevados es una solución razonable, si no es así hay que buscar otra solución que no requiera que la dimensión del canal dependa del valor del semáforo.

Una solución de este tipo requeriría, como en los algoritmos de barreras o productores-consumidores, de una cola para mantener un mensaje con el valor actual del semáforo (+value+) y otra cola para bloquear en _wait_ si el semáforo toma un valor negativo (+queue+). La solución no es muy diferente a la simulación de <<monitors_semaphores, semáforos con monitores>> o la implementación del <<futex_semaphore, semáforo con FUTEX>>. En el primer caso usamos la cola de la variable de condición para bloquear a los procesos, en el segundo la cola del FUTEX. Para la siguiente solución usaremos el canal +queue+ para mantener la cola de bloqueados.

La estructura e inicialización es la siguiente (<<channel_semaphore2_go, código>>):

[source, go]
----
type Sem struct {
    value chan int
    queue chan Empty
}

func NewSem(value int) Sem {
    var s Sem
    s.value = make(chan int, 1)
    s.queue = make(chan Empty)
    s.value <- value            <1>
    return s
}
----
<1> El canal +value+ se inicializa con un mensaje que almacena el valor del semáforo.

Los algoritmos de las operaciones _wait_ y _signal_ son prácticamente idénticos a la <<semaphore_definition, definición>> de semáforos. La diferencia es que en vez de una variable compartida usamos un mensaje para almacenar el valor.

La función +Wait+ lee el mensaje con el valor del semáforo, lo decrementa y vuelve a depositar el mensaje en el canal. Si el valor del semáforo es menor que cero se bloqueará en el canal +queue+ hasta que otro proceso haga un _signal_.

[source, go]
----
func (s Sem) Wait() {
    v := <-s.value
    v--
    s.value <- v
    if v < 0 {
        <-s.queue
    }
}
----

+Signal+ es la inversa, incrementa el valor del semáforo, si el resultado es menor o igual que cero hay procesos esperando un mensaje en el canal +queue+ por lo que enviará un mensaje para que se despierte el siguiente.

[source, go]
----
func (s Sem) Signal() {
    v := <-s.value
    v++
    s.value <- v
    if v <= 0 {
        s.queue <- Empty{}
    }
}
----

Puede parecer que aparecerán _condiciones de carrera_ porque el envío y recepción en +queue+ se hacen luego de enviar el mensaje pero no existe ese problema. Si al llamar al _wait_ la variable local +v+ es menor que cero el proceso obligatoriamente debe esperar un mensaje (en +queue+). El de _signal_ espera que se haga así y enviará siempre el mensaje correspondiente.

Pero el algoritmo puede optimizarse con una breve modificación en el canal +queue+. Si un proceso en _wait_ ejecuta `s.value <- v` y se interrumpe, el proceso que hace el _signal_ se bloqueará momentáneamente en `s.queue <- Empty{}`, el canal es sincrónico y no podrá continuar hasta que el primero ejecute `<-s.queue`. Se soluciona haciendo que el canal +queue+ tenga un _buffer_ pequeño, por ejemplo `s.queue = make(chan Empty, 1)`. No cambia el algoritmo, sigue siendo correcto pero la diferencia es notablefootnote:[En el ejemplo de incrementar el contador los tiempos se reducen hasta cuatro veces.].


=== Filósofos cenando
La solución natural con canales asincrónicos es definir un array de tantos canales como tenedores (<<channel_philosophers_go, código>>), en la inicialización se deposita un mensaje en cada uno de ellos indicando su disponibilidad:

[source, go]
----
var forks [Philosophers]chan Empty

for i := range forks {
    forks[i] = make(chan Empty, 1)
    forks[i] <- Empty{}
}
----

Para tomar los tenedores cada filósofo lee de sus canales correspondientes. Si el tenedor está disponible habrá un mensaje y podrá continuar, caso contrario se quedará bloqueado hasta que sea liberado. Para evitar el interbloqueo (ya analizados en la <<dining_philosophers, solución con semáforos>>) evitamos la espera circular haciendo que siempre se tome primero el tenedor con el menor identificador y luego el de mayor:


[source,go]
----
func pick(id int) {
    if id < right(id) {
        <-forks[id]
        <-forks[right(id)]
    } else {
        <-forks[right(id)]
        <-forks[id]
    }
}
----

Para liberar los tenedores es suficiente con enviar un mensaje a sus canales correspondientes. Si otros filósofos están esperando se desbloquearán, si no quedarán almacenados en el _buffer_.

[source, go]
----
func release(id int) {
    forks[id] <- Empty{}
    forks[right(id)] <- Empty{}
}
----

==== Con canales sincrónicos

El algoritmo anterior solo funciona con canales asincrónicos, de no ser así ni siquiera la inicialización funcionaría porque se bloquearía al ejecutar el primer `forks[i] <- Empty{}` . En el modelo _CSP_ los canales son sincrónicos y Hoare propuso una solución correctafootnote:[Aunque produce interbloqueo, lo avisa en el mismo artículo.].

[[philosophers_hoare]]
.Filósofos en _CSP_
image::hoare_philosophers.png[height="180", align="center"]

La solución es más sencilla de lo que parece (<<channel_philosophers_sync_go, código>>), hay que hacer como se propone en el modelo _CSP_, crear un proceso adicional para cada tenedor (+fork+), los filósofos no requieren de ningún cambio en su algoritmo. Cada proceso +fork+ no requiere de ninguna computación adicional, solo recibe y envía mensajes por el canal correspondiente a su tenedor:

.Proceso para el tenedor _i_
[source,go]
----
func fork(i int) {
    for {
        forks[i] <- Empty{}
        <-forks[i]
    }
}
----

[NOTE]
====
Al tratarse de canales sincrónicos se puede invertir el orden de envío y recepción de mensajes, para tomar los tenedores los filósofos envín un mensaje y al soltarlos reciben uno. En este caso el proceso +fork+ debe invertir también sus operaciones:

    for {
        forks[i] <- Empty{}
        <-forks[i]
    }

De esta forma -es equivalente- el programa queda idéntico a la solucion propuesta por Hoare con _CSP_.
====

Los procesos comunicados por canales asincrónicos pueden ser convertidos -tal como acabamos de hacer- a uno equivalente con canales sincrónicos. La solución general es añadir nuevos procesos que suplanten las capacidades de los canales con _buffer_. En el caso de los filósofos añadimos un nuevo proceso para cada tenedor para convertirlo en una comunicaciones entre procesos _filósofos_ y otros _tenedores_.

Todos los algoritmos de este capítulo que requieren de canales con _buffer_ pueden ser adaptados para funcionar con sincrónicos. Por ejemplo, para el <<channel_mutex_go, código>> de simulación de _mutex_ se requieren muy pocos cambios. La función _pseudo-constructora_ de +Mutex+ con canales asincrónicos crea un canal con _buffer_ 1 y deposita un mensaje:


[source,go]
----
func NewMutex() Mutex {
    m := make(Mutex, 1)
    m <- Empty{}
    return m
}
----

Dado que no podemos hacerlo con canales sincrónicos se requiere otro proceso que actúe de forma similar al +fork+ de los filósofos. Se puede hacer que el propio constructor inicie el nuevo proceso sin necesidad de modificar la implementación de las otras funciones (<<channel_mutex_sync_go, código completo>>)footnote:[Uso función anónima con clausura, de lectura y comprensión más sencilla.]:

[source,go]
----
func NewMutex() Mutex {
    m := make(Mutex)
    go func() {         <1>
        for {
            m <- Empty{}
            <-m
        }
    }()
    return m
}
----
<1> Se lanza una _goroutine_, la función es anónima y aprovecha de la clausura para hacer referencia al mismo canal +m+.

==== Solución óptima
La solución anterior (ya la analizamos <<dining_philosophers_semaphores, con semáforos>>) no asegura que puedan comer todos los filósofos que podrían hacerlo. Se puede implementar una solución óptima similar a la de semáforos pero adaptada a canales (<<channel_philosophers_provider_go, código completo>>).

En vez de solicitar los tenedores individualmente habrá un proceso _proveedor_ (+provider+) para toda la mesa, este proceso usará un único canal sincrónico para recibir los mensajes de todos los filósofos. Estos enviarán mensajes indicando si quieren tomar o soltar los tenedores. El proveedor verificará el estado de los filósofos vecinos, si ambos palillos están libres le responderá con un mensaje para que continúe. Si alguno de sus vecinos está comiendo no le responderá inmediatamente sino cuando sus vecinos hayan dejado de comer.

El mensaje de filósofos al proveedor será una estructura que indicará el índice el filósofo, el estado (+Hungry+ si desea comer y +Thinking+ si es para liberar los palillos) y el canal individual del filósofo (también sincrónico) para recibir la respuesta del proveedorfootnote:[Go permite enviar descriptores de canales en los mensajes por lo que no hace falta que estos sean parte del estado global, cada filósofo crea el suyo y lo pasa el proveedor en el mensaje.]:

[source, go]
----
type Request struct {
    id     int
    status int
    c      chan Empty
}
----

Cuando un filósofo desea comer envía un mensaje al canal del proveedor con su identificación (+i+), su propio canal (+myCh+) y el estado +Hungry+. A continuación espera la respuesta del proveedor:

[source, go]
----
provider <- Request{id: i, c: myCh, status: Hungry}

<-myCh
----

Cuando libera los palillos envía otro mensaje similar pero con el estado +Thinking+:

[source, go]
----
provider <- Request{id: i, c: myCh, status: Thinking}
----

El proveedor mantiene un array que con el estado de los filósofos y su canal de comunicación. Inicialmente cada posición es una copia de la estructura +Request+ que recibe en el mensaje. El proceso está en un bucle infinito recibiendo mensajes desde su canal +provider+. Cuando recibe un mensaje lo copia al array de estado y verifica el estado:

1. Si es +Hungry+ llama a la función +canEat+, esta función responderá con un mensaje al canal del filósofo si puede comer.

2. Si el estado es +Thinking+ significa que deja los tenedores por lo que se llama a la función +canEat+, una vez para cada vecino por si querían comer y están esperando.

[source, go]
----
for {
    m := <-provider
    philo[m.id] = m
    switch m.status {
    case Hungry:
        canEat(m.id)
    case Thinking:
        canEat(left(m.id))
        canEat(right(m.id))
    }
}
----

La función +canEat+ es idéntica a la homónima de la solución óptima con semáforosfootnote:[Nuevamente aparecen las similitudes de sincronización entre semáforos y canales.] (<<philosophers_2_py, código Python>>), solo que en vez de señalizar un semáforo se responde con un mensaje. La función verifica el estado de los vecinos a izquierda y derecha del filósofo indicado en el argumento (+i+), si ninguno de los vecinos está comiendo entonces permite continuar enviando un mensaje al canal correspondiente.

[source, go]
----
func canEat(i int) {
    r := right(i)
    l := left(i)
    if philo[i].status == Hungry &&
        philo[l].status != Eating &&
        philo[r].status != Eating {
        philo[i].status = Eating
        philo[i].c <- Empty{}
    }
}
----

=== Paralelismo
En 1979, poco después de la publicación del artículo del modelo _CSP_ la empresa británica INMOfootnote:[Actualmente STMicroelectronics, http://www.st.com/.] pidió colaboración a Hoare para crear el lenguaje occam para su nueva arquitectura de multiprocesamiento masivo _Transputer_. A principios de la década de 1980 se pensaba que se había llegado al límite de la capacidad de los procesadoresfootnote:[Podían poner más transistores en un chip pero no sabían qué hacer con ellos, luego surgieron las arquitecturas _superescalares_ que permitieron aumentar la potencia de cálculo, lo que también significó la decadencia de _Transputer_.] por lo que diseñaron una arquitectura basada en el modelo _CSP_. Consistía de procesadores con instrucciones genéricas, 4 KB de RAM incluidas en el chip y cuatro puertos series de alta velocidad. Cada puerto podía usarse para conectar a otros procesadores y así formar arrays de procesasores con canales sincrónicosfootnote:[Llegaron a fabricar un _switch_ de red de 32x32 procesadores.].


[[BOO42]]
.Placa con Transputer con matriz de 6x7 procesadoresfootnote:[De la página David May, uno de los arquitectos de Transputer, https://www.cs.bris.ac.uk/~dave/transputer.html]
image::B0042.jpg[width="300", align="center"]

Inicialmente solo se podía programar en occam pero luego se adaptaron librerías para lenguajes como Pascal, C y Fortran, también se desarrollaron y portaron varios sistemas operativos como Minix, Paros y Trollius. Aunque inicialmente tuvo éxito en el ambiente académico (ofrecía buena potencia de cálculo, sobre todo de matrices) y se usó en sistemas satelitales desapareció posiblemente por la aparición de microprocesadores más potentes (especialmente a partir de Pentium) y económicos. Aunque ya no existe su arquitectura influyó notablemente en el desarrollo de los chips para tratamiento digital de señales, la supercomputación basada en _clusters_ y hasta la conocida _Blue Gene_ de IBM que soporta miles de procesadores conectados por canales de alta velocidadfootnote:[Está basada en la arquitectura QCDOC, originalmente soportaba canales de comunicacion con 12 nodos vecinos y hasta 12 Gbits/seg.]


==== Multiplicación de matrices en paralelo

Una muestra de la potencia del modelo _CSP_ en arquitecturas con múltiples procesadores es el producto de matrices. Aunque el siguiente ejemplo trata con matrices y enteros pequeños su uso está orientado a matrices de grandes dimensiones que compensen la sobrecarga y demoras provocados por el envío de mensajes. Analicemos el algoritmo para multiplicar en paralelo dos matrices de 3x3, como las de la siguiente imagen:

[[matrix_multiplication]]
image::matrix_multiplication.png[width="360", align="center"]

Cada elemento de la matriz resultante puede ser calculado independientemente, por ejemplo el elemento central de la matriz (25) se calcula de la siguiente forma:

[[element_multiplication]]
image::element_multiplication.png[width="400", align="center"]

El cálculo se puede descomponer en diferentes procesos _multiplicadores_ comunicados por canales. Cada uno de ellos multiplican un elemento de cada matriz, lo suman al resultado recibido de otro proceso (otra suma parcial) y envían el resultado al siguiente multiplicador. Para matrices de 3x3 se necesitan tres procesos por fila inicializados con los valores de una fila de la primera matriz ([4, 5, 6]). Del canal _norte_ (_north_)footnote:[Recordad que cada procesador de _Transputer_ tiene cuatro puertos, para ubicarlos en el diagrama los llamamos _norte_, _este_, _sur_ y _oeste_.] reciben un elemento de la fila correspondiente a la segunda matriz ([2, 1, 2]):

[[col_row_multiplication]]
image::col_row_multiplication.png[width="480", align="center"]

Para obtener el resultado final a la izquierda (_oeste_) cada proceso multiplica el valor inicial por el que le llegó desde el _norte_, lo suma al resultado desde el canal del _este_ y lo envía en su canal del _oeste_. El proceso _zero_ de la columna de la derecha unicamente envia ceros para iniciar la suma parcial, así el algoritmo de cada multiplicador es idéntico:

[source, go]
----
second := <-north
sum := <-east
west <- sum + first*second
----

Tal como ya había descrito Hoare, se puede generalizar para la multiplicación en paralelo de la matriz completa con nueve _multiplicadores_ (en el centro de la imagen). Los procesos de la fila superior (_norte_) envían los datos, uno a uno, de las filas de la segunda matriz, los resultados parciales lo obtienen los procesos de la columna izquierda. (_result_). Además cada multiplicador copia el mensaje recibido del canal _norte_ al canal _sur_ para que procesos de las siguientes filas (se añaden los procesos _sink_ de la fila inferior con el único objetivo de que el algoritmo sea el mismo para todos los multiplicadores).


[[parallel_multiplication]]
.Array de procesos para multiplicación de matrices
image::parallel_multiplication.png[width="480", align="center"]

El algoritmo de cada uno de los cuatro tipos de procesos de la _matriz de procesos_ es el siguiente (<<parallel_matrix_multiplication_go, código completo>>):

[source, go]
----
func multiplier(first int) {
    for {
        second := <-north
        south <- second
        sum := <-east
        west <- sum + first*second
    }
}

func result(rowNum int) {
    for i := 0; i < Dim; i++ {
        row[i] := <-east
    }
}

func source(row Row) {
    for i := range row {
        south <- row[i]
    }
}

func zero(west chan int) {
    for {
        west <- 0
    }
}

func sink() {
    for {
        <-north
    }
}
----

=== Algoritmos distribuidos

No es el tema de este libro, se necesitaría de otro específico y aún así sería incompleto dado el avance y cantidad de sistemas y protocolos que se desarrollaron en los últimos años. Pero no podía dejar de mencionarlo, los canales de comunicación son el elemento fundamental y el concepto de _procesos comunicados_ son la espina dorsal de las sistemas distribuidos. Cuando se habla de sistemas distribuidos se agrega un elemento nuevo a _canales_ y procesos: _nodos_. Estos son ordenadores independientes conectados solo por un canal de comunicaciónfootnote:[De características diferentes fundamentalmente si son fiables y entregan los mensajes en el mismo orden en que lo reciben] (_debilmente acoplados_) y pueden ejecutar más de un proceso.

Los programas diseñados según los principios de _CSP_ y cuyo único mecanismo de comunicación y compartición de datos son los mensajes pueden ser fácilmente portados a sistemas distribuidos cambiando las primitivas de canales locales por sistemas de gestión de _colas de mensajes_ (como Beanstalkd o RabbitMQ). Por el mismo principio, algoritmos diseñados para ser distribuidos pueden ser fácilmente implementados en el modelo _CSP_.

Hay otros problemas que hay que tener en cuenta en los sistemas distribuidos que no preocupan en procesos locales:

- los canales y nodos pueden fallar sin notificar a los demás procesos por lo que hay que considerar tiempos y expiración,

- el grafo o estructura de la red que conecta a los diferentes nodos puede ser variable,  muy compleja y no permitir la conexión de cada nodo con todos los demás,

- no se pueden tomar decisiones suponiendo un número fijo de nodos o procesos y que cada uno de ellos recibió cada mensaje, se requieren más pasos de sincronización y verificación,

- la operación que más tiempo toma es la copia de mensajes de un nodo a otro por lo que la prioridad es reducir el tamaño y número de mensajes que hacen falta intercambiar.

Los procesos distribuidos deben responder a mensajes de sincronización que llegan desde otros nodos y que necesitan de respuesta inmediata se suele implemenar al menos un hilo auxiliar independiente que es el responsable de recibir los mensajes de la red y responder adecuadamente lo antes posible. Así un proceso que se ejecuta en un nodo (_Process_) consiste de un hilo principal (_Main_) y un auxiliar (_Receiver_) que comparten memoria y se sincronizan entre ellos con cualquiera de los mecanismos de memoria compartida vistos en este libro.

[[distributed_process]]
image::distributed_process.png[width="240", align="center"]




----
func node(aChannel chan Struct) {
    myNumber := 0
    mutex := new(sync.Mutex)

    receiver := func() {
        for {
            request := <-aChannel
            ...
            aChannel <- response()
            }
        }
    }
    go receiver()
    mainProcessing()
}
----

==== Exclusión mutua
Como breve introducción a cómo se desarrollan los algoritmos distribuidos analizaremos tres algoritmos diferentes para resolver el problema de la exclusión mutua distribuida:

1. Exclusión mutua de Ricart-Agrawala inspirado en el algoritmo de la panadería (<<distributed_me1_go, código>>),

2. _token-passing_ de los mismos autores que reduce el número de mensajes (<<distributed_me2_go, código>>),

3. _token-passing_ de Neilsen-Mizuno que reduce el número el tamaño de los datos que requiere el anterior de Ricard-Agrawala (<<distributed_me3_go, código>>).








////


http://www.slideshare.net/dabeaz/an-introduction-to-python-concurrency (para ver lo de mensajes)
////
