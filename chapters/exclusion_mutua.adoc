== Exclusión mutua

La exclusión mutua es un problema básico y fundamental de sincronización entre procesosfootnote:[O hilos (_threads_), a menos que especifique lo contrario uso el término indistintamente.] con _memoria compartida_, se trata de asegurar que el acceso a recursos compartidos entre ellos se haga de forma ordenada para asegurar que los valores o estados de esos recursos sean consistentes. Un problema de exclusión mutua muy genérico y naïve pero que ilustra perfectamente el problema: si varios procesos en un ordenadorfootnote:[Si la impresora admite trabajos desde diferentes ordenadores el problema se convierte en _distribuido_, el interés de este libro es estudiar las soluciones de _memoria compartida_.] envían diferentes trabajos de impresión se debe asegurar que las páginas no se intercalen, es decir, asegurar la exclusión mutua en el acceso a la impresora.

El mismo problema ocurre con granularidades menores, datos en ficheros modificados por varios procesos independientes, la metainformación de los sistemas de ficheros, fragmentos de la memoria del navegador web accedidas y modificadas desde diferentes hilos de ejecución, hasta variables enteras simples

////
////

Este capítulo describe el problema de la exclusión mutua, en qué casos se presenta y qué condiciones deben cumplir una solución correcta al problema. En los siguientes capítulos analizaremos cómo solucionarla algorítmicamente, los problemas con las arquitecturas modernas, soluciones de hardware y abstracciones de más alto nivel (semáforos, monitores, canales y mensajes, etc.) que no sólo permiten solucionar la exclusión mutua, también problemas genéricos y técnicas más sofisticadas de sincronización (productor-consumidor, lectores-escritores, etc.).


=== Intercalado de instrucciones

La mayoría de los lenguajes de programación están diseñados para especificar y ejecutar las instrucciones secuencialmente. Tomemos la siguiente secuencia de instrucciones que se ejecutan en un programa con las variable +a+ y +b+ inicializadas a +0+

----
a = a + 1
b = b + a
print "a, b:", a, b
----

Por el modelo de consistencia secuencial es fácil deducir que el resultado de imprimir las tres variables será +1 1+. Si las dos asignaciones se repiten el resultado será +a, b: 2 3+, el siguiente +a, b: 3 6+, etc.

Ahora supongamos que este fragmento de código se ejecuta en procesos o hilos diferentes (+P+ y +Q+) sobre un sistema con un único procesador y que tanto +a+ como +b+ con _variables compartidas_. Se puede producir la siguiente intercalación de las instrucciones del programa:


----
Proceso P               Proceso Q

...
a = a + 1
                        a = a + 1
                        b = b + a
                        print "a, b:", a, b
                        ...
b = b + a
print "a, b:", a, b
----



El resultado de la ejecución de estas instrucciones será:

----
a, b: 2 2
a, b: 2 4
----

Ninguno de los valores es correcto. Si se ejecuta nuevamente el resultado podría ser diferente, depende del instante y orden en que cada proceso ejecuta las instrucciones en _secciones críticas_ del código que acceden a recursos u _objetos compartidos_ (en este caso variables). Este problema se denomina genéricamente como _condición de carrera_ (_race condition_). Es muy difícil detectar los _bugs_ causados por condiciones de carrera, habitualmente no son frecuentes porque la probabilidad de que ocurra es muy bajafootnote:[Al contrario de los ejemplos en este libro, diseñados de tal manera que se aumenta artificialmente la probabilidad de que ocurran estas condiciones de carrera.] y es muy difícil repetir el error con las mismas condicionesfootnote:[Recuerda que la planificación de CPU es no determinística en los sistemas operativos modernos.].

Esas dos líneas (o tres si contamos con el +print+ de ambos resultados) acceden a variables compartidas y que además tienen dependencias entre ellas: el resultado de +b+ depende de +a+. Las secuencias anteriores de _instrucciones_ no son _atómicas_, el proceso puede ser interrumpido y ejecutarse otro que modifica las mismas variables. Lo mismo puede ocurrir con instrucciones más básicas y sobre las que solemos hacer suposiciones erróneas:

    counter += 1

Se suele suponer que una operación tan básica como sumar una constante (o _literal_) a una variable no es interrumpible, pero no es así. El código ejecutable está compuesto por al menos tres instrucciones de procesador:

----
movl  counter(%rip), %eax
addl  $1, %eax
movl  %eax, counter(%rip)
----

Si se ejecuta dos veces el valor de +counter+ será +2+, es factible que se presente la siguiente condición de carrera ente dos procesos:

----
movl counter(%rip), %eax <1>
                        movl counter(%rip), %eax
                        addl $1, %eax
                        movl %eax, counter(%rip)
addl $1, %eax <2>
movl %eax, counter(%rip)
----

<1> Se almacena 0 en el registro eax.
<2> Aunque la variable ya tiene almacenado el valor +1+, el registro %eax sigue siendo 0.

En este caso el valor será +1+, se ha _perdido_ una operación. Es el problema más habitual. También pasa con lenguajes dinámicos y con compilación de _bytecode_ como Java o Python. El siguiente código es el generado por la compilación de Python, son cuatro instrucciones:

----
LOAD_GLOBAL   0 (counter)
LOAD_CONST    1 (1)
INPLACE_ADD
STORE_GLOBAL  0 (counter)
----

==== Ejemplos en diferentes lenguajes

Los siguientes programas  <<counter_c, en C>>, <<gocounter_go, Go>>, <<counter_java, Java>> y <<counter_py, Python>> hacen lo mismo: crean dos hilos que incrementan un contador compartido (+counter+) cuyo total debería ser diez millones. El resultado de sus ejecuciones son los siguientes:

[[counter_times]]
.Resultados y tiempos de CPU
----
$ time ./counter
Counter value: 5785131 Expected: 10000000
real    0m0.010s <1>
user    0m0.017s
sys     0m0.000s

$ time ./gocounter
Counter value: 5052927 Expected: 10000000
real    0m0.021s <1>
user    0m0.032s
sys     0m0.008s

$ time java Counter
Counter value: 4406963 Expected: 10000000
real    0m0.333s <1>
user    0m0.564s
sys     0m0.020s

$ time ./counter.py
Counter value: 7737979 Expected: 10000000
real    0m5.400s <2>
user    0m5.365s
sys     0m0.044s
----
<1> El tiempo de _reloj_ es *menor* al tiempo acumulado de CPU.
<2> El tiempo de _reloj_ es *mayor* al tiempo acumulado de CPU.


[NOTE]
.Sobre los tiempos de CPU
====
Compara los _tiempos de CPU_ con los _tiempos de reloj_. Salvo Python todos lo superan, se ejecutan en paralelo en dos CPUs por lo que por cada segundo de reloj corresponde a dos segundos de procesador. Los programas en Python no pueden ejecutarse simultáneamente en más de un procesador debido a al _Python Global Interpreter Lock_ (<<Sampson>>).
====



=== Definición

En los ejemplos anteriores se observa que en todos _perdieron_ hasta más de la mitad de los operaciones. El error se debe a la intercalación de instrucciones, éstas pueden ocurrir tanto en sistemas con un único procesador como con paralelismo. Una solución correcta de exclusión mutua es equivalente y funciona para ambos modos: el paralelismo es sólo un caso particular de la intercalación.

La solución formal a la solución a este problema fue publicado por Dijkstra en 1965 (<<Dijkstra65>>). Consideró una ejecución de procesos independientes, que podían ser considerados cíclicos y cada uno de sus ciclos se ejecuta una parte de código denominoado _sección crítica_ que accede y modifica recursos o zonas de memoria compartidas. La intercalación de las instrucciones de esas secciones críticas generan condiciones de carrera, pueden generar resultados erróneos

Así se definió el modelo o _problema de la sección crítica_  -también llamado simplemente _exclusión mutua_-, es el más sencillo y estudiado de los problemas genéricos de concurrencia o sincronización de procesos. Consiste en asegurar la exclusión mutua de la ejecución de esas secciones críticas. El modelo de sección crítica separa al código en secciones críticas y _resto del código_. La solución consiste en desarrollar los algotirmos que se insertan antes y después de las secciones críticas:

- Preprotocolo o _entrada a la sección crítica_.

- Posprotocolo o _salida de la sección crítica_.


[source,python]
.Modelo de sección crítica
----
while forever:
    # ...
    cs_entry()             <1>
    critical_section()
    cs_exit()              <2>
    # ...
----
<1> Preprotoclo o entrada a la sección crítica.
<2> Posprotocolo o salida de la sección crítica


Hay muchas algoritmos y construcciones de lenguajes que solucionan el problema de la sección crítica, aunque cada uno tiene sus propios problemas y ventajas. El objetivo del resto del capítulo es razonar y encontrar soluciones por software, consiste en desarrollar el algoritmo para la entrada y salida de la sección crítica.

Esos algoritmos deben cumplir conm los siguientes requisitos:

[[em_requisites]]
[IMPORTANT]
.Requisitos para exclusión mutua
====
Exclusión mutua:: Se debe asegurar que sólo uno de los procesos ejecuta código de la sección crítica.

Progreso o _libre de interbloqueos_ (_deadlock free_ o _lock-free_):: Si varios procesos desean entrar a la sección crítica, al menos _uno de ellos_ debe poder hacerlo.

Espera limitada o _libre de inanición_ (_starvation free_ o _wait-free_):: Si cualquier proceso desea entrar en la sección crítica _ese proceso_ deber poder hacerlo en un tiempo finito. Esta condición es deseable pero no siempre se puede asegurar, sobre todo cuando se implementan con algoritmos con soporte de instrucciones de hardware que no están <<fairness, diseñados para asegurar _equidad_>>.
====

Además de los tres requisitos fundamentales anteriores, en el artículo roginal (<<Dijkstra65>>) Dijkstra propuso cuatro reglas que se deben cumplir:

[[four_requisites]]
.Cuatro requisitios de Dijkstra
* La solución debe ser _simétrica_ en los diferentes procesos, no se permiten soluciones que cambien el comportamiento o la prioridad estática de algún proceso.

* No se deben hacer suposiciones de la _velocidad relativa_ de los procesos, ni se puede suponer que las velocidades sean constantes.

* Un proceso que se interrumpe fuera de su sección crítica (o _resto del código_) no debe _interferir_ ni bloquear a los demás procesos.

* Si varios procesos desean entrar simultáneamente la decisión en la _entrada de la sección crítica_ debe tomar un número finito de pasos.

////
. Debe permitir la *entrada inmediata* a la sección crítica si no hay ningún proceso en ella.
. Un proceso permanece en su sección crítica por tiempo finito. Dado que nuestro interés es desarrollar los algoritmos de entrada y salida a la sección crítica, damos por cierta la validez de esta reglafootnote:[Pero sí se debe tomar en cuenta cuando se desarrollan los programas que *implementan* la sección crítica.].
////
