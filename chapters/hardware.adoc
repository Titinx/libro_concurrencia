[[hardware]]
== Soluciones por hardware
Hasta ahora hemos visto soluciones al problema de la exclusión mutua sin soporte de hardware y con sólo _registros de lectura-escritura atómicos_. Hemos visto que tanto para la solución de dos procesos (Dekker y Peterson) como para _N_ procesos (Panadería) se necesita una cantidad de registros proporcional al número de procesos que han de sincronizar. Está demostrado (<<Herlihy12>>) que dichos algoritmos son óptimos en cuestión de espacio

Los algoritmos anteriores implementan _spinlocks_ pero son muy ineficientes. Además de la sobrecarga para mantene la consistencia de cache se recorren múltiples registros aunentando el consumo de CPU y la presión sobre la cache. Si habéis probado los algoritmo anteriores, en algunos procesadores puede tomar tiempos de órdenes de magnitud superiores a otros. En el caso de un único procesador el avance es tan lento que lo que tarda décimas en uno puede tomar horas en otrosfootnote:[Como pasa en la Raspberry 1.] en el caso de que exista mucha _competencia_ (o _contention_) para entrar a la sección crítica.

Obviamente desde el inicio se buscó una solución con soporte del hardware.


=== Deshabilitar interrupciones
Si el problema fundamental es el intercalado de instrucciones generado por las interrupciones al procesador ¿por qué no deshabilitarlas?. Aunque es una solución que se usa en casos muy específicos en los sistemas operativosfootnote:[Como local_irq_disable() o local_irq_enable() en Linux.] no es una solución segura: si los procesos pueden deshabilitar las interrupciones entonces pueden tomar control del sistemafootnote:[Deshabilita la cualidad de _apropiativo_ (o _preemptive_) del _scheduler_.]. Por lo tanto es una solución genérica válida para los procesos de usuario.

Aún al nivel del núcleo del sistema operativo presenta dificultades: la complicación de deshabilitar todas las interrupciones en todos los procesadores y el riesgo de perder interrupciones. Dada la dificultad de deshabilitar las interrrupciones en todos los procesadores tampoco es una solución para asegurar exclusión mutua dado que un _registro_ puede ser modificado por un procesador diferente sin que haya habido intercalación en el mismo procesador.

=== Sincronización por hardware
Por ello se buscaron otras alternativas que en general son conocidas como _primitivas de sincronización de hardware_. Son instrucciones del procesador que leen y modifican el valor de un registro sin ser interrumpidas y asegurando la coherencia de cache (introducen barreras de memoria). Hay muchas variantes de estas instrucciones, -_getAndAdd_, _testAndSet (TAS)_, _swap_, _compareAndSwap (CAS)_, etc.-, cada una con propiedades diferentes. Pero antes de estudiarlas veremos definiciones más genéricas de _registros_ que  proporcionen modelos simples y genéricos de consistencia por encima de las interrrupciones o mecanismos de consistencia de cache.

=== Tipos de registros
El término _registro_ no trata sólo de los registros del procesador, su uso es más general. Puede involucrar a zonas de memoria RAM o en términos generales a un _objeto compartido_. Aunque nos interesan los registros de hardware hay que tener en cuenta que estos son intermediarios de la memoria RAM lo que implica asegurar consistencia de cache.

A nivel de hardware los hilos se comunican leyendo y escribiendo en memoria compartida. Desde el punto de vista del hardware la comunicación se hace vía registros de lectura-escritura. Un registro de este tipo encapsula dos métodos, _read_ y _store_. O _get_ y _write_ cuando nos referimos a objetos compartidos en general y que pueden ser implementados en lenguajes de alto nivel.


==== Registros _seguros_

Los registros con las propiedades de consistencia más débiles son los _registros seguros_, su nombre es un mero accidente histórico, son muy inseguros (<<Herlihy12>>). Estos tipos de registros sólo aseguran que se retorna el último valor escrito si no hay operaciones _get_ y _write_ concurrentes, caso contrario podrá devolver cualquier valor aceptable en el rango del registro.

==== Registros regulares

Una alternativa intermedia son los _registros regulares_ donde una operación de lectura concurrente con escrituras puede retornar alguno de los valores que están siendo escritos. Se dice que estos registros sólo aseguran _consistencia por inactividad_ (_quiescent consistency_) ya que sólo aseguran retornar el mismo valor después de un período de inactividad entre el último _write_ y el siguiente _get_.

==== Registros atómicos

Los registros de procesadores modernos que usamos para la implementación de los algoritmos de exclusión mutua son _registros atómicos_, generalmente bytes únicos, enteros de varios bytes o referencias a memoria u objetos que cumplen las siguientes dos condiciones (<<Lamport2>>):

1. El método _get_ retorna el último valor escrito, si una lectura retorna un valor y no hubo otra escritura intermedia la siguiente lectura será el mismo valor.

2. Si hay varios _write_ concurrentes el valor que retornará el siguiente _get_ es uno de los valores del _write_ no un rango de posibles valores. Por ejemplo, si un _write_ concurrente es el número 0 y otro es el número 1000, el _get_ retornará 0 o 1000, ni un valor intermedio ni del rango posible que puede tomar el registro.

=== Primitivas de hardware y registros _Read-Modify-Write_
Como hemos observado en la implementación del algoritmo de la panadería, el requerimiento de registros atómicos para solucionar los problemas de exclusión mutua crece linealmente con el número de hilos o procesos involucrados. Tiene otros problemas, son _spinlocks_ sobre muchos registros que introducen mucha presión sobre grandes zonas de la cache, por lo que son muy ineficientes. El otro problema era tener que introducir barreras de memoria para forzar la consistencia secuencial.

Por ello no es de extrañar que desde el principio se introdujen instrucciones atómicas del procesador que permitiesen implementar operaciones de sincronización de forma más sencilla y eficiente. Este tipo de operaciones pueden ser expresadas como construcciones de registros denominados genéricamente _registros Read-Modify-Write_ o _RMW_. Los registros _RMW_ son interesantes porque pueden implementarse en construcciones de lenguajes o como instrucciones de procesador, sus propiedades son similares.


[NOTE]
[[consensus]]
.Registros RMW no triviales
====

Los registros _RMW_ que proveen operaciones adicionales a la _función identidad_ se denominan _no triviales_. <<Herlihy91>> demostró que los registros no triviales tienen un _consenso_ de al menos 2 (o son de _clase 2_). Todas las instrucciones mencionadas anterioremente (a excepción de la identidad, como es obvio) implementan registros RMW no triviales.

De todas las implementaciones, _compareAndSwap_ es la más potente. <<Herlihy91>> demostró que pertenece a la clase de consenso N (o _infinito_). Este tipo de instrucciones son, en palabras de <<Herlihy12>>, _a la computación asincrónica el equivalente de las máquinas de Turing de la computación secuencial_. Afortunadamente la mayoría de procesadores implementan la instrucción _compareAndSwap_ o la similar _load-linked/store-conditional_ (o _LL/SC_, disponible en las arquitecturas Power, MIPS y ARM).

====

Hay varios tipos de intrucciones que implementan registros _RMW_:

- _get_: Retorna el valor del registro, se denomina también _función identidad_.
- _getAndSet_: Asigna un nuevo valor al registro y retorna el anterior.
- _getAndAdd_: Incrementa el valor del registro en el valor indicado y retorna el valor anterior.
- _testAndSet_: verifica el valor del registro, si es cero asigna el nuyevo valor (habitualmente 1, por ejemplo en IBM 360 el registro es binario o booleano, solo admite 0 y 1).
- _swap_: Intercambia el valor de dos registros.
- _compareAndSwap_: Compara el valor del registro con otro, si son iguales asigna un nuevo y retorna el anterior.


Los fabricantes proveen muchas operaciones diferentes, y compiladores como el GCC tienen macros que generan estas instrucciones o sus equivalentes: <<Atomics_C11>> y las antiguas <<Atomics>>.  Estudiaremos cómo implementar exclusión mutua con algunas de estas primitivas.

[IMPORTANT]
====

A partir de aquí usaremos las primitivas atómicas de las últimas versiones de GCC (<<Atomics_C11>>). Estas primitivas implementan el modelo de memoria de C11 y C\+\+11. para probar los ejemplos en C aseguraros de tener versiones nuevas del GCC, estos ejemplos fueron probados con la versión 4.9.

====


==== getAndSet
Usaremos una variable global `mutex` que estará inicializada a cero e indica que no hay procesos en la sección crítica. En la entrada de la sección crítica se almacena 1 y se verifica si el valor anterior era 0 (es decir, no había nadie en la sección crítica). Si era diferente a cero esperará hasta que lo sea.

La función `lock()` es la entrada a la sección crítica y `unlock()` la salida.

----
		mutex = 0

def lock():
	while getAndAdd(mutex, 1) != 0:
		pass

def unlock():
	mutex = 0

----

En <<getAndSet>> está el código en C implementado con el macro `__atomic_exchange_n`. A pesar de su nombre no es la instrucción _swap_ sino un equivalente para _getAndSet_.


==== getAndAdd

Se puede implementar exclusión mutua con una idea muy similar a la del algoritmo de la panadería, cada proceso obtiene un número y espera a tu turno. Sólo que esta vez la obtención del _siguiente número_ es atómica y por lo tanto no se necesita un array de números ni hacer un bucle de controles adicionales.

Usaremos dos variables, `number` para el siguiente número y `turn` para indicar a qué número le corresponde entrar a la sección crítica.


----
		number = 0
		turn = 0

def lock():
	""" current is a local variable """
	current = getAndAdd(number, 1)
	while current != turn:
		pass

def unlock():
	getAndAdd(turn, 1)

----

En <<getAndAdd>> podéis ver el código en C implementado con el macro `__atomic_fetch_add` y en Go con `atomic.AddUint32`.footnote:[Estrictamente no es getAndAdd sino addAndGet, devuelve el valor después de sumar, pero son equivalentes, sólo hay que cambiar la inicialización de la variable turn.] A diferencia de la implementación con _getAndSet_ esta implementación asegura que no se producen esperas infinitas ya que el número que _elige_ cada proceso es único y creciente, aunque hay que tener en cuenta que el valor de `number` llegará a un máximo y rotará. Los _spinlocks_ de este tipo son también llamados _Ticket lock_ y son muy usados, incluso en el núcleo de Linux, por que aseguran que no se producen esperas infinitas y que los procesos entran a la sección crítica en orden FIFO (_fairness_).



==== testAndSet

La instrucción _testAndSet_ o _TAS_ fue la instrucción usada para control de concurrencia hasta la década de 1970 cuando fue reemplazada por operaciones que permitían niveles (_clase_) de consenso más elevados. La implementación consiste de una variable entera binaria (o _booleana_) que podía tomar valores 0 y 1. La intrucción sólo recibe un argumento, la dirección de memoria. Si el valor de la dirección de memoria es 0 le asigna 1 y retorna 1 (o _true_), caso contrario retorna 0 (o _false).

----
def testAndSet(register):
	if register == 0:
		register = 1
		return 0

	return 1
----

La implementación de exclusión mutua con TAS es muy similar a _getAndSet_:

----
		mutex = 0

def lock():
	while testAndSet(mutex) == 0:
		pass

def unlock():
	mutex = 0

----

El código en C implementado con el macro `__atomic_test_and_set`: <<testAndSet>>.

==== Swap

Esta instrucción intercambia atómicamente dos posiciones de memoria, usualmente enteros de 32 o 64 bitsfootnote:[No todas las arquitecturas la tienen, en Intel es XCHG para enteros de 32 bits. Esta función estaba implementada en el antiguo <<Atomics>> con el confuso nombre de `__sync_lock_test_and_set` pero realmemte ejecuta la instrucción XCHG y devuelve el valor anterior de la primer variable. Su algoritmo es igual al genérico pero devuelve el valor previo de la primer variable, en este sentido es equivalente a _getAndSet_]. El algoritmo de la instrucción es tan sencillo como parece:

----
def swap(register1, register2):
	tmp = register1
	register1 = register2
	register2 = tmp
----

El algoritmo de exclusión mutua con _swap_:

----
		mutex = 0

def lock():
	local = 1
	while local != 0:
		swap(mutex, local)

def unlock():
	mutex = 0
----

La implementación con el macro `__atomic_exchange` de las últimas versiones de GCC: <<counter_swap_c>>. En Go se pueden usar las funciones atómicas implementadas en el paquete `sync/atomic`, por ejemplo con `atomic.SwapInt32`: <<gocounter_swap_go>>footnote:[Esta función no estaba disponible en Go para ARM hasta 2013, si la pruebas en una Raspberry asegúrate de tener una versión de Go moderna.].

==== Compare&Swap

Esta instrucción, o _CAS_, es la más comúnfootnote:[Es la que se usa en la arquitectura Intel/AMD.] y la que provee el mayor _nivel de consenso_ (ver nota <<consensus>>)footnote:[Aunque sufre el _problema ABA_.]. La instrucción trabaja con tres valores:

. Registro: que se comparará y asignará un nuevo valor si corresponde.
. Nuevo valor: el valor que se asignará al registro.
. Valor a comparar: si el valor del registro es igual a este valor entonces se asigna al registro, caso contrario se copia el valor del registro al valor a comparar.


En la versión modernafootnote:[En los antiguos <<atomics>> las instrucciones equivalentes `__sync_bool_compare_and_swap` y `__sync_val_compare_and_swap` respectivamente. La diferencia fundamental es que no se modifica el registro del valor a comparar.] de macros atómicos las dos versiones son `__atomic_compare_exchange_n` y `__atomic_compare_exchange_n`, ambas retornan un booleano si se pudo hacer el cambio, lo único que cambian es la forma de los parámetros (en el último caso son todos punteros). El algoritmo de estas instrucciones es:

----
def compareAndSwap(register, expected, desired):
	if registro == expected:
		registro = desired
		return True
	else:
		expected = register
		return False
----



La implementación de exclusión mutua en C (<<counter_compare_and_swap_c>>)
es sencilla, necesitamos una variable local porque hay que pasar un puntero y ambas instrucciones copiarán el valor de mutex a la posición indicada por el puntero:

----
		mutex = 0

def lock():
	local = 0
	while not compareAndSwap(mutex, local, 1):
		local = 0

def unlock():
	mutex = 0
----

La instrucción `CompareAndSwapInt32` en Go (<<gocounter_compare_and_swap_go>>) es algo diferente y más similar al antiguo macro de GCC. Los argumentos del valor _esperado_ y el _nuevo_ no se pasan por puntero sino por valor. La función en Go queda de la siguiente forma:

[source,go]
----
func lock() {
	for ! atomic.CompareAndSwapInt32(&mutex, 0, 1) {}
}
----


===== El problema ABA

_CAS_ tiene un problema conocido, el _problema ABA_, aunque este no se presenta en casos sencillos como el de exclusión mutua sino en casos de intercalados donde un proceso lee el valor _A_ y cede la CPU a otro proceso, otro modifica el registro con el valor _B_ y vuelve a poner el mismo valor _A_ antes antes que el primero se vuelva a ejecutar. Éste ejecutará la instrucción _CAS_ sin haber notado el cambio. Veamos un caso práctico.

Tenemos implementada una pila de estructuras _node_, con las funciones _push_ y _pop_ para agregar y quitar elementos de la pila. _push_ recibe como argumentos el puntero a la variable cabecera de la pilafootnote:[Es decir, al primer nodo.] y el puntero al nodo a añadir. _pop_ sólo recibe el puntero a la cabeza de la pila y devuelve el puntero al primer elemento de la pila (o NULL sin no hay ninguno). A continuación el código en C _simplificado_ de ambas funciones.

[source, c]
----
void push(struct node **head, struct node *e) {
	e->next = *head; <1>
	while (! CAS(head, &e->next, &e); <2>
}


struct node *pop(struct node **head) {
	struct node *result, *orig;

	orig = *head; <3>
	do {
		if (! orig) {
			return NULL; <4>
		}
	} while (! CAS(head, &orig, &orig->next); <5>

	return orig; <6>
}
----
<1> _push_: El nodo siguiente al nodo a insertar será el apuntado por la cabecera.
<2> _push_: Si la cabecera no fue modificada se hará el cambio y ahora apuntará al nuevo nodo `e`. Si por el contrario `head` fue modificada, el nuevo valor de `head` se copia a `e->next` (ahora apuntará al elemento nuevo que apuntaba `head`) y se volverá a intentar. Cuando se haya podido hacer el _swap_ `head` apuntará correctamente a `e` y `e->next` al elemento que estaba antes.
<3> _pop_: Se hace una copia de la cabecera.
<4> _pop_: Si es NULL la pila está vacía y retorna el mismo valor. Recordad que _CAS_ copia el valor anterior de `head` en `orig`, por lo que podría darse el caso que sea NULL, de allí que la comparación esté dentro del bucle `do... while`.
<5> _pop_: Si por el contrario la cabecera apuntaba a un nodo y ésta no fue modificada se hará el cambio y la cebecera apuntará al siguiente nodo. Si por el contrario fue modificada se hará una copia del último valor a `orig` y se volverá a intentar.
<6> _pop_: Se retorna el puntero al nodo que antes apuntaba la cabecera.

Este algoritmo funciona sin problemas, de hecho es un algoritmo correcto para gestionar una pila concurrente... solo si es imposible eliminar un nodo y volver a insertar otro nuevo con la misma dirección de memoria. Con _CAS_ es imposible saber si otro proceso ha modificado y vuelto a poner el mismo valor que copiamos (en este caso `orig`). Supongamos que tenemos una pila con tres nodos que comienzan en la direcciones 10, 20 y 30:

    head -> [10] -> [20] -> [30]

El proceso _P1_ que acaba de ejecutar `orig = *head;` dentro de _pop_ y es interrumpido. Otro u otros procesos eliminan dos elementos de la pila:

    head -> [30]

Y luego se inserta un nuevo nodo con una dirección usada previamente:

    head -> [10] -> [30]

Cuando _P1_ continue su ejecución _CAS_ hará el cambio ya que la direccion es también `10`. El problema es que era una copia antigua que apuntaba antes a `[20]` por lo que dejará la cabecera apuntando a un nodo que ya no existe y los siguientes habrá quedado _descolgados_ de la pila:

    head -> ¿20?    [30]

Este caso es muy habitual si usamos `malloc` para cada nuevo nodo que insertamos y luego el `free` cuando lo eliminamos de la listafootnote:[Las implementaciones de `malloc` suelen reusar las direcciones de los elementos que acaban de ser liberados.]. El programa <<stack_cas_malloc_c>> usa estas funciones en cuatro hilos diferentes, cada uno de ellos ejecuta repetidamente el siguiente código:

[source, c]
----
e = malloc(sizeof(struct node));
e->data.tid = tid;
e->data.c = i;
push(&head, e); <1>
e = pop(&head); <2>
if (e) {
	e->next = NULL; <3>
	free(e);
} else {
	printf("Error, stack empty\n"); <4>
}
----
<1> Agregamos el elemento nuevo a la pila, la memoria de este fue obtenida con el malloc anterior.
<2> Inmediatamente lo quitamos de la lista. El resultado nunca debería ser NULL ya que siempre debería haber al menos un elemento: todos los hilos primero agregan y luego lo quitan.
<3> Antes de liberar la memoria del elemento recién quitado ponemos el puntero al siguiente en NULL. No debería hacer falta pero agregamos por seguridad y para que observéis que no hay errores no provocados por el efecto ABA.
<4> Si no pudo obtener un elemento de la lista es un error y lo indicamos.

Si lo ejecutáis veréis que en todos los casos da el error de la pila vacía y/o de error por intentar liberar dos veces la misma memoria.
----
Error, stack empty
*** Error in `./stack_cas_malloc': free(): invalid pointer: 0x00007fcc700008b0 ***
Aborted (core dumped)
----

En sistemas con un único procesador, como en Raspberry 1, quizás necesites de varias ejecuciones para que aparezca el error, o aumentar el número de operaciones en `OPERATIONS`, pero ocurrirá. Es uno de los problemas inherentes de la programación concurrente, a veces la probabilidad de que ocurra el error es muy baja y hace más difícil detectar. Algunas implementaciones de `malloc` no retornan las direcciones usadas recientemente por lo que quizás no observes el error de doble liberación del mismo puntero. Podemos forzar al reuso de direcciones recientes mediante una segunda pila.

[[double_stack]] En vez de liberar la memoria de los nodos con el `free` los insertamos en una segunda lista `free_nodes`, los nodos que se eliminan de la lista `head` son insertados en la lista de libres. En vez de asignar memoria con `malloc`cada vez que se crea un nuevo nodo se busca primero de la lista de libres y se lo reusa. El código <<stack_cas_freelist_c>> ejecutará repetidamente el siguiente código:


[source, c]
----
e = pop(&free_nodes); <1>
if (! e) {
	e = malloc(sizeof(struct node)); <2>
	printf("malloc\n");
}
e->data.tid = tid;
e->data.c = i;
push(&head, e); <3>
e = pop(&head); <4>
if (e) {
	push(&free_nodes, e); <5>
} else {
	printf("Error, stack empty\n"); <6>
}
----
<1> Obtenemos un nodo de la lista de libres.
<2> La lista de libres estaba vacía, se solicita memoria. En la siguiente línea se imprime, debería haber como máximo tantos `malloc` como hilos.
<3> Se agrega el elemento a la pila de `head`.
<4> Se elimina un elemento de la pila de `head`.
<5> Se se pudo obtener el elemento se agrega el elemento a la pila de libres.
<6> La lista estaba vacía, es un error.

La ejecución del programa dará numerosos errores de de la pila vacía y se harán también más `malloc` de los que debería. Es consecuencia del problema ABA.



===== Compare&Swap etiquetado
Una solución para el problema ABA es el usar bits adicionales como etiquetas para identificar una _transacción_ (_tagged CAS_). Para ello algunas arquitecturas introdujeron instrucciones _CAS_ que permiten la verificación e intercambio de más de una palabrafootnote:[Los _registros atómicos_ explicados antes.], como Intel con las instrucciones `cmpxchg8b` y `cmpxchg16b` dobles que permiten trabajar con estructuras de 64 y 128 bits, en vez de sólo registros atómicos de 32 o 64 bits. En nuestro caso necesitamos hacerlo sólo para verificar el intercambio de las cabeceras, por lo que usaremos la estructura `node_head` para ambas.

[source, c]
----
struct node_head {
	struct node *node; <1>
	uintptr_t aba; <2>
};

struct node_head stack_head; <3>
struct node_head free_nodes;
----
<1> El puntero al nodo que contiene los datos.
<2> Será usada como etiqueta, un contador que se incrementará en cada _transacción_. Es un entero del mismo tamaño que los punteros (32 o 64 bits según la arquitectura),
<3> Los punteros a las pilas no serán un simple puntero sino la estructura con el puntero y la etiqueta.

El código completo en C está en <<stack_cas_tagged_c>>, pero analizemos el funcionamiento de de _push_.

[source, c]
----
void push(struct node_head *head, struct node *e) {
	struct node_head orig, next;

	__atomic_load(head, &orig); <1>
	do {
		next.aba = orig.aba + 1; <2>
		next.node = e;
		e->next = orig.node; <3>
	} while (! CAS(head, &orig, &next); <4>
}
----
<1> Al tratarse de una estructura no es un _registro atómico_ debemos asegurar que se hace una copia atómica de `head` a `orig`.
<2> `next` tendrá los datos de `head` después del _CAS_, en este incrementamos el valor de `aba`.
<3> El nodo siguiente de nuevo nodo es el que está ahora en la cola.
<4> Se intenta el intercambio, sólo se hará si tanto el puntero al nodo y el entero `aba` son idénticos a los copiados en `orig`. Si entre <1> y <4> el valor de `head` es cambiado por otros procesos el valor de `aba` habrá cambiado (será un valor mayor) por lo que _CAS_ retornará falso aunque el puntero al nodo sea el mismo.


==== Load-link/store-conditional (_LL/SC_)

_compareAndSwap_ es la más potente de las operaciones atómicas anteriores ya que permite el _consenso_ con infinitos procesos (_consenso de clase N_). Sin embargo en algunas arquitecturas RISC (PowerPC, Alpha, MIPS y ARM) implementaron una técnica diferente para implementar registros _RMW_ tan potente que puede emular a cualquiera de las anteriores, el _LL/SC_. De hecho, si has compilado los programas de ejemplos en algunas de esas arquitecturas (por ejemplo en una Raspberry) el compilador habrá reemplazado llamadas a esas operaciones por una serie de instrucciones que las emulan.

El diseño de _LL/SC_ es muy ingenioso, se basa en dos operaciones diferentes que trabajan en cooperación con la gestión de caché. Una es similar a la tradicional cargar (_load_) una dirección de memoria en un registro: LWARX en PowerPC, LL en MIPS, LDREX en ARM. La otra a la de almacenar (_store_) un registro en una dirección de memoria: STWC en PowerPC, SC en MIPS y STREX en ARM. La diferencia es que ambas están _enlazadas_, tomemos LDREX y STREX de la arquitectura ARM.

LDREX::
Carga una dirección de memoria en un registro y _etiqueta_ o marca esa dirección como de _acceso exclusivo_. Luego puede ejecutarse cualquier número de instrucciones hasta el STREX.

STREX::
Almacena el valor de un registro en una dirección de memoria pero solo si esa dirección ha sido _reservada_ anteriormente con un LDREX y no ha sido modificada por ningún otro proceso. Por ejemplo la siguiente instrucción :

El siguiente código carga el contenido de la dirección indicada por `r0` en el registro `r1` y marca esa direcciónfootnote:[En ARM se etiqueta en el sistema del _monitor de acceso exclusivo_, en otras arquitecturas asocia un bit del TLB o de memorica cache.]:


----
ldrex   r1, [r0] <1>
...
strex   r2, r1, [r0] <2>
----
<1> Carga el contenido de la dirección indicada por `r0` en el registro `r1` y marca esa direcciónfootnote:[En ARM se etiqueta en el sistema del _monitor de acceso exclusivo_, en otras arquitecturas asocia un bit del TLB o de memorica cache.]
<2> Almacena el valor del resgistro `r1` en la dirección apuntada por `r0` si y solo sí esa dirección no fue modificada por otro proceso. Si se almacenó se pone `r2` en `0`, caso contrario en `1`.

Vale la pena analizar algunas de las emulaciones de instrucciones atómicasfootnote:[Si quieres presumir has de llamarles "implementaciones de registros _RMW_".], por ejemplo _getAndAdd_ y _compareAndSwap_:

._getAndAdd_
----
.L1:
    ldrex   r1, [r0] <1>
    add     r1, r1, #1 <2>
    strex   r2, r1, [r0] <3>
    cmp     r2, #0
    bne     .L1 <4>
----
<1> Carga la dirección especificada por `r0` en `r1`.
<2> Incrementa en 1.
<3> Almacena _condicionalmente_ la suma.
<4> Si falló vuelve a intentarlo cargando el nuevo valor.


[[CAS_assembly]]
._compareAndSwap_
----
	ldr     r0, [r2] <1>
.L1
	ldrex   r1, [r3] <2>
	cmp     r1, r0
	bne     .L2 <3>
	strex   lr, ip, [r3] <4>
	cmp     lr, #0
	bne     .L1 <5>
.L2
	...
----
<1> Carga el contenido de la primera dirección en `r0`.
<2> Carga el contenido de la segunda dirección en `r1`.
<3> El resultado de la comparación es falso, sale del CAS.
<4> Intenta almacenar el nuevo valor en la dirección indicada por `r3` (es decir, hace el _swap_).
<5> Si no se pudo almacenar vuelve a intentarlo.


===== _LL/SC_ y ABA
Las implementaciones en hardware de las instrucciones _LL/SC_ tiene algunos problemas que afectan a la eficiencia. El resultado del _store condicional_ retorne con errorfootnote:[No implica que falle el algoritmo implementado, solo que fuerza que se haga otro bucle de lectura y escritura.] _espurio_ por cambios de contexto, emisiones _broadcast_ en el bus de cache, actualizaciones en la misma línea de cache o incluso otras operaciones de lectura o escritura no relacionadas entre el _load_ y el _store_. Por eso la recomendación general es que el fragmento de código dentro de una seccion exclusiva sea lo más breve y eficiente posible.

La mayor ventaja de las instrucciones _LL/SC es que no sufren del problema ABA. Es muy sencillo, con _LL/SC_ es imposible que ocurra porque el primer cambio invalidaría el _store_ condicional. Cuando analizamos el problema ABA vimos demostramos cómo se puede reproducir el problema <<double_stack, con un par de colas>>, una para los nodos y la otra para los que quedan libres. El algoritmo usa el macro atómico para _compareAndSwap_ y cuando se traduce a ensamblador para arquitecturas como ARM se traduce a código que emula el _compareAndSwap_



https://twitter.com/sergiolpascual


.Comparación de tiempos en Raspberry 1
|===
|Programa |Tiempo de reloj

|Pila con malloc, CAS (problema ABA)
|8.6 seg

|Doble pila, CAS (problema ABA)
|4.9 seg

|Doble pila CAS etiquetado (sin ABA)
|10.0 seg

|Doble pila con LL/SC (ensamblador, sin ABA)
|2.3 seg
|===

Reader-writer: https://jfdube.wordpress.com/2014/01/03/implementing-a-recursive-read-write-spinlock/
https://jfdube.wordpress.com/2014/01/12/optimizing-the-recursive-read-write-spinlock/



(http://nullprogram.com/blog/2014/09/02/ https://github.com/skeeto/lstack)
Common Pitfalls in Writing Lock-Free Algorithms http://blog.memsql.com/common-pitfalls-in-writing-lock-free-algorithms/

Toward generic atomic operations/The C11 memory model http://lwn.net/Articles/509102/

Ticket Spinlocks: http://lwn.net/Articles/267968/

MCSLocks http://lwn.net/Articles/590243/

Improving ticket spinlocks  http://lwn.net/Articles/531254/


==== MCS Spinlocks

[[mcs_queue]]
.Cola MCS
image::mcs.png[width=400, align="center"]
