[[hardware]]
== Soluciones por hardware
Hasta ahora hemos visto soluciones al problema de la exclusión mutua sin soporte de hardware y con solo _registros de lectura-escritura atómicos_, todos ellos son _spinlocks_ pero muy ineficientes. Por un lado por el consumo de memoria, tanto para la solución de dos procesos (Dekker y Peterson) como para _N_ procesos (Panadería) el número de registros necesarios es proporcional al número de procesos máximos que sincronizaránfootnote:[Está demostrado (<<Herlihy12>>) que dichos algoritmos son óptimos en cuestión de espacio]. Esta necesidad de memoria impone una sobrecarga importante para mantener la consistencia de la memoria caché, además del consumo de CPU por la espera activa todos los procesos involucrados tienen que acceder al mismo rango de memoria que los demás. Es una penalización muy importante para sistemas con varios  procesadores o núcleos. Por otro lado, si se tiene un único procesador el avance es tan lento que lo que tarda décimas en uno puede tomar horas en otros en casos de mucha _competencia_ (_contention_) porque varios procesos desean entrar a la sección crítica de forma casi simultánea.

Desde el inicio se buscaron soluciones por hardware que permitiesen implementar algoritmos de sincronización de forma mucho más eficiente.


=== Deshabilitar interrupciones
Si el problema fundamental es el intercalado de instrucciones generado por las interrupciones al procesador ¿por qué no deshabilitarlas?. Aunque es una solución que se usa en casos muy específicos en sistemas operativosfootnote:[Como _local_irq_disable()_ o _local_irq_enable()_ en Linux.] no es una solución genérica segura: si los procesos pueden deshabilitar las interrupciones entonces pueden tomar control del sistemafootnote:[Deshabilita la cualidad de _apropiativo_ (o _preemptive_) del _scheduler_.]. Por lo tanto no es una solución válida para procesos de usuario.

Aún al nivel del núcleo del sistema operativo presenta dificultades: la complicación de deshabilitar todas las interrupciones en todos los procesadores y el riesgo de perderlas. Por esta dificultad de deshabilitar las interrupciones en varios procesadores simultáneamente tampoco es una solución para asegurar exclusión mutua dado que un _registro_ puede ser modificado por un procesador diferente sin que haya habido intercalación en el mismo procesador.

=== Sincronización por hardware
Por ello se buscaron otras alternativas que en general son conocidas como _primitivas de sincronización de hardware_. Son instrucciones del procesador que leen y modifican el valor de uno o varios registros sin ser interrumpidas y asegurando la coherencia de caché (introducen barreras de memoria). Hay muchas variantes de estas instrucciones, los fabricantes diseñaron e implementaron sus propias instrucciones. No es fácil decidir cuál de ellas es la que implementarán en _silicio_, casi todas las arquitecturas ofrecen un conjunto variado: _getAndAdd_, _testAndSet (TAS)_, _swap_, _compareAndSwap (CAS)_, etc.

Pero antes de estudiarlas estudiaremos las definiciones de _registros_ que proporcionen modelos simples y genéricos de consistencia por encima de las interrupciones o mecanismos de consistencia de caché.

=== Tipos de registros
El término _registro_ no se refiere solo a los registros del procesador. Puede involucrar a zonas de memoria RAM, memoria caché o en general a un _objeto compartido_. A nivel de hardware los hilos se comunican leyendo y escribiendo en memoria compartida, desde ese punto de vista la comunicación se hace vía registros de lectura-escritura. Un registro de este tipo encapsula dos métodos, _read_ y _store_. O _get_ y _write_ cuando nos referimos a objetos compartidos en general y que pueden ser implementados en lenguajes de alto nivel.

[[safe_register]]
==== Registros _seguros_
Los registros con las propiedades de consistencia más débiles son los _registros seguros_, su nombre es un mero accidente histórico, son muy inseguros (<<Herlihy12>>). Estos tipos de registros solo aseguran que se retorna el último valor escrito si no hay operaciones _get_ y _write_ concurrentes, caso contrario podrá devolver cualquier valor aceptable en el rango del registro. Por ejemplo, si se trata de un único byte y haya procesos concurrentes que escriben solo +0+ o +1+ el _get_ de un registro seguro podría devolver cualquier valor entre +0+ y +255+ ya que todos están en el rango de 8 bits.

==== Registros regulares
Una alternativa intermedia son los _registros regulares_ donde una operación de lectura concurrente con escrituras puede retornar alguno de los valores que están siendo escritos. En un caso similar al anterior, el _get_ de este tipo de registros solo devolvería +0+ o +1+. Se dice que estos registros solo aseguran _consistencia por inactividad_ (_quiescent consistency_) ya que solo aseguran retornar el mismo valor después de un período de inactividad entre el último _write_ y el siguiente _get_.

[[atomic_register]]
==== Registros atómicos
Los registros de procesadores modernos que usamos para la implementación de los algoritmos de exclusión mutua son _registros atómicos_, generalmente se tratan de registros de un único bytes, una _palabra_, enteros de varios bytes, o referencias a memoria u objetos que cumplen las siguientes dos condiciones (<<Lamport2>>):

1. El método _get_ retorna el último valor escrito, si una lectura retorna un valor y no hubo otra escritura intermedia la siguiente lectura será el mismo valor.

2. Si hay varios _write_ concurrentes el valor que retornará el siguiente _get_ es uno de los valores del _write_ no un rango de posibles valores. Por ejemplo, si un _write_ concurrente es el número +0+ y otro es el número +1000+, el _get_ retornará +0+ o +1000+.

[[RMW]]
=== Primitivas de hardware y registros _Read-Modify-Write_
Como hemos observado en la implementación del algoritmo de la panadería, el requerimiento de registros atómicos para solucionar los problemas de exclusión mutua crece linealmente con el número de hilos o procesos involucrados. Tiene otros problemas, son _spinlocks_ sobre muchos registros que introducen mucha presión sobre grandes zonas de la caché, son muy ineficientes. El otro problema hemos visto es que obliga a la especificación manual -no siempre sencilla ni eficiente- para asegurar la consistencia secuencial.

Por ello no es de extrañar que desde el principio se introdujeron instrucciones atómicas del procesador que permitieron implementar algoritmos de sincronización más sencillos y eficientes. Este tipo de operaciones pueden ser expresadas como construcciones de registros denominados genéricamente _registros Read-Modify-Write_ o _RMW_. Los registros _RMW_ son interesantes porque pueden implementarse en construcciones de lenguajes o como instrucciones de procesador, sus propiedades son similares.


[NOTE]
[[consensus]]
.Registros RMW no triviales
====

Los registros _RMW_ que proveen operaciones adicionales a la _función identidad_ se denominan _no triviales_. <<Herlihy91,  Maurice Herlihy>> demostró que los registros no triviales tienen un _consenso_ de al menos 2 (o son de _clase 2_). Todas las instrucciones mencionadas anteriormente (a excepción de la identidad, obviamente) implementan registros _RMW_ no triviales.

De todas las implementaciones, _compareAndSwap_ (_CAS_) es la más potente. <<Herlihy91, Herlihy>> también demostró que pertenece a la clase de _consenso N_ (o _infinito_). Este tipo de instrucciones son, en palabras del autor, _a la computación asincrónica el equivalente de las máquinas de Turing de la computación secuencial_. Afortunadamente la mayoría de procesadores implementan _CAS_ o la similar _load-linked/store-conditional_ (o _LL/SC_, disponible en las arquitecturas PowerPC, MIPS, Alpha y ARM).

====

Hay varios tipos de instrucciones que implementan registros _RMW_:

- _get_: Retorna el valor del registro, se denomina también _función identidad_.
- _getAndSet_: Asigna un nuevo valor al registro y retorna el anterior.
- _getAndAdd_: Incrementa el valor del registro en el valor indicado y retorna el valor anterior.
- _testAndSet_: verifica el valor del registro, si es cero asigna el nuevo valor (habitualmente 1, por ejemplo en IBM 360 el registro es binario o booleano, solo admite 0 y 1).
- _swap_: Intercambia el valor de dos registros.
- _compareAndSwap_: Compara el valor del registro con otro, si son iguales asigna un nuevo y retorna el anterior.


Los fabricantes implementan conjuntos de operaciones diferentes, para facilitar la programación y portabilidad los compiladores proveen macros que generan la secuencias de instrucciones que usan o simulan las operaciones en cada arquitectura. Por ejemplo GCC <<Atomics, tenía los macros>> +\__sync_*+ que en las últimas versiones fueron reemplazados por <<Atomics_C11, nuevos macros>> más cercanos al modelo de memoria del C11 y C++11.


==== getAndSet
Usaremos una variable global +mutex+ que estará inicializada a cero que indica que no hay procesos en la sección crítica. En la entrada de la sección crítica se almacena +1+ y se verifica si el valor anterior era +0+ (es decir, no había ningún proceso en la sección crítica). Si era diferente a cero esperará hasta que lo sea.

La función +lock+ es la entrada a la sección crítica y +unlock+ la salida.

[source,python]
----
        mutex = 0

def lock():
    while getAndSet(mutex, 1) != 0:
        pass

def unlock():
    mutex = 0

----

En <<getAndSet>> está el código en C implementado con el macro `__atomic_exchange_n`. A pesar de su nombre no es la instrucción _swap_ sino un equivalente de _getAndSet_.


==== getAndAdd

Se puede implementar exclusión mutua con un algoritmo muy similar al de la _panadería_, cada proceso obtiene un número y espera a su turno, solo que esta vez la obtención del _siguiente número_ es atómica y por lo tanto no se necesita un array ni un bucle para controles adicionales.

Usaremos dos variables, +number+ para el siguiente número y +turn+ para indicar a qué número le corresponde entrar a la sección crítica.

[source,python]
----
        number = 0
        turn = 0

def lock():
    """ current is a local variable """
    current = getAndAdd(number, 1)
    while current != turn:
        pass

def unlock():
    getAndAdd(turn, 1)

----

[[get_and_add_ticket]]
El <<getAndAdd, código en C>> está implementado con el macro +\__atomic_fetch_add+ y <<gocounter_get_and_add_go, en Go>> con +atomic.AddUint32+.footnote:[Estrictamente no es _getAndAdd_ sino _addAndGet_, devuelve el valor después de sumar, pero son equivalentes, solo hay que cambiar la inicialización de la variable turn.] A diferencia de la implementación con _getAndSet_ esta implementación asegura que no se producen esperas infinitas ya que el número que _elige_ cada proceso es único y creciente, aunque hay que tener en cuenta que el valor de +number+ llegará a un máximo y rotará. Los _spinlocks_ de este tipo son también <<ticket_lock, llamados _ticket locks_>> y son muy usados en el núcleo de Linux, aseguran que no se producen esperas infinitas y que los procesos entran a la sección crítica en orden FIFO (_fairness_).



==== testAndSet
La instrucción _testAndSet_ o _TAS_ fue la instrucción más usada para control de concurrencia hasta la década de 1970 cuando fue reemplazada por operaciones que permiten niveles (_clase_) de consenso más elevados. La implementación consiste de una variable entera binaria (o _booleana_) que puede tomar valores 0 y 1. La instrucción solo recibe un argumento, la dirección de memoria. Si el valor de la dirección de memoria es +0+ le asigna +1+ y retorna +1+ (o _true_), caso contrario retorna +0+ (o _false).

[source,python]
----
def testAndSet(register):
    if register == 0:
        register = 1
        return 0

    return 1
----

La implementación de exclusión mutua con TAS es muy similar a _getAndSet_:

[source,python]
----
        mutex = 0

def lock():
    while testAndSet(mutex) == 0:
        pass

def unlock():
    mutex = 0

----

<<testAndSet, El código en C>> está implementado con el macro +__atomic_test_and_set+.


==== Swap
Esta instrucción intercambia atómicamente dos posiciones de memoria, usualmente enteros de 32 o 64 bitsfootnote:[No todas las arquitecturas la tienen, en Intel es +XCHG+ para enteros de 32 bits.]. El algoritmo de la instrucción es tan sencillo como parece:

[source,python]
----
def swap(register1, register2):
    tmp = register1
    register1 = register2
    register2 = tmp
----

El algoritmo de exclusión mutua con _swap_:

[source,python]
----
        mutex = 0

def lock():
    local = 1
    while local != 0:
        swap(mutex, local)

def unlock():
    mutex = 0
----

La <<counter_swap_c, implementación en C>> es con el macro `__atomic_exchange` de las últimas versiones de GCC. <<gocounter_swap_go, En Go>> se pueden usar las funciones atómicas implementadas en el paquete +sync/atomic+, por ejemplo con +atomic.SwapInt32+ footnote:[Esta función no estaba disponible en Go para ARM hasta 2013, si la pruebas en una Raspberry asegúrate de tener una versión de Go moderna.].

==== Compare&Swap

Esta instrucción, o _CAS_, es la más comúnfootnote:[Es la que se usa en la arquitectura Intel/AMD.] y la que provee el mayor _nivel de consenso_ (ver nota <<consensus>>)footnote:[Aunque sufre el _problema ABA_.]. La instrucción trabaja con tres valores:

Registro:: La dirección de memoria cuyo valores se comparará y asignará un nuevo valor si corresponde.
Nuevo valor:: El valor que se asignará al registro, o que recibirá el valor del registro.
Valor a comparar:: Si el valor del registro es igual a éste entonces se le asignará el nuevo valor, de lo contrario se copia el valor actual del _registro_ a la posición de memoria del _nuevo valor_ anteriorfootnote:[Es decir, se copia en el sentido inverso.].


En la versión modernafootnote:[En los <<Atomics, antiguos macros de GCC>> las instrucciones equivalentes son +\__sync_bool_compare_and_swap+ y +__sync_val_compare_and_swap+ respectivamente. La diferencia fundamental es que no se modifica el registro del valor a comparar.] de macros atómicos las dos versiones son +\__atomic_compare_exchange_n+ y +__atomic_compare_exchange+, ambas retornan un booleano si se pudo hacer el cambio, lo único que cambia es la forma de los parámetros (en el último caso son todos punteros). El algoritmo de estas instrucciones es:

[source,python]
----
def compareAndSwap(register, expected, desired):
    if registro == expected:
        registro = desired
        return True
    else:
        expected = register
        return False
----


La implementación de exclusión mutua <<counter_compare_and_swap_c, en C>> es sencilla, necesitamos una variable local porque hay que pasar un puntero y ambas instrucciones copiarán el valor de mutex a la posición indicada por el puntero:

[source,python]
----
        mutex = 0

def lock():
    local = 0
    while not compareAndSwap(mutex, local, 1):
        local = 0

def unlock():
    mutex = 0
----

La instrucción +CompareAndSwapInt32+ en <<gocounter_compare_and_swap_go, en Go>> es algo diferente y más similar al antiguo macro de GCC, los argumentos del valor _esperado_ y el _nuevo_ no se pasan por puntero sino por valor:

[source,go]
----
func lock() {
    for ! atomic.CompareAndSwapInt32(&mutex, 0, 1) {}
}
----


===== El problema ABA
_CAS_ tiene un problema conocido, el _problema ABA_. Aunque no se presenta en casos sencillos como el de exclusión mutua sino en casos de intercalados donde un proceso lee el valor _A_ y cede la CPU a otro proceso, otro modifica el registro con el valor _B_ y vuelve a poner el mismo valor _A_ antes que el primero se vuelva a ejecutar. Éste ejecutará la instrucción _CAS_ sin haber _notado_ el cambio.

[[free_lock_stack]]
Un caso práctico con implementación de _pilas concurrentes sin bloqueo_ (_free-lock stacks_). La estructura   +node+ tiene un puntero al siguiente elemento (_next_) y a una estructura que guarda los datos (o +payload+, su estructura interna nos es irrelevante):

[[struct_node]]
[source, c]
----
struct node {
    struct node *next;
    struct node_data data;
};
----

Las funciones +push+ y +pop+ agregan y quitan elementos de la pila, +push+ recibe como argumentos el puntero a la variable cabecera de la pila y el puntero al nodo a añadir, +pop+ el puntero a la cabeza de la pila y devuelve el puntero al primer elemento de la pila o +NULL+ si está vacía. A continuación el código en C simplificado de ambas funciones.


[source, c]
----
void push(struct node **head, struct node *e) {
    e->next = *head;                  <1>
    while (! CAS(head, &e->next, &e); <2>
}
----
<1> El nodo siguiente al nodo a insertar será el apuntado por la cabecera.
<2> Si la cabecera no fue modificada se hará el cambio y apuntará al nuevo nodo +e+. Si por el contrario +head+ fue modificada, el nuevo valor de +head+ se copia a +e->next+ (apuntará al elemento nuevo que apuntaba +head+) y se volverá a intentar. Cuando se haya podido hacer el _swap_ +head+ apuntará correctamente a +e+ y +e->next+ al elemento que estaba antes.

[source, c]
----
struct node *pop(struct node **head) {
    struct node *result, *orig;

    orig = *head;
    do {
        if (! orig) {
            return NULL;              <1>
        }
    } while (! CAS(head, &orig, &orig->next)); <2>

    return orig;                      <3>
}
----
<1> Si es +NULL+ la pila está vacía y retorna el mismo valor.
<2> Si la cabecera apuntaba a un nodo y no fue modificada se hará el cambio y la cabecera apuntará al siguiente nodo. Si por el contrario fue modificada se hará una copia del último valor a +orig+ y se volverá a intentar.
<3> Se retorna el puntero al nodo que antes apuntaba la cabecera.

Este algoritmo es correcto para gestionar una pila concurrente pero solo si es imposible eliminar un nodo y volver a insertar otro nuevo con la misma dirección de memoria. Con _CAS_ es imposible saber si otro proceso ha modificado y vuelto a insertar el mismo valor que copiamos (en este caso +orig+). Supongamos una pila con tres nodos que comienzan en la direcciones 10, 20 y 30:

+head => [10] => [20] => [30]+

El proceso _P1_ acaba de ejecutar +orig = *head;+ dentro de _pop_ y es interrumpido. Otro u otros procesos eliminan dos elementos de la pila:

+head => [30]+

Y luego uno de ellos inserta un nuevo nodo con una dirección de memoria usada previamente:

+head => [10] => [30]+

Cuando _P1_ continúe su ejecución _CAS_ hará el cambio ya que la dirección es también +10+. El problema es que era una copia antigua que apuntaba antes a +[20]+ por lo que dejará la cabecera apuntando a un nodo que ya no existe y los siguientes habrán quedado _descolgados_ de la pila:

+head => ¿20?    [30]+

Este caso es muy habitual si usamos +malloc+ para cada nuevo nodo que insertamos y luego el +free+ cuando lo eliminamos de la listafootnote:[Las implementaciones de +malloc+ suelen reusar las direcciones de los elementos que acaban de ser liberados.]. [[stack_cas_malloc]]El siguiente <<stack_cas_malloc_c, programa en C>> usa estas funciones en cuatro hilos diferentes, cada uno de ellos ejecuta repetidamente el siguiente código:

[source, c]
----
e = malloc(sizeof(struct node));
e->data.tid = tid;
e->data.c = i;
push(&head, e);           <1>
e = pop(&head);           <2>
if (e) {
    e->next = NULL;       <3>
    free(e);
} else {
    puts("Error, empty"); <4>
}
----
<1> Se agrega el elemento nuevo a la pila, su memoria de fue obtenida con el +malloc+ de la línea anterior.
<2> Inmediatamente se lo elimina de la lista. El resultado nunca debería ser +NULL+ ya que siempre debería haber al menos un elemento: todos los hilos primero agregan y luego lo quitan.
<3> Antes de liberar la memoria del elemento recién eliminado se pone +next+ en +NULL+. No debería hacer falta pero lo hacemos por seguridad y para que observéis claramente que los errores son por el problema ABA.
<4> Si no pudo obtener un elemento de la lista es un error y lo indicamos.

Si lo ejecutáis veréis que en todos los casos da el error de la pila vacía y/o de error por intentar liberar dos veces la misma memoria.

----
Error, stack empty
*** Error in `./stack_cas_malloc': free(): invalid pointer: 0x00007fcc700008b0 ***
Aborted (core dumped)
----

En sistemas con un único procesador quizás necesites de varias ejecuciones o aumentar el número de operaciones en +OPERATIONS+ para que aparezca el error. Es uno de los problemas inherentes de la programación concurrente, a veces la probabilidad de que ocurra el error es muy baja y hace más difícil detectarlos. Algunas implementaciones de +malloc+ no retornan las direcciones usadas recientemente por lo que quizás no observes el error de doble liberación del mismo puntero. Podemos forzar al reuso de direcciones recientes mediante una segunda pila.

[[cas_double_stack]] En vez de liberar la memoria de los nodos con el +free+ los insertamos en una segunda lista +free_nodes+, los nodos que se eliminan de la lista +head+ son insertados en la lista de libres. En vez de asignar memoria con +malloc+ cada vez que se crea un nuevo nodo se busca primero de la lista de libres y se lo reusa. <<stack_cas_freelist_c, El programa>> ejecutará repetidamente el siguiente código:


[source, c]
----
e = pop(&free_nodes);     <1>
if (! e) {
    e = malloc(sizeof(struct node)); <2>
    printf("malloc\n");
}
e->data.tid = tid;
e->data.c = i;
push(&head, e);           <3>
e = pop(&head);           <4>
if (e) {
    push(&free_nodes, e); <5>
} else {
    printf("Error, stack empty\n"); <6>
}
----
<1> Obtiene un nodo de la lista de libres.
<2> La lista de libres estaba vacía, se solicita memoria. En la siguiente línea se imprime, debería haber como máximo tantos +malloc+ como hilos.
<3> Se agrega el elemento a la pila de +head+.
<4> Se elimina un elemento de la pila de +head+.
<5> Se se pudo obtener el elemento se agrega el elemento a la pila de libres.
<6> La lista estaba vacía, es un error.

La ejecución del programa dará numerosos errores de de la pila vacía y se harán también más +malloc+ de los que debería. Es consecuencia del problema ABA.


[[stack_cas_tagged]]
===== Compare&Swap etiquetado
Una solución para el problema ABA es usar bits adicionales como etiquetas para identificar una _transacción_ (_tagged CAS_). Para ello algunas arquitecturas introdujeron instrucciones _CAS_ que permiten la verificación e intercambio de más de una palabrafootnote:[Los _registros atómicos_ explicados antes.], por ejemplo Intel con las instrucciones +cmpxchg8b+ y +cmpxchg16b+ dobles que permiten trabajar con estructuras de 64 y 128 bit, en vez de solo registros atómicos de 32 o 64 bits. En nuestro caso necesitamos hacerlo solo para verificar el intercambio de las cabeceras por lo que usaremos la estructura +node_head+ para ambas.


[source, c]
----
struct node_head {
    struct node *node; <1>
    uintptr_t aba;     <2>
};

struct node_head stack_head; <3>
struct node_head free_nodes;
----
<1> El puntero al nodo que contiene los datos.
<2> Será usada como etiqueta, un contador que se incrementará en cada _transacción_. Es un entero del mismo tamaño que los punteros (32 o 64 bits según la arquitectura),
<3> Los punteros a las pilas no serán un simple puntero sino la estructura con el puntero y la etiqueta.

El código completo en C está en <<stack_cas_tagged_c, stack_cas_tagged.c>>, analicemos el funcionamiento de +push+.

[source, c]
----
void push(struct node_head *head, struct node *e) {
    struct node_head orig, next;

    __atomic_load(head, &orig);  <1>
    do {
        next.aba = orig.aba + 1; <2>
        next.node = e;
        e->next = orig.node;     <3>
    } while (!CAS(head, &orig, &next); <4>
}
----
<1> Al tratarse de una estructura no es un _registro atómico_ mas bien un <<safe_register, _registro seguro_>>, debemos asegurar que se hace una copia atómica de +head+ a +orig+.
<2> +next+ tendrá los datos de +head+ después del _CAS_, en este incrementamos el valor de +aba+.
<3> El nodo siguiente de nuevo nodo es el que está ahora en la cola.
<4> Se intenta el intercambio, solo se hará si tanto el puntero al nodo y el entero +aba+ son idénticos a los copiados en +orig+. Si entre <1> y <4> el valor de +head+ es cambiado por otros procesos el valor de +aba+ habrá cambiado (será un valor mayor) por lo que _CAS_ retornará falso aunque el puntero al nodo sea el mismo.


==== Load-Link/Store-Conditional (_LL/SC_)

_compareAndSwap_ es la más potente de las operaciones atómicas anteriores ya que permite el _consenso_ con infinitos procesos (_consenso de clase N_). Sin embargo en algunas arquitecturas RISC (PowerPC, Alpha, MIPS y ARM) diseñaron una técnica diferente para implementar registros _RMW_, es tan potente que puede emular a cualquiera de las anteriores: el _LL/SC_. De hecho, si has compilado los programas de ejemplos en algunas de esas arquitecturas (por ejemplo en una Raspberry) el compilador habrá reemplazado por llamadas a esas operaciones por una serie de instrucciones con _LL/SC_ que las emulan.

El diseño de _LL/SC_ es muy ingenioso, se basa en dos operaciones diferentes que trabajan en cooperación con la gestión de caché. Una es similar a la tradicional cargar (_load_) una dirección de memoria en un registro: LWARX en PowerPC, LL en MIPS, LDREX en ARM. La otra a la de almacenar (_store_) un registro en una dirección de memoria: STWC en PowerPC, SC en MIPS y STREX en ARM. El matiz importante es que ambas están _enlazadas_, la ejecución de la segunda es condicional si el registro objetivo no fue modificado desde la ejecución de la primera. Tomemos por LDREX y STREX de la arquitectura ARM.

LDREX:: Carga una dirección de memoria en un registro y _etiqueta_ o marca esa dirección como de _acceso exclusivo_. Luego puede ejecutarse cualquier número de instrucciones hasta el STREX.

STREX:: Almacena el valor de un registro en una dirección de memoria pero solo si esa dirección ha sido _reservada_ anteriormente con un LDREX y no ha sido modificada por ningún otro proceso. Por ejemplo las siguiente instrucciones:

----
ldrex   r1, [r0]     <1>
...
strex   r2, r1, [r0] <2>
----
<1> Carga el contenido de la dirección indicada por +r0+ en el registro +r1+ y marca esa direcciónfootnote:[En ARM se etiqueta en el sistema del _monitor de acceso exclusivo_, en otras arquitecturas se asocia un bit del TLB o de memoria caché.]
<2> Almacena el valor del registro +r1+ en la dirección apuntada por +r0+ si y solo sí esa dirección no fue modificada por otro proceso. Si se almacenó se pone +r2+ en +0+ caso contrario en +1+.

Vale la pena analizar algunas de las emulaciones de instrucciones atómicasfootnote:[Si quieres presumir has de llamarles "implementaciones de registros _RMW_".], por ejemplo _getAndAdd_ y _compareAndSwap_:

._getAndAdd_
----
.L1:
    ldrex   r1, [r0]     <1>
    add     r1, r1, #1   <2>
    strex   r2, r1, [r0] <3>
    cmp     r2, #0
    bne     .L1 <4>
----
<1> Carga la dirección especificada por +r0+ en +r1+.
<2> Incrementa en 1.
<3> Almacena _condicionalmente_ la suma.
<4> Si falló vuelve a intentarlo cargando el nuevo valor.


[[CAS_assembly]]
._compareAndSwap_
----
    ldr     r0, [r2]     <1>
.L1
    ldrex   r1, [r3]     <2>
    cmp     r1, r0
    bne     .L2          <3>
    strex   lr, ip, [r3] <4>
    cmp     lr, #0
    bne     .L1          <5>
.L2
    ...
----
<1> Carga el contenido de la primera dirección en +r0+.
<2> Carga el contenido de la segunda dirección en +r1+.
<3> El resultado de la comparación es falso, sale del _CAS_.
<4> Intenta almacenar el nuevo valor en la dirección indicada por +r3+ (es decir, hace el _swap_).
<5> Si no se pudo almacenar vuelve a intentarlo.


===== _LL/SC_ y ABA
Las implementaciones en hardware de las instrucciones _LL/SC_ tiene algunos problemas que afectan a la eficiencia. El resultado del _store condicional_ puede retornar erroresfootnote:[No implica que falle el algoritmo implementado, solo que fuerza que se haga otro bucle de lectura y escritura.] _espurios_ por cambios de contexto, emisiones _broadcast_ en el bus de caché, actualizaciones en la misma línea de caché o incluso otras operaciones de lectura o escritura no relacionadas entre el _load_ y el _store_. Por eso la recomendación general es que el fragmento de código dentro de una sección exclusiva sea breve y que se minimicen los almacenamientos a memoria.

La mayor ventaja de las instrucciones _LL/SC_ es que no sufren del problema ABA, el primer cambio ya invalidaría el _store_ condicional posterior. Cuando analizamos el problema ABA vimos cómo se puede reproducir el problema <<cas_double_stack, con un par de colas>>, una para los nodos y la otra para los que quedan libres. El algoritmo usa el macro atómico para _compareAndSwap_ y cuando se traduce a ensamblador para arquitecturas como ARM se traduce a código que emula el _compareAndSwap_. En una arquitectura con _LL/SC_ es mejor implementarlo directamente con esas instrucciones, pero a menos que lo hagas con los compiladores de los fabricantes no contamos con los macros adecuadosfootnote:[Al menos no en GCC.], por lo que debemos recurrir a ensamblador para hacerlo.


[[llsc]]
===== _LL/SC_ en ensamblador nativo
Dividimos el código en dos partes. La de <<stack_llsc_freelist_c, C>> es similar al <<stack_cas_freelist_c, ejemplo anterior con doble pila>> pero sin la implementación de las funciones +pop+ y +push+. Éstas están implementadas <<stack_llsc_freelist_s, en ensamblador>> de ARMfootnote:[Para que funcione en una Raspberry, agradezco a https://twitter.com/sergiolpascual[Sergio L. Pascual] por ayudarme a mejorar y probar el código.] y trabajan con <<safe_register, la misma estructura de pila anterior>>.

El código es bastante sencillo de entender, vamos a ver analizar en detalle la función +pop+ que es la más breve de ambas:

.pop()
----
pop:
    push    {ip, lr}
1:
    ldrex   r1, [r0]     <1>
    cmp     r1, #0
    beq     2f           <2>
    ldr     r2, [r1]     <3>
    strex   ip, r2, [r0] <4>
    cmp     ip, #0
    bne     1b           <5>
2:
    mov     r0, r1       <6>
    pop     {ip, pc}
----
<1> Carga _LL_ del primer argumento de la función (_head_), la dirección del primer elemento de la lista punterofootnote:[Recordad que el primer argumento de la función es la _dirección_ del puntero, es decir un _puntero a puntero_.].
<2> En la línea anterior se compara si es igual a cero, de ser así es porque la cola está vacía, sale del bucle para devolver el puntero +NULL+.
<3> Carga en +r2+ el puntero del siguiente elementofootnote:[Dado que +next+ es el primer campo del nodo su dirección coincide con la del nodo, por eso no hay _desplazamieno_ en el código ensamblador cuando lee o modifica +next+.] de la lista, la dirección de +e->next+ de <<struct_node, la estructura del nodo>>.
<4> Almacena el siguiente elemento en +head+.
<5> Copia el contenido de +r1+ a +r0+, que es el valor devuelto por la función.

Una vez conocidas las características y posibilidades de _LL/SC_ es relativamente sencillo simular las otras operaciones atómicas y quizás aún más sencillo implementar el algoritmo directamente basado en _LL/SC_. La dificultad es que no es habitual contar con macros genéricos debido a que en arquitecturas sin _LL/SC_ es muy complicado simular estas operaciones con instrucciones _CAS_, por lo que habrá que recurrir a ensamblador y además con una versión para cada plataforma que lo implemente.

Pero si se hace correctamente además de evitar el problema ABA se puede hacer mucho más eficiente. Los siguientes son los tiempos de ejecución de los algoritmos de pilas concurrentes en Raspberry 1 y 2.

[[free_lock_stack_times]]
.Tiempos de ejecución de pila concurrente en Raspberry
[caption=""]
image::free_lock_stacks.png[align="center"]


Con un único procesador del ARM6 la implementación con _LL/SC nativo_ es más de dos veces más rápido que el siguiente más rápido, que sufre del problema ABAfootnote:[Y por lo tanto incorrecto.] y más de cuatro veces más rápido que la simulación de _CAS etiquetado_. En el más moderno ARM7l con varios núcleos el _CAS con malloc_ es el más rápido (pero erróneo), la implementación en ensamblador con LL/SC es la siguiente más rápida aunque las diferencias con el _CAS etiquetado_ implementado en C con los macros atómicos de GCC no es tan notable.

=== Recapitulación

En este capítulo hemos visto las instrucciones por hardware esenciales, tanto para sistemas operativos como lenguajes, para construir primitivas de sincronización de más alto nivel. Las técnicas que usan estas primitivas -directa o indirectamente- son llamados _spinlocks_. Las hemos analizado desde las más básicas hasta las más potentes como _CAS_ y _LL/SC_. Aunque comenzamos solo con el objetivo de resolver el problema fundamental de sincronización entre procesos -exclusión mutua- hemos introducido el uso de las mismas para problemas más sofisticados, como el _CAS etiquetado_ y el uso de _LL/SC_ para gestión de pilas concurrentes sin bloqueo.

No hay instrucciones de hardware unificadas para todas las arquitecturas, tampoco una estandarización a nivel de lenguajes de programación. Esa es la razón por la que los compiladores implementan sus propios _macros atómicos_ que luego son convertidos a  funciones más complejas que simulan a las instrucciones o registros _RMW_ definidos por el macro. Lo vimos claramente con la arquitectura ARM, todas las operaciones se simulan con _LL/SC_. La inversa es más complicada -sino imposible- por lo que habitualmente no se cuentan con esos macrosfootnote:[Salvo los compiladores de los propios fabricantes que los incluyen en sus compiladores propietarios, en ARM se llaman _intrinsics_] y hay que recurrir al ensamblador para poder aprovechar las capacidades de nativas de cada procesador, muy habitual en los sistemas operativosfootnote:[Por ejemplo en Linux se usa el ensamblador +inline+, +ASM()+.].

De todas maneras los _spinlocks_ basados en instrucciones por hardware son fundamentales y se requieren algoritmos muy eficientes sobre todo para multiprocesadores o núcleos. Además de solucionar problemas la exclusión mutua interesa gestionar estructuras concurrentes habituales (pilas, listas, lectores-escritores, etc.) que minimicen el impacto sobre el sistema de caché. Este será el tema del siguiente capítulo.

==== Por las dudas

En todos los ejemplos de exclusión mutua vistos hasta ahora la sección crítica consistía solo en incrementar un contador compartido. Es perfecto para mostrar que una instrucción y operación aritmética que en apariencia son tan simples también son víctimas del acceso concurrente desorganizado. Pero espero que os hayáis dado cuenta que no hace falta recurrir a un _spinlock_ para hacerlo correctamente, hay instrucciones de hardware que lo hacen de forma eficiente, como el _getAndAdd_ o _addAndGet_.

Por ejemplo en  C:

[source, c]
----
for (i=0; i < max; i++) {
    c = __atomic_add_fetch(&counter, 1, __ATOMIC_RELAXED);
}
----

O en Go:

[source, go]
----
for i := 0; i < max; i++ {
    c = atomic.AddInt32(&counter, 1)
}
----
