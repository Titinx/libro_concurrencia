== Semáforos

El concepto de semáforos lo inventó Edsger W. Dijkstra a finales de los años 60 (<<Dijkstra74>>), aunque las primers ideas son de principios de la misma década (<<Dijkstra35>>). La idea y nombre está inspirado de las señales visuales ferroviarias que indican si un tren está habilitado para entrar en una vía. Es una construcción sencilla, eficiente y muy utilizada que permite solucionar problemas genéricos de sincronización entre procesos.

Las soluciones a la exclusión mutua y otros mecanismos de sincronización vistos hasta ahora no requieren la colaboración del sistema operativo, funcionan directamente sobre el _hardware desnudo_. En cambio los semáforos se implementan habitualmente como servicios de los sistemas operativos. Estos tienen la característica _intrínseca_ de bloquear y planificar para ejecución de los procesos e hilos. Bloquear a un proceso hasta que pueda continuar su ejecución no necesita de funcionalidades adicionales sofisticadas, los sistemas operativos hacen lo mismo para todas las operaciones de entrada-salida. En el caso de semáforos los procesos se bloquean o ejecutan condicionados únicamente por el valor que tiene una variable entera. Una abstracción tan simple como potente.


=== Definición
Un semáforo es una construcción definida por una variable entera, el _valor_ del semáforo, que puede tomar valores no negativos y una cola de procesos _bloqueados_ en el semáforo. La estructura es similar a la siguiente:

----
struct Semaphore {
    unsigned value;
    Queue q;
}
----

Un semáforo puede ser inicializado con un valor no negativo, por ejemplo la siguiente indica que el valor del semáforo (la variable _value_) será inicializada con `1`:

----
Semaphore s = 1
----

Sobre la estructura de datos anteriores se definen dos primitivas fundamentalesfootnote:[La mayoría de lenguajes y librerías de concurrencia ofrecen funciones adicionales.]: _P_ y _V_.

Pfootnote:[De la contracción _Prolaag_ del holandés _proberen te verlagen_ que significa _intentar decrementar_.]:: Si el contador es mayor que cero lo decrementa, caso contrario bloquea al proceso que la llamó. Actualmente es más conocida como *_wait_* o *_acquire_*

Vfootnote:[Del holandés _Verhoog_ o _verhogen_ que significa _incrementar_.]:: Si hay un algún proceso bloqueado en el semáforo lo desbloquea para que pueda continuar su ejecución, caso contrario incrementa el valor. Esta operación es más conocida como *_signal_*, *_release_* o *_post_*.

El algoritmo de ambas:

._wait_
----
def wait(s):
    if s.value > 0:
        s.value -= 1          <1>
    else:
        add(process, s.queue) <2>
        block(process)        <2>
----
<1> Solo se decrementa el valor del semáforo si es mayor que cero.
<2> Si es cero se bloquea al proceso que llamó a _wait_.


._signal_
----
def signal(s):
    if empty(s.queue):
        s.value += 1           <1>
    else:
        process = get(s.queue) <2>
        sched(process)         <2>
----
<1> Si no hay procesos bloqueados en la cola del semáforo (i.e. ésta está vacía) se incrementa su valor.
<2> Caso contrario se desbloquea a un proceso.


==== Exclusión mutua
El algoritmo de exclusión mutua es muy sencillo:

[source]
----
        Semaphore s = 1

...
wait(s)
critical_section()
signal(s)
...
----

Se inicializa el semáforo a `1`, cuando el primer proceso quiera entrar a la sección crítica decrementará su valor y continuará. Si otro proceso desea entrar el valor será cero por lo que se bloqueará hasta que el siguiente proceso ejecute el _signal_ y lo desbloquee. La solución del contador en <<sem_counter_c, C con semáforos POSIX>>, <<sem_counter_py, Python>> y <<sem_counter_java, Java>> usando semáforos.

Como ya puede intuirse, el valor del semáforo es un indicador del _número de recursos_ disponibles, en algunos lenguajes al valor del semáforo le denominan _permisos_ (_permits_). En el caso de exclusión mutua interesa que sólo haya un proceso en la sección crítica por ello el valor inicial es `1`. Pero se pueden programar casos más complejos de sincronización simplemente modificando el valor inicial del semáforo. Supongamos que tenemos un systema con _N_ procesadores y para evitar cambios de contextos innecesarios queremos que hay hasta _N_ procesos ejecutando una parte del código. En ese caso sólo hay que inicializar el valor del semáforo con _N_. Este tipo de uso de semáforos donde se permiten más de uno y hasta _N_ procesos en la sección crítica se denominan _multiplexes_.

==== Semáforos binarios
La definición anterior de semáforos permite valores cero y positivos, son denominados _semáforos generales_. Si el semáforo permite sólo valores de `0` y `1` se denominan _semáforos binarios_. Los semáforos binarios son equivalentes en el sentido que permiten resolver los mismos problemas, aunque con algunas líneas más de código, por ejemplo el algoritmo de Barz (<<Barz>>). Este algoritmo  emula semáforos contadores que usa un par de semáforos binarios (`mutex` y `gate`) y una variable entera (`value`).

Las funciones `generalWait` y `generalSignal` son las emulaciones genéricas de _wait_ y _signal_ respectivamente,  _k_ es el valor inicial del semáforo. El uso del semáforo `mutex` es obvio, asegura exclusión mutua en las secciones críticas de la implementación, allí donde se modifica y verifica el valor de la variable compartida `value`. El semáforo `gate` se usa para controlar qué procesos deben bloquearse o desbloquearse según el valor que tome `value`.

.Algoritmo de Barz
----
        BinarySemaphore mutex = 1
        BinarySemaphore gate = 1
        value = k

def generalWait():
    wait(gate)       <1>
    wait(mutex)
    value -= 1
    if value > 0:
        signal(gate) <2>
    signal(mutex)

def generalSignal():
    wait(mutex)
    value += 1
    if value == 1:
        signal(gate) <3>
    signal(mutex)
----
<1> Si no es el primer proceso en entrar a la sección crítica debe esperar a ser _autorizado_ por el proceso anterior.
<2> Si después de decrementar el valor es todavía mayor que cero permite que entre otro proceso.
<3> Si después de incrementarlo el valor es igual a uno significa que antes estaba en cero por lo que habilita para que pueda entrar otro proceso.


==== Semáforos _mutex_
Los _semáforos mutex_, también llamados _locks_ en algunos lenguajes (como Java o Python), son semáforos binarios optimizados para ser usados con exclusión mutuafootnote:[De allí el nombre _mutex_ de _mutual exclusion_, el mismo nombre que usé en los _spinlocks_ cuando se trataba de asegurar exclusión mutua.] con restricciones adicionales:

. Son inicializados a `1`.
. Se añade el concepto de propiedad, solo el proceso que hizo el _wait_ puede hacer luego el _signal_. En algunos lenguajes se permite que el mismo hilo haga varios _wait_, si ya es el propietario del _lock_ continúa su ejecución, estos últimos se denominan _reentrantes_.

Los _mutex_ son muy comunes y son recomendados para exclusión mutua, hay lenguajes como Go que no tienen funciones _nativas_ de semáforos generales, sólo mutex. De forma similar a cómo se hace con _spilonks_ en estos semáforos a la operación _wait_ se la suele llamar *_lock_* y a _signal_ *_unlock_*. El algoritmo genérico es similar a los semáforos,

[source]
----
        Mutex mutex

...
lock(mutex)
critical_section()
unlock(mutex)
...
----

En C se pueden usar los semáforos _mutex_ de librerías de POSIX Threads, las primitivas son `pthread_mutex_lock` y `pthread_mutex_unlock` (<<sem_mutex_c, programa en C>>). Go lo ofrece en el módulo `sync`, las primitivas son `Lock` y `Unlock` (<<go_mutex_go, código>>).

En <<sem_lock_java, Java se puede usar>> la clase `ReentrantLock` de java.util.concurrent.locks. Python tiene una clase similar, `threading.RLock()`, además <<sem_lock_py, de las llamadas tradicionales a `acquire` and `release`>> se puede usar <<sem_lock_with_py, con la cláusula `with`>>:

[source, python]
----
for i in range(MAX_COUNT/THREADS):
    with mutex:
        counter += 1
----


==== Semáforos fuertes y débiles
Cada semáforo tiene asociado una cola con la información de los procesos bloqueados, el sistema de gestión de esta cola es fundamental. Si la cola es una FIFO entonces asegura que los procesos entran en orden a la sección crítica, es decir, aseguran _espera limitada_ y estos semáforos se denominan _semáforos fuertes_. Por el contrario, si los procesos a desbloquear se seleccionan aleatoriamente se denominan _semáforos débiles_ (_weak semaphores_).

[NOTE]
.Semáforos en Unix y Linux
****

Semáforos System V:: Estos semáforos, parte del módulo IPC (_Inter Porcess Comunnication_) del UNIX System V fue el estándar de facto durante muchos años y siguen disponibles en las útimas versiones de Linux y Solaris. Desde la definición del estándar POSIX Semaphores de 2001 ha caído mucho en desuso ya que tiene una interfaz (API) poco elegante, ineficiente e innecesariamente compleja para los usos más habituales. En este estándar los semáforos se obtienen con `semget()` que retorna un array de semáforos (que puede ser de tamaño uno), se inicializan destruyen con `semctl()` y las operaciones de _wait_ y _signal_ se hacen con `semop()`. Ambas pueden incrementar o decrementar el valor de cada semáforo del array con valores a discreción, no sólo `1` o `-1` y hay que especificar siempre un array de valores y el índice del semáforo al que se aplica. Esta es la complejidad innecesaria para realizar operaciones simples, pero tiene características interesantes:
- Operaciones sobre varios semáforos del array son atómicas, facilita la programación de algoritmos complejos que lo requieran.
- La primitiva adicional esperar por cero o _wait_for_0_. Como se intuye por su nombre bloquea a los procesos si el valor del semáforo es diferente a cero, los desbloquea cuando se hace cero.
- Deshacer la última operación, `SEM_UNDO`, si el proceso acaba. Es útil como medida de protección, si un proceso está en la sección crítica y el proceso acaba por error el sistema revierte la última operación y los demás procesos pueden continuar.

Semáforos POSIX:: Están implementados en Linux desde la versión 2.6, lo usamos en el <<sem_counter_c, primer ejemplo de semáforos en C>>. Es el estándar actual y más usado, aunque carece de la flexibilidad y operaciones adicionales de los System V tiene una interfaz más sencilla y la implementación es más eficiente. Se pueden crear dos tipos, _sin nombre_ (_unnamed_) y _con nombre_ (_named_). El primero es más sencillo de usar cuando los procesos comparten la memoria, como es el caso de los _threads_ creados desde un único proceso, sólo hay que declarar una variable del tipo `sem_t` y luego inicializar el valor del semáforo con `sem_init()`. Cuando se necesitan en procesos que no comparten memoria se los puede crear y/o abrir con la función `sem_open()` usando un nombre similar a ficheros y luego inicialiarlos y usarolos igual que los semáforos _sin nombre_.

Mutex de POSIX Threads:: Las usamos en el <<sem_mutex_c, ejemplo anterior>> de semáforos _mutex_. No hay que confundirlos con los semáforos POSIX, en este caso se trata de las librerías POSIX para la implementación de hilos que incluyen mecanismos básicos de sincronización entre ellos: _mutex_ y variables de condiciónfootnote:[Las veremos en el capítulo <<monitors>>.].

****



=== Sincronización de orden de ejecución

La sección crítica es una abstracción -cómoda y sencilla- para resolver el problema de sincronización de varios procesos compitiendo por recursos compartidos. Otro problema común es la coordinación del orden de ejecución de operaciones de diferentes procesos (<<Ben-Ari>>). Supongamos dos procesos _P_ y _Q_, la instrucción _Q~j~_ debe ejecutarse solo después de la instrucción _P~i~_, se denota por como _P~i~ < Q~j~_. Para asegurar que se cumpla esta condición hay que asegurar antes de _Q~j~_:

- Continuar la ejecucion si _P~i~_ ya se ejecutó.
- Bloquear a _Q_ si _P~i~_ todavia no se ejecutó y desbloquearlo una vez que se haya ejecutado _P~i~_.

Para ello se necesita un semáforo (contador o binario) inicializado a cero. Inmediatamente después de _P~i~_ se llama _signal_ sobre dicho semáforo. En el proceso _Q_ se llama a _wait_ inmediatamente antes de _Q~i~_. Los programas serán similares al siguiente ejemplo:

----
        Semaphore sync = 0

P               Q

...             ...
Pi              wait(sync)
signal()        Qj
...             ...
----


==== Productores-Consumidores

El problema de los productores-consumidores es muy común y es un ejemplo de sincronización de orden de ejecución. Hay dos tipos de procesos incolucrados:

Productores:: Produce un nuevo elemento que será transmitido al o los consumidores.
Consumidores:: Recibe y consume los elementos transmitidos desde los productores.

Los productores-consumidores son muy habituales en todos los sistemas informáticos, las tuberías entre procesosfootnote:[Como cuando se usa `|` entre dos comandos en el shell.], la E/S a dispositivos, la comunicaciones por red, etc. Hay dos tipos fundamentales de productores-consumidores:

Sincrónicos:: Cuando se produce un elemento debe se consumido inmediatamente antes de que el productor pueda agregar un nuevo elemento.

Asincrónicos:: El canal de comunicación tiene capacidad de almacenamiento, un _buffer_, por lo que no es necesario que los productores esperen a que cada elemento sea consumido, estos agregan los elementos a una cola y los consumidores obtienen el primer el primer elemento de ésta.

El segundo caso es el más habitualfootnote:[El sincrónico es similar al asincrónico con tamaño de _buffer_ uno.]. El uso de un _buffer_ permite que productores y consumidores avancen a su propio ritmo pero hay que sincronizarlos para hacer que los consumidores esperen si el _buffer_ está vacío y los productores si el _buffer_ está lleno. El algoritmo genérico para productores y consumidores es el siguiente:

.Productor
----
while True:
    data = produce()
    buffer.add(data)
----

.Consumidor
----
while True:
    data = buffer.get()
    consume(data)
----



[NOTE]
====
Debido a que el modelo productor-consumidor es muy común la mayoría de lenguajes ya ofrecen una implementación nativa o por librerías. Por ejemplo la clase `ArrayBlockingQueue` en Java, `Queue` en Python (`queue` partir de Python 3) y Ruby, los mensajes nativos de Go son productores-consumidores que pueden ser sincrónicos o asincrónicos (los estudiaremos en el capítulo <<messages>>).

En las siguientes secciones estudiaremos lo relevante: cómo se implementan los algoritmos usando solo semáforos, no como usar los ya implementados de cada lenguaje.
====

===== _Buffer_ infinito
Aunque no existe la memoria infinita y no es recomendable confiar en que la velocidad relativas de los productores es tal que el _buffer_ nunca crecerá más de tamaños razonablesfootnote:[Aunque si lo hará en el ejemplo], es una buen primer paso para la implementación del algoritmo más general.

No debemos preocuparnos de que el _buffer_ se llene, sólo de bloquear a los consumidores si el buffer está vacío, y desbloquearlos cuando hay nuevos elementos disponibles. Además del buffer compartido necesitaremos dos semáforos: `mutex` para asegurar exclusión mutua mientras se añaden o quitan elementos a la cola y otro semáforo contador de sincronización, `notEmpty`, para bloquear a los consumidores si el _buffer_ está vacío.


[source]
----
    Queue buffer
    Semaphore mutex = 1
    Semaphore notEmpty = 0
----


Los siguientes son los algoritmos (en notación de objetos) para los productores y consumidores respectivamente:

.Productor
----
while True:
    data = produce()

    mutex.wait()
    buffer.add(data)  <1>
    mutex.signal()

    notEmpty.signal() <2>
----
<1> Agrega un elemento dentro de una sección crítica.
<2> Señaliza el semáforo, su valor será el número de elementos en el _buffer_.


.Consumidor
----
while True:
    notEmpty.wait()     <1>

    mutex.wait()
    data = buffer.get() <2>
    mutex.signal()

    consume(data)
----
<1> Se bloquea si el _buffer_ está vacío, si no es así decrementa y obtiene el siguiente elemento. Notad que el valor del semáforo contador `notEmtpy` siempre se corresponde con el número de elementos disponibles en el _buffer_.
<2> Obtiene el elemento de la cola.

En el <<producer_consumer_infinite_py, código en Python>> podéis ver la implementación completa. hay dos clases, `Producer` y `Consumer` que implementa el algoritmo de productores y consumidores respectivamente. Se crean dos productores (variable `PRODUCERS`) y dos consumidores (`CONSUMERS`), los productores producen 1000 elementos (`TO_PRODUCE`) cada uno y acaban. Para el buffer se usa una lista nativa de Python, se agregan elementos con `append()` y se obtiene el primer elemento con `pop(0)`.

===== _Buffer_ finito
El algoritmo anterior puede ser fácilmente modificado para que funcione con un tamaño de _buffer_ limitado. Así como los consumidores se bloquean si no hay elementos en el _buffer_ debería también hacer lo mismo con los producrtores si no quedan _posiciones libres_. Necesitamos otro semáforo contador (`notFull`) cuyo valor indicará el número de posiciones libre y que se inicializará con el tamaño del _buffer_ (`BUFFER_SIZE`).

[source]
----
    Queue buffer
    Semaphore mutex = 1
    Semaphore notEmpty = 0
    Semaphore notFull = BUFFER_SIZE
----

Los siguientes son los algoritmos para cada proceso, solo se añade una línea a cada uno (el <<producer_consumer_py, código en Python>>):

.Productor
----
while True:
    data = produce()

    notFull.wait()    <1>

    mutex.wait()
    buffer.add(data)
    mutex.signal()

    notEmpty.signal()
----
<1> Se bloqueará si `notFull` vale cero, caso contrario lo decrementará y añadirá un nuevo valor.

.Consumidor
----
while True:
    notEmpty.wait()

    mutex.wait()
    data = buffer.get()
    mutex.signal()

    notFull.signal()    <1>

    consume(data)
----
<1> Como acaba de quitar un elemento incrementa el semáforo para que un productor pueda añadir otro elemento.

[NOTE]
.Semáforos partidos
====
La técnica de la sincronización con los dos semáforos se denomina _semáforos partidos_ (_split semaphores_). Se llama así cuando se usan dos o más semáforos cuya suma es una constante. En este caso el invariante es:

_notEmpty + notFull = BUFFER_SIZE_
====

==== Lectores-Escritores

=== Filósofos cenando

==== Deadlocks

=== Inversión de prioridades

=== Optimizaciones

==== Spinlocks más semáforos

==== FUTEXes

////
https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ArrayBlockingQueue.html
http://docs.oracle.com/javase/7/docs/technotes/guides/collections/overview.html
http://docs.oracle.com/cd/E19683-01/806-6867/sync-27385/index.html

https://cs.nyu.edu/~yap/classes/os/resources/EWD74.pdf
http://docs.oracle.com/cd/E19683-01/806-6867/sync-27385/index.html
http://www.cs.utexas.edu/users/EWD/transcriptions/EWD00xx/EWD74.html

<<railroad>>
_It is Texas law that when two trains meet each other at a railroad crossing, each shall come to a full stop, and neither shall proceed until the other has gone._


////
