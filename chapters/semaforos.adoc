== Semáforos

El concepto de semáforos lo inventó Edsger W. Dijkstra a finales de los años 60 (<<Dijkstra74>>), aunque las primers ideas son de principios de la misma década (<<Dijkstra35>>). La idea y nombre está inspirado de las señales visuales ferroviarias que indican si un tren está habilitado para entrar en una vía. Es una construcción sencilla, eficiente y muy utilizada que permite solucionar problemas genéricos de sincronización entre procesos.


Las soluciones a exclusión mutua y otros mecanismos de sincronización vistos hasta ahora no requieren la colaboración del sistema operativo, funcionan directamente sobre el _hardware desnudo_. En cambio los semáforos se implementan habitualmente como servicios de los sistemas operativos. Estos tienen la característica _intrínseca_ de bloquear y planificar para ejecución de los procesos e hilos. Bloquear a un proceso hasta que pueda continuar su ejecución no necesita de funcionalidades adicionales sofisticadas, los sistemas operativos hacen lo mismo para todas las operaciones de entrada-salida. En el caso de semáforos los procesos se bloquean o ejecutan condicionados únicamente por el valor que tiene una variable entera. Una abstracción tan simple como potente.


=== Definición
Un semáforo es una construcción definida por una variable entera, el _valor_ del semáforo, que puede tomar valores no negativos y una cola de procesos _bloqueados_ en el semáforo. La estructura es similar a la siguiente:

----
struct Semaphore {
    unsigned value;
    Queue q;
}
----

Un semáforo puede ser inicializado con un valor no negativo, por ejemplo la siguiente indica que el valor del semáforo (la variable _value_) será inicializada con `1`:

----
Semaphore s = 1
----

Sobre la estructura de datos anteriores se definen dos primitivas fundamentalesfootnote:[La mayoría de lenguajes y librerías de concurrencia ofrecen funciones adicionales.]: _P_ y _V_.

Pfootnote:[De la contracción _Prolaag_ del holandés _proberen te verlagen_ que significa _intentar decrementar_.]:: Si el contador es mayor que cero lo decrementa, caso contrario bloquea al proceso que la llamó. Actualmente es más conocida como *_wait_* o *_acquire_*

Vfootnote:[Del holandés _Verhoog_ o _verhogen_ que significa _incrementar_.]:: Si hay un algún proceso bloqueado en el semáforo lo desbloquea para que pueda continuar su ejecución, caso contrario incrementa el valor. Esta operación es más conocida como *_signal_*, *_release_* o *_post_*.

El algoritmo de ambas:

._wait_
----
def wait(s):
    if s.value > 0:
        s.value -= 1          <1>
    else:
        add(process, s.queue) <2>
        block(process)        <2>
----
<1> Solo se decrementa el valor del semáforo si es mayor que cero.
<2> Si es cero se bloquea al proceso que llamó a _wait_.


._signal_
----
def signal(s):
    if empty(s.queue):
        s.value += 1           <1>
    else:
        process = get(s.queue) <2>
        sched(process)         <2>
----
<1> Si no hay procesos bloqueados en la cola del semáforo (i.e. ésta está vacía) se incrementa su valor.
<2> Caso contrario se desbloquea a un proceso.


==== Exclusión mutua
El algoritmo de exclusión mutua es muy sencillo:


----
        Semaphore s = 1

...
wait(s)
critical_section()
signal(s)
...
----

Se inicializa el semáforo a `1`, cuando el primer proceso quiera entrar a la sección crítica decrementará su valor y continuará. Si otro proceso desea entrar el valor será cero por lo que se bloqueará hasta que el siguiente proceso ejecute el _signal_ y lo desbloquee. La solución del contador en <<sem_counter_c, C con semáforos POSIX>>, <<sem_counter_py, Python>> y <<sem_counter_java, Java>> usando semáforos.

Como ya puede intuirse, el valor del semáforo es un indicador del _número de recursos_ disponibles, en algunos lenguajes al valor del semáforo le denominan _permisos_ (_permits_). En el caso de exclusión mutua interesa que sólo haya un proceso en la sección crítica por ello el valor inicial es `1`. Pero se pueden programar casos más complejos de sincronización simplemente modificando el valor inicial del semáforo. Supongamos que tenemos un systema con _N_ procesadores y para evitar cambios de contextos innecesarios queremos que hay hasta _N_ procesos ejecutando una parte del código. En ese caso sólo hay que inicializar el valor del semáforo con _N_. Este tipo de uso de semáforos donde se permiten más de uno y hasta _N_ procesos en la sección crítica se denominan _multiplexes_.

==== Semáforos binarios
La definición anterior de semáforos permite valores cero y positivos, son denominados _semáforos generales_. Si el semáforo permite sólo valores de `0` y `1` se denominan _semáforos binarios_. Los semáforos binarios son equivalentes en el sentido que permiten resolver los mismos problemas, aunque con algunas líneas más de código, por ejemplo el algoritmo de Barz (<<Barz>>). Este algoritmo  emula semáforos contadores que usa un par de semáforos binarios (`mutex` y `gate`) y una variable entera (`value`).

Las funciones `generalWait` y `generalSignal` son las emulaciones genéricas de _wait_ y _signal_ respectivamente,  _k_ es el valor inicial del semáforo. El uso del semáforo `mutex` es obvio, asegura exclusión mutua en las secciones críticas de la implementación, allí donde se modifica y verifica el valor de la variable compartida `value`. El semáforo `gate` se usa para controlar qué procesos deben bloquearse o desbloquearse según el valor que tome `value`.

.Algoritmo de Barz
----
        BinarySemaphore mutex = 1
        BinarySemaphore gate = 1
        value = k

def generalWait():
    wait(gate)       <1>
    wait(mutex)
    value -= 1
    if value > 0:
        signal(gate) <2>
    signal(mutex)

def generalSignal():
    wait(mutex)
    value += 1
    if value == 1:
        signal(gate) <3>
    signal(mutex)
----
<1> Si no es el primer proceso en entrar a la sección crítica debe esperar a ser _autorizado_ por el proceso anterior.
<2> Si después de decrementar el valor es todavía mayor que cero permite que entre otro proceso.
<3> Si después de incrementarlo el valor es igual a uno significa que antes estaba en cero por lo que habilita para que pueda entrar otro proceso.


==== Semáforos _mutex_
Los _semáforos mutex_, también llamados _locks_ en algunos lenguajes (como Java o Python), son semáforos binarios optimizados para ser usados con exclusión mutuafootnote:[De allí el nombre _mutex_ de _mutual exclusion_, el mismo nombre que usé en los _spinlocks_ cuando se trataba de asegurar exclusión mutua.] con restricciones adicionales:

. Son inicializados a `1`.
. Se añade el concepto de propiedad, solo el proceso que hizo el _wait_ puede hacer luego el _signal_. En algunos lenguajes se permite que el mismo hilo haga varios _wait_, si ya es el propietario del _lock_ continúa su ejecución, estos últimos se denominan _reentrantes_.

Los _mutex_ son muy comunes y son recomendados para exclusión mutua, hay lenguajes como Go que no tienen funciones _nativas_ de semáforos generales, sólo mutex. De forma similar a cómo se hace con _spilonks_ en estos semáforos a la operación _wait_ se la suele llamar *_lock_* y a _signal_ *_unlock_*. El algoritmo genérico es similar a los semáforos,


----
        Mutex mutex

...
lock(mutex)
critical_section()
unlock(mutex)
...
----

En C se pueden usar los semáforos _mutex_ de librerías de POSIX Threads, las primitivas son `pthread_mutex_lock` y `pthread_mutex_unlock` (<<sem_mutex_c, programa en C>>). Go lo ofrece en el módulo `sync`, las primitivas son `Lock` y `Unlock` (<<go_mutex_go, código>>).

En <<sem_lock_java, Java se puede usar>> la clase `ReentrantLock` de java.util.concurrent.locks. Python tiene clases similares, `threading.Lock()` y `threading.RLock()` footnote:[También incluye primitivas similares en el nuevo paquete `asyncio`.], además de las llamadas tradicionales a <<sem_lock_py, `acquire` y `release`>> se puede usar <<sem_lock_with_py, con la cláusula `with`>>:

[source, python]
----
for i in range(MAX_COUNT/THREADS):
    with mutex:
        counter += 1
----


==== Semáforos fuertes y débiles
Cada semáforo tiene asociado una cola con la información de los procesos bloqueados, el sistema de gestión de esta cola es fundamental. Si la cola es una FIFO entonces asegura que los procesos entran en orden a la sección crítica, es decir, aseguran _espera limitada_ y estos semáforos se denominan _semáforos fuertes_. Por el contrario, si los procesos a desbloquear se seleccionan aleatoriamente se denominan _semáforos débiles_ (_weak semaphores_).


.Semáforos en Unix y Linux
****

Semáforos System V:: Estos semáforos, parte del módulo IPC (_Inter Porcess Comunnication_) del UNIX System V fue el estándar de facto durante muchos años y siguen disponibles en las útimas versiones de Linux y Solaris. Desde la definición del estándar POSIX Semaphores de 2001 ha caído mucho en desuso ya que tiene una interfaz (API) poco elegante, ineficiente e innecesariamente compleja para los usos más habituales. En este estándar los semáforos se obtienen con `semget()` que retorna un array de semáforos (que puede ser de tamaño uno), se inicializan destruyen con `semctl()` y las operaciones de _wait_ y _signal_ se hacen con `semop()`. Ambas pueden incrementar o decrementar el valor de cada semáforo del array con valores a discreción, no sólo `1` o `-1` y hay que especificar siempre un array de valores y el índice del semáforo al que se aplica. Esta es la complejidad innecesaria para realizar operaciones simples, pero tiene características interesantes:
- Operaciones sobre varios semáforos del array son atómicas, facilita la programación de algoritmos complejos que lo requieran.
- La primitiva adicional esperar por cero o _wait_for_0_. Como se intuye por su nombre bloquea a los procesos si el valor del semáforo es diferente a cero, los desbloquea cuando se hace cero.
- Deshacer la última operación, `SEM_UNDO`, si el proceso acaba. Es útil como medida de protección, si un proceso está en la sección crítica y el proceso acaba por error el sistema revierte la última operación y los demás procesos pueden continuar.

Semáforos POSIX:: Están implementados en Linux desde la versión 2.6, lo usamos en el <<sem_counter_c, primer ejemplo de semáforos en C>>. Es el estándar actual y más usado, aunque carece de la flexibilidad y operaciones adicionales de los System V tiene una interfaz más sencilla y la implementación es más eficiente. Se pueden crear dos tipos, _sin nombre_ (_unnamed_) y _con nombre_ (_named_). El primero es más sencillo de usar cuando los procesos comparten la memoria, como es el caso de los _threads_ creados desde un único proceso, sólo hay que declarar una variable del tipo `sem_t` y luego inicializar el valor del semáforo con `sem_init()`. Cuando se necesitan en procesos que no comparten memoria se los puede crear y/o abrir con la función `sem_open()` usando un nombre similar a ficheros y luego inicialiarlos y usarolos igual que los semáforos _sin nombre_.

Mutex de POSIX Threads:: Las usamos en el <<sem_mutex_c, ejemplo anterior>> de semáforos _mutex_. No hay que confundirlos con los semáforos POSIX, en este caso se trata de las librerías POSIX para la implementación de hilos que incluyen mecanismos básicos de sincronización entre ellos: _mutex_ y variables de condiciónfootnote:[Las veremos en el capítulo <<monitors>>.].

****



=== Sincronización de orden de ejecución

La sección crítica es una abstracción conveniente y sencilla para resolver el problema de sincronización de varios procesos compitiendo por recursos compartidos. Otro problema común es la coordinación del orden de ejecución de operaciones de diferentes procesos (<<Ben-Ari>>). Supongamos dos procesos _P_ y _Q_, la instrucción _Q~j~_ debe ejecutarse solo después de la instrucción _P~i~_, se denota por como _P~i~ < Q~j~_. Para asegurar que se cumpla esta condición hay que asegurar antes de _Q~j~_:

- Continuar la ejecucion si _P~i~_ ya se ejecutó.
- Bloquear a _Q_ si _P~i~_ todavia no se ejecutó y desbloquearlo una vez que se haya ejecutado _P~i~_.

Para ello se necesita un semáforo (contador o binario) inicializado a cero. Inmediatamente después de _P~i~_ se llama _signal_ sobre dicho semáforo. En el proceso _Q_ se llama a _wait_ inmediatamente antes de _Q~i~_. Los programas serán similares al siguiente ejemplo:

----
        Semaphore sync = 0

P               Q

...             ...
Pi              wait(sync)
signal(sync)    Qj
...             ...
----


=== Productores-Consumidores

El problema de los productores-consumidores es muy común y es un ejemplo de sincronización de orden de ejecución. Hay dos tipos de procesos incolucrados:

Productores:: Produce un nuevo elemento que será transmitido al o los consumidores.
Consumidores:: Recibe y consume los elementos transmitidos desde los productores.

Los productores-consumidores son muy habituales en todos los sistemas informáticos, las tuberías entre procesosfootnote:[Como cuando se usa `|` entre dos comandos en el shell.], la E/S a dispositivos, la comunicaciones por red, etc. Hay dos tipos fundamentales de productores-consumidores:

Sincrónicos:: Cuando se produce un elemento debe se consumido inmediatamente antes de que el productor pueda agregar un nuevo elemento.

Asincrónicos:: El canal de comunicación tiene capacidad de almacenamiento, un _buffer_, por lo que no es necesario que los productores esperen a que cada elemento sea consumido, estos agregan los elementos a una cola y los consumidores obtienen el primer el primer elemento de ésta.

El segundo caso es el más habitualfootnote:[El sincrónico es similar al asincrónico con tamaño de _buffer_ uno.]. El uso de un _buffer_ permite que productores y consumidores avancen a su propio ritmo pero hay que sincronizarlos para hacer que los consumidores esperen si el _buffer_ está vacío y los productores si el _buffer_ está lleno. El algoritmo genérico para productores y consumidores es el siguiente:

.Productor
----
while True:
    data = produce()
    buffer.add(data)
----

.Consumidor
----
while True:
    data = buffer.get()
    consume(data)
----



[NOTE]
====
Debido a que el modelo productor-consumidor es muy común la mayoría de lenguajes ofrecen una implementación nativa o por librerías. Por ejemplo la clase `ArrayBlockingQueue` en Java, `Queue` en Python (`queue` partir de Python 3) y Ruby, los mensajes nativos de Go son productores-consumidores que pueden ser sincrónicos o asincrónicos (los estudiaremos en el capítulo <<messages>>).

En las siguientes secciones estudiaremos lo relevante: cómo se implementan los algoritmos usando solo semáforos, no como usar los ya implementados de cada lenguaje.
====

==== _Buffer_ infinito
Aunque no existe la memoria infinita y no es recomendable confiar en que la velocidad relativas de los productores es tal que el _buffer_ nunca crecerá más de tamaños razonablesfootnote:[Aunque si lo hará en el ejemplo], es una buen primer paso para la implementación del algoritmo más general.

No debemos preocuparnos de que el _buffer_ se llene, sólo de bloquear a los consumidores si el buffer está vacío, y desbloquearlos cuando hay nuevos elementos disponibles. Además del buffer compartido necesitaremos dos semáforos: `mutex` para asegurar exclusión mutua mientras se añaden o quitan elementos a la cola y otro semáforo contador de sincronización, `notEmpty`, para bloquear a los consumidores si el _buffer_ está vacío.



----
    Queue buffer
    Semaphore mutex = 1
    Semaphore notEmpty = 0
----


Los siguientes son los algoritmos (en notación de objetos) para los productores y consumidores respectivamente:

.Productor
----
while True:
    data = produce()

    mutex.wait()
    buffer.add(data)  <1>
    mutex.signal()

    notEmpty.signal() <2>
----
<1> Agrega un elemento dentro de una sección crítica.
<2> Señaliza el semáforo, su valor será el número de elementos en el _buffer_.


.Consumidor
----
while True:
    notEmpty.wait()     <1>

    mutex.wait()
    data = buffer.get() <2>
    mutex.signal()

    consume(data)
----
<1> Se bloquea si el _buffer_ está vacío, si no es así decrementa y obtiene el siguiente elemento. Notad que el valor del semáforo contador `notEmtpy` siempre se corresponde con el número de elementos disponibles en el _buffer_.
<2> Obtiene el elemento de la cola.

En el <<producer_consumer_infinite_py, código en Python>> podéis ver la implementación completa. hay dos clases, `Producer` y `Consumer` que implementa el algoritmo de productores y consumidores respectivamente. Se crean dos productores (variable `PRODUCERS`) y dos consumidores (`CONSUMERS`), los productores producen 1000 elementos (`TO_PRODUCE`) cada uno y acaban. Para el buffer se usa una lista nativa de Python, se agregan elementos con `append()` y se obtiene el primer elemento con `pop(0)`.

==== _Buffer_ finito
El algoritmo anterior puede ser fácilmente modificado para que funcione con un tamaño de _buffer_ limitado. Así como los consumidores se bloquean si no hay elementos en el _buffer_ debería también hacer lo mismo con los producrtores si no quedan _posiciones libres_. Necesitamos otro semáforo contador (`notFull`) cuyo valor indicará el número de posiciones libre y que se inicializará con el tamaño del _buffer_ (`BUFFER_SIZE`).


----
    Queue buffer
    Semaphore mutex = 1
    Semaphore notEmpty = 0
    Semaphore notFull = BUFFER_SIZE
----

Los siguientes son los algoritmos para cada proceso, solo se añade una línea a cada uno (el <<producer_consumer_py, código en Python>>):

.Productor
----
while True:
    data = produce()

    notFull.wait()    <1>

    mutex.wait()
    buffer.add(data)
    mutex.signal()

    notEmpty.signal()
----
<1> Se bloqueará si `notFull` vale cero, caso contrario lo decrementará y añadirá un nuevo valor.

.Consumidor
----
while True:
    notEmpty.wait()

    mutex.wait()
    data = buffer.get()
    mutex.signal()

    notFull.signal()    <1>

    consume(data)
----
<1> Como acaba de quitar un elemento incrementa el semáforo para que un productor pueda añadir otro elemento.


===== Semáforos partidos
La técnica de la sincronización con los dos semáforos se denomina _semáforos partidos_ (_split semaphores_, <<Ben-Ari>>). Se llama así cuando se usan dos o más semáforos cuya suma es una constante. En este caso el invariante es:

_notEmpty + notFull = BUFFER_SIZE_

Si la constante es uno la técnica se denomina _semáforos partidos binarios_.

Para resolver el problema de la sección crítica el par de operaciones _wait_ y _signal_ son ejecutadas por el mismo proceso y en ese orden. Para el algoritmo con _buffer_ limitado se usan dos semáforos y las llamadas a _wait_ y _signal_ se hacen desde diferentes hilos. Los _semáforos partidos_ permiten que los procesos esperen por eventos que se producen en otros.




=== El problema de los filósofos cenando

Es un problema típico y muy estudiado en el área de la programación concurrente, fue inventado por Dijkstra en 1965 y luego formalizado por Hoare (<<Hoare>>). No es un problema realista pero es lo suficientemente simple pero al mismo tiempo propone desafíos interesantes por lo que es objeto habitual de estudio y discusión.

Se trata de cinco filósofos sentados en una mesa, sobre esta también hay cinco tenedoresfootnote:[Algunos textos dicen que son palillos, por ello se suele decir que los filósofos son chinos pero es contradictorio con la imagen.], uno a cada lado de los filósofos.

[[dining_image]]
.Filósofos cenandofootnote:["Dining philosophers" by Benjamin D. Esham / Wikimedia Commons. Licensed under CC BY-SA 3.0 via Wikimedia Commons - https://commons.wikimedia.org/wiki/File:Dining_philosophers.png#/media/File:Dining_philosophers.png]
image::dining_philosophers.jpg[height="250", align="center"]


Cada filósofo realiza solo dos actividades: pensar o comer. Si cada filósofo es un proceso, al algoritmo general de cada uno de ellos es:

----
def philosopher():
    while True:
        think()
        preprotocol()  <1>
        eat()
        postprotocol() <2>
----
<1> Asegurar que puede coger los dos tenedores, el de la izquierda y el de la derecha
<2> Liberar ambos tenedores.

Para comer necesita dos tenedores, solo puede coger los que tiene a su lado. Para que el programa sea correcto se deben verificar las siguientes propiedades:

[[philosophers_requisites]]
1. Un filósofo solo puede comer si tiene los dos tenedores.
2. Exclusión mutua, un tenedor solo puede ser usado por un filósofo a la vez.
3. Se debe asegurar _progreso_, es decir, que no se producen interbloqueos (_deadlocks_).
4. Se debe asegurar _espera limitada_ (es decir no debe haber espera infinita o _starvation_).
5. Debe ser eficiente, si no hay competencia por un tenedor éste debe poder ser usado por uno de sus dos filósofos vecinos.

Identificamos a los filósofos y tenedores con un índice de `0` a `4` (es decir, de `0` a _N-1_), el tenedor a la izquierda del _filósofo~0~_ será el _tenedor~0~_ y el de su derecha el _tenedor~1~_, así sucesivamente hasta el último _filósofo~4~_ que a su izquierda tendrá el _tenedor~4~_ y a su derecha el _tenedor~0~_.

Un primera solución es asegurar exclusión mutua a toda la mesa, solo un filósofo puede comer a la vez. Para ello sólo necesitamos un semáforo _mutex_ para sincronizar toda la mesa:

----
    Semaphore table = 1

def philosopher():
    while True:
        think()
        table.wait()
        eat()
        table.signal()

----

El problema con esta solución es que es muy ineficiente, aunque hay tenedores para que pueda comer dos filósofos simultáneamente solo uno podrá comer. Una mejor solución es asegurar exclusión mutua por cada tenedor, para ello necesitamos un array de cinco semáforos mutex, uno para cada tenedor. El índice _i_ identifica a cada filósofo, cada intentará intentará coger primero el tenedor de su izquierda (también es _i_) y el de su derecha (corresponde a `(i + 1) % 5`).

Definimos las funciones `pickForks()` y `releaseForks()` que tomarán y soltarán los tenedores respectivamente y por conveniencia la función `right()` que retorna el índice del tenedor de la derecha (recordad que el de la izquierda es simplemente _i_):

----
    Semaphore forks[5] = [1, 1, 1, 1, 1]

def philosopher(i):
    while True:
        think()
        pickForks(i)
        eat()
        releaseForks(i)

def right(i):
    return (i+1) % 5

def pickForks(i):
    forks[i].wait()
    forks[right(i)].wait()

def releaseForks(i):
    forks[i].signal()
    forks[right(i)].signal()

----

Antes de comer cada filósofo hará un _wait_ sobre los dos tenedores que le corresponde, primero al de la izquierda y luego al de la derecha. Si alguno de ellos está ocupado por otro quedará bloqueado hasta que el filósofo que lo tiene haga el _signal_ al semáforo correspondiente. Pero tiene un problema importantefootnote:[Lo podéis probar físicamente con la ayuda de otra persona -no hacen falta cinco- una mesa y tenedores.]: si todos intentan comer _simultáneamente_ cada uno cogerá su tenedor de la izquierda, cuando lo intenten con el de la derecha quedarán bloqueados porque ya habrá sido tomado por su vecino.

Una secuencia de instrucciones que lleva a este estado pueder ser la siguiente.

Cada filósofo toma el tenedor de su izquierda, la ejecución se intercala o se ejecuta en paralelo (recordad que el problema es equivalente):

----
fork[0].wait()
  fork[1].wait()
    fork[2].wait()
      fork[3].wait()
        fork[4].wait()
----

Ahora cada uno de ellos intenta con el tenedor de su derecha:
----
fork[1].wait()
  fork[2].wait()
    fork[3].wait()
      fork[4].wait()
        fork[0].wait() <1>
----
<1> El _filósofo~4~_ es el único que hace el _wait_ en orden decreciente.

Todos quedarán bloqueados porque los semáforos _mutex_ estan todos en cero, es un _interbloqueo_, como <<first_deadlock, vimos>> en el capítulo <<algorithms>>.


==== Interbloqueo

Los interbloqueos se pueden producir cuando hay competencias por recursos de cualquier tipo. Dos procesos `P` y `Q` necesitan los recursos `a` y `b` y los solicitan en orden diferente como en el siguiente ejemplo:

----
P               Q

get(a)          get(b)
...             ...
get(b)          get(a)
----


Ambos procesos quedarán esperando que el otro libere uno de los recursos pero el otro no lo hará porque tampoco puede avanzar ya que está esperando otro recurso. Por eso se dice que _no hay progreso_, se produce un bucle en el _grafo de asignación de recursos_. Es lo mismo que está pasando con la solución anterior de los filósofos, se dice que hay una _espera circular_.

.Condiciones necesarias para interbloqueo
****
Si no se presentan una o varias de las condiciones siguientes no se puede producir interbloqueo.

1. *Exclusión mutua*: Los recursos solo pueden asignarse a un proceso.

2. *Retención y espera*: Un proceso mantiene los recursos ya asignados mientras espera la asignación de otro.

3. *No apropiación*: No se puede quitar un recurso que está asignado a un proceso, debe ser éste el que lo libere.

4. *Espera circular*: Se produce un bucle, un ciclo cerrado de procesos esperando por recursos asignados a otros. Esta condición es derivada de la segunda, sin _retención y espera_ no se puede producir una _espera circular_ (pero la retención y espera no implica que sí se produce).

****

Si queremos evitar los _deadlocks_ en la solución de los filósofos el algoritmo debe evitar que se presente algunas de las condiciones necesarias. La exclusión mutua no se puede evitar, un tenedor solo puede tenerlo un filósofo. La retención y espera se podría evitar pero requiere algoritmos de sincronización más complejos que el de exclusión mutua. Se podría hacer que sea apropiativo si se detecta el interbloqueo y se quita el tener a uno de los filósofos incolucrados en la cadena, también requiere un algoritmo más sofisticado.

La condición de espera circular es la más sencilla de evitar que se produzca, basta forzar a que todos los procesos soliciten los recursos en el mismo orden, ascendente o descendente. El _culpable_ de que no se soliciten los tenedores en el mismo orden es el filósofo con el último índice. El contrario que los demás que solicitan los tenedores en orden ascendente, el _filósofo~4~_ los solicita en orden descendente, primero el _tenedor~4~_ y luego el _tenedor~0~_.

Para forzar el mismo orden para todos basta cambiar la función `pickForks()` para que siempre haga el primer _wait_ sobre el menor índice y luego sobre el mayor (<<philosophers_1_py, código en Python>>):

----
def pickForks(i):
    if i < right(i):
        forks[i].wait()
        forks[right(i)].wait()
    else:
        forks[right(i)].wait()
        forks[i].wait()
----

Con este algoritmo ya no se producen interbloqueos al no haber esperas circulares. Sin embargo no es el algoritmo óptimo, hay situaciones donde podrían estar comiendo dos filósofos pero solo lo hace uno. Si como en el caso anterior todos los filósofos desean comer más o menos simultáneamente puede darse la siguiente secuencia:

----
fork[0].wait()
  fork[1].wait()
    fork[2].wait()
      fork[3].wait()
        fork[0].wait() <1>

fork[1].wait()
  fork[2].wait()
    fork[3].wait()
      fork[4].wait()   <2>

----
<1> El _filósofo~4~_ que ahora hace el _wait_ en orden y se bloquea.
<2> El _filósofo~3~_, el _tenedor~4~_ está libre y puede continuar comiendo, todos los demás esperarán, cuando _filósofo~3~_ podrá comer el _filósofo~2~_, luego _filósofo~1~_, etc.



==== Solución óptima

Para obtener la solución óptima hay que cambiar el enfoque, el vez de un problema de exclusión mutua tratarlo como una sincronización del orden de instrucciones. Cuando una filósofo desea comer verifica el estado de sus dos vecinos, si ninguno de los dos está comiendo podrá continuar. Caso contrario tendrá que esperar que los vecinos le _avisen_ cuando han dejado de comer.

Usaremos el array `status` para indicar el estado de cada filósofo: pensando (`THINKING`), que desea empezar a comer (con _hambre_, `HUNGRY`) y comiendo (`EATING`). El array `sync` de semáforos para sincronizar entre los filósofos y el semáforo `mutex` para asegurar exclusión mutua cuando se verifica y manipula el array `status`.

----
    Semaphore status[5] = [THINKING,... ,THINKING]
    Semaphore sync[5] = [0, 0, 0, 0, 0]
    Semaphore mutex = 1
----

La función `pickForks()` asigna `HUNGRY` al estado del filósofo y llama a la función `checkNeighbors()` que verifica si ninguno de los vecinos está comiendo. Si no es así señaliza en su semáforo `sync` correspondiente por lo que no se bloqueará en `acquire()` del final. Si alguno de los vecinos está comiendo el filósofo se quedará bloqueado en su semáforo.

----
def pickForks(i):
    mutex.acquire()
    status[i] = HUNGRY
    checkNeighbors(i)
    mutex.release()
    sync[i].acquire()
----

Si ninguno de los vecinos está comiendo `checkNeighbors()` asigna `EATING` al estado de _filósofo~i~_ y señaliza en su semáforo. A diferencia del algoritmo anterior, las funciones `left()` y `right()` retornan el índide del filósofo vecino (no del tenedor), _right_ sigue siendo como antes, `(i + 1) % 5`, pero _left_ indica el vecino con un índice menor: `(i - 1) % 5` (el vecino de la izquierda de _filósofo~0~_ es el _filósofo~4~_).

----
def checkNeighbors(i):
    if status[i] == HUNGRY
            and status[left(i)] != EATING
            and status[right(i)] != EATING:
        status[i] = EATING
        sync[i].release()
----

Cuando un filósofo deja de comer debe verificar si sus vecinos desean comer y estaban esperando por sus tenedores. Para poder indicarles que pueden comer también hay que verificar si sus otros vecinos no están comiendo. Para ello se puede usar la función `checkNeighbors()` que precisamente hace eso, lo que cambiará es el `i` como argumento.

----
def releaseForks(i):
    mutex.acquire()
    status[i] = THINKING
    checkNeighbors(left(i))  <1>
    checkNeighbors(right(i)) <1>
    mutex.release()
----
<1> Se reusa la función `checkNeighbors()` para verificar el estado de los _vecinos del vecino_. Si el filósofo que deja los tenedores es el `1` entonces se llamará con el argumento `0` (el filósofo de la izquierda) y luego con el `2` (el filósofo de la derecha).

Hay que tener en cuenta que las llamadas a `checkNeighbors()` se hacen siempre desde dentro de la sección crítica del semáforo `mutex` por lo que no se producen condiciones de carrera ni conflictos en las verificaciones y cambios de estado del array `status`.

Este algoritmo es el óptimo (<<philosophers_2_py, código fuente completo>>), asegura que si hay tenedores para que coman dos filósofos estos podrán hacerlo sin demora. Se debe entre otras cosas a que no existe _retención y espera_, los filósofos que no pueden comer no retienen el tenedor libre. Sin _retención y espera_ tampoco se puede producir la _espera circular_, dado que no se cumplen ninguna de estas dos condiciones necesarias tampoco pueden producirse _interbloqueos_. Cumple con todas las propiedades que <<philosophers_requisites, mencionamos al principio>>.


=== Lectores-Escritores


=== FUTEX

Los semáforos son habitualmente implementados en los sistemas operativos, estos tienen mayor facilidad y capacidad para cambiar el estado de los procesos. Pero las llamadas de sistema toman un tiempo considerable debido a la interrupción de software y el cambio de contexto a la ejecución del núcleo. Se puede mejorar mucho el rendimiento si se reducen las llamadas de sistema solo a los casos donde hay competencia, si un proceso es el único que desea entrar a la sección crítica puede resolverse sin necesidad de llamar a la sección crítica. Se puede resolver con la ayuda de cualquiera de las instrucciones vistas en el capítulo de <<hardware>>.

Supongamos que tenemos la variable entera `mutex` compartida y la instrucción CAS (_compare&Swap_) el algoritmo para el _wait_ verificará si se pudo hacer el cambio, en este caso no hay competencia y podrá continuar. Caso contrario llamará al sistema operativo que un semáforo asociado al valor de mutex bloqueará al proceso. Algo similar al siguiente algoritmo:

----
local = 1
CAS(mutex, local, 0)
if local != 0:
    syscall_wait(mutex)
----

En caso de no haber competencia el proceso podrá entrar a la sección crítica sin ninguna llamada de sistema. Obviamente el algoritmo no puede ser _tan_ sencillo, pero es la idea básica (tampoco es tan complicado).

Esta es la idea de la interfaz FUTEXfootnote:[man 7 futex] (_Fast user-space mutexes_) de Linux. Al contrario de los que dice sun nombre FUTEX no solo sirve para semáforos _mutex_, también para una variedad de mecanismos de sincronización, desde _mutex_ a variables de condición.

FUTEX no está diseñado para ser usada directamente por desarrolladores de aplicaciones sino por de librerías, por ejemplo las _Native POSIX Thread Libraries_ (_NPTL_, las librerías estándares de Posix Threads de Linux y que usamos en todos los ejemplos) o las de semáforos POSIX. No tiene definida siquiera una función, hay que recurrir a `syscall()` y exige conocimientos de las instrucciones atómicas de hardware. Como ya hemos visto cómo usar macros del compilador que generan las operaciones atómicas necesarias, cómo usarlas en diferentes algoritmos y cómo funcionan los semáforos podemos aventurarnos sin demasiado esfuerzo en desarrollar un semáforo _mutex_ con la interfaz FUTEX.

El núcleo de la interfaz (<<Franke>>, <<Hart>>, <<Drepper>>, <<LockLess1>>) es una variable entera, el núcleo del sistema operativo usa al dirección física de la variable (a partir de ahora un _futex_) para generar una tabla de _hashing_ para mantener colas de procesos bloqueados para cada _futex_. Para que varios procesos compartan los mecanismos de sincronización basta con que los procesos puedan compartir variables en memoria. Como hemos visto en todos los ejemplos con _threads_ es muy sencillo, basta una variable global, en casos de procesos independientes se puede usar cualquier mecanismo de compartición de memoria. Como se usa la dirección física no se producen conflictos con que cada uno use diferentes direcciones virtuales.

Actualmente hay treces operaciones definidas en `/usr/include/linux/futex.h`, las más importantes son: `FUTEX_WAIT`, `FUTEX_WAKE`, `FUTEX_FD`, `FUTEX_CMP_REQUEUE` y `FUTEX_WAKE_OP` (las otras implementan herencia de prioridades o permiten especificar máscaras para implementar algoritmos como el de lectores-escritores).

==== _Mutex_ simple

Para el _mutex_ simple mostrado a continuaciónfootnote:[Lo desarrollé para este libro buscando que sea muy sencillo de explicar, no encontré publicado un algoritmo similar.] se requieren solo dos operaciones:

`FUTEX_WAIT`:: Si el valor del _futex_ es igual al valor del segundo argumento suspende al proceso y lo agrega a la cola de bloqueados en ese _futex_. Retorna `0` si fue desbloqueado por el FUTEX_WAKE, `-1` si no pudo bloquear o hubo error.

`FUTEX_WAKE`:: Desbloquea a uno o más procesos, según lo indicado en un segundo argumento, en la cola del _futex_. El número de procesos a despertar se indica en un argumento, retorna el número de procesos que se desbloquearon.

En el <<futex_simple_mutex_c, código completo en C>> se usa `syscall()` pero simplifico el pseudocódigo con `futex_wait(futex, value)` (`value` es el valor a comparar)  y `futex_wake(futex, value)` respectivamente (en este case `value` es el número de procesos a desbloquear). Las operaciones atómicas que usaremos serán `swap` (retorna el valor previo) y `fetch_and_add`. Las funciones `lock()` y `unlock()` reciben como argumento la dirección de una estructura con dos enteros (en C):

----
struct simple_futex {
    int locked;
    int waiters;
};
----

El campo `locked` será usado como variable binaria, si vale `0` no hay procesos en la sección crítica, `waiters` indicará el número de procesos que están bloqueados en la cola del _futex_ (es decir, que ejecutaron `futex_wait()`).


===== _lock_

Si el resultado del _swap_ del campo `locked` es cero significa que no hay ningún proceso en la sección crítica y podrá entrar directamente sin ninguna llamada de sistema. Caso contrario se agregará a la cola, antes de hacerlo incrementa el contador de procesos en espera, en la `futex_wait` se indica que compare que el valor de `locked` siga siendo `1`. Si no es así el proceso que estaba en en la sección crítica ya salió por lo que debe volver a verificar si puede entrar desde el principio. Antes de volver tiene que decrementar `waiters`.

Si el proceso fue bloqueado en el `futex_wait` cuando se despierte decrementará `waiters` y volverá al principio del bucle para verificar si esta vez puede entrar.

----
def lock(futex):

    while True:
        local = swap(futex.locked, 1)
        if local == 0:                   <1>
            return

        fetch_and_add(futex.waiters, 1)
        futex_wait(futex.locked, 1)      <2>
        fetch_and_add(futex.waiters, -1)
----
<1> Si `locked` valía cero ahora vale `1` por lo que el proceso puede entrar a la sección crítica directamente.
<2> Para que se agregue a la cola de bloqueados se verifica que `locked` siga en `1`.

===== _unlock_
Esta función es muy sencilla, indica que salió de la sección crítica poniendo `0` en `locked` y si hay procesos en espera despierta a uno de ellos.

----
def unlock(futex):
    futex.locked = 0
    if futex.waiters > 0:
        futex_wake(futex.locked, 1)
----


Este algoritmo es muy sencillo pero tiene un problema importante, aunque las colas del sistema operativo son FIFO esta implementación no es _equitativa_, no asegura espera limitada. Si el proceso que sale de la sección crítica inmeditamente vuelve a llamar al `lock` podrá entrar antes que el proceso que se despertó con el `futex_wake`. Como dicho proceso estaba bloqueado y el sistema operativo tiene que hacer el cambio de contexto la probabilidad de que el que acaba de salir ejecute antes el _swap_ es muy elevada.

===== _Mutex_ equitativo

Lo idea obvia es implementar un algoritmo equitativo similar al <<ticket_lock, _ticket-lock_>>. El algoritmo es el siguiente ()<<futex_fair_simple_mutex_c, código en C>>):

----
def lock(futex):
    number = fetch_and_add(futex.number, 1)
    turn = futex.turn

    while number != turn:
        futex_wait(futex.turn, turn)
        turn = futex.turn
----

----
def unlock(futex):
    current = fetch_and_add(futex.turn)
    if futex.number >= current:
        futex_wake(futex.turn, MAXINT) <1>

----
<1> Como no se puede seleccionar solo al proceso del siguiente turno hay que despertar a todos para que verifiquen el turno. Por ello se especifica un número muy grande, en este caso el máximo entero.

Comparado con el anterior este último es muy ineficiente. El primero se ejecuta en menos de un segundo de tiempo de reloj, con aproximadamente tres segundos de uso de CPU:

----
$ time ./futex_simple_mutex
real	0m0.874s
user	0m0.373s
sys	    0m2.664s
----

Los tiempos del _ticket-lock_ en el mismo ordenador:
----
$ time ./futex_fair_simple_mutex
real	0m34.997s
user	0m8.185s
sys	    1m22.512s
----

La diferencia es enorme. Uno de los problemas, los procesos no entran a la cola en el mismo orden de su turno lo que significa que hay que despertar a todos para que verifiquen su turno, lo que  provoca una _tormenta_ de procesos que se despiertan, verifican el turno y vuelven a bloquearse. Esta _tormenta_ puede aliviarse usando las opciones `BITSET`. Éstas permiten especifica una máscara de 32 bits, se pueden tener hasta 32 colas diferentes en cada _futex_ y seleccionar cuál de ellas usar para el _wait_ o el _wake_ (<<futex_fair_mutex_bitset_c, código completo>>, se usa módulo 32 del número seleccionado y el turno para indicar la cola).

----
$ time ./futex_fair_mutex_bitset
real	0m28.359s
user	0m7.006s
sys	    0m29.680s
----

El tiempo se reduce, aún así sigue siendo muy ineficiente, la raíz es que en caso de alta competencia todos los procesos -prácticamente sin excepción- son bloqueados y luego desbloqueados.
 después.


===== Optimización del _mutex_ equitativo

FUTEX es muy potente es complicado y costoso asegurar que un _mutex_ sea _equitativo_, por eso el _mutex_ de las librerías POSIX Threads tampoco es equitativo. Su comportamiento es muy similar al del primer ejemplo de _mutex simple_, el proceso que acaba de salir de la sección crítica es el primero en volver a entrar si lo intenta inmediatamente. Aunque la solución sea contraintuitiva es posible optimizar considerablemte más el _mutex_ equitativo recurriendo a esperas activas limitadas.

Si hay alta competencia y las secciones críticas son breves conviene más hacer una breve espera activa -en la entrada y salida- para dar oportunidad a que el siguiente proceso pueda obtener el _lock_ sin necesidad se pasar por la cola de bloqueados. El número de iteraciones en espera activa debe estar limitada para evitar convertir al algoritmo en un _spinlock_. En el `lock()` se hace antes de intentar el _wait_ y en el `unlock()` antes del _wake_ (<<futex_fair_mutex_spin_c, código fuente>>).


----
def lock(futex):
    number = fetch_and_add(futex.number, 1)

    tries = 0               <1>
    while number != futex.turn and tries < 100:
        tries++;

    turn = futex.turn
    while number != turn:
        futex_wait(futex.turn, turn)
        turn = futex.turn

    futex.current = number  <2>
----
<1> Espera activa limitada a 100 iteraciones.
<2> Campo adicional para indicar el número de turno del proceso en la sección crítica.

----
def unlock(futex):
    current = fetch_and_add(futex.turn)

    tries = 0               <1>
    while current != futex.current and tries < 100:
        tries++

    if current > futex.current:
        futex_wake(futex.turn, MAXINT)

----
<1> La espera actica antes de intentar el _wake_ también limitada a 100 iteraciones. Se usa el campo `futex.current` para verificar si el proceso al que le corresponde el turno entró a la sección crítica.

El tiempo de ejecución es ahora un poco más del doble que el original no equitativo y casi veinte veces menos que el equitativo sin espera activa.

----
$ time ./futex_fair_mutex_spin
real	0m1.702s
user	0m2.804s
sys	    0m3.898s
----

Demuestra las ventajas de evitar cambios de contexto cuando hay alta competencia y las secciones críticas son muy breves (<<LockLess2>>).

==== La implementación de semáforos más simple
La implementación de semáforos generales con FUTEX es muy sencilla si se toman algunas precauciones:

1. Permitimos que el valor del semáforo, `value`, pueda tomar números negativos (el valor absoluto indica el número de procesos en la cola).

2. Si el _wait_ genera un valor negativo el proceso se siempre se bloqueará y esperará el _wake_ desde el proceso que ejecute el _signal_. Como con la implementación del _mutex simple_ no es eficiente pero simplifica mucho el diseñofootnote:[Queda como ejercicio al lector buscar hacerlo eficiente, no es complicado.].

3. Al ejecutar el _signal_ se asegura que un proceso siempre se despierta.

Si se toman estas precauciones además es posible evitar el bucle de verificación de que el proceso fue bloqueadofootnote:[Recordad que el `futex_wait` verifica que el valor del _futex_ sea igual al segundo argumento.] usamos el campo adicional `futex` que no se modifica, solo la referencia de memoria para el sistema operativo.

La operación _wait_ queda muy sencilla, prácticamente idéntica a la definición _académica canónica_ de semáforos del principio del capítulo.

----
def wait(sem):
    value = add_and_fetch(sem.value, 1)
    if value < 0:
        futex_wait(sem.futex, sem.futex)    <1>
----
<1> Si el valor es `0` el proceso siempre se bloqueará.

_Signal_ también es muy próxima a la definición básica, lo único _adicional_ es el bucle que verifica que efectivamente se desbloqueó a un proceso. Hay que hacer esta comprobación ya que el proceso que decrementó el semáforo y lo dejó negativo pudo no haber ejecutado el `futex_wait` antes que el _signal_ en otro proceso ejecute el `fute_wake` correspondiente.

----
void signal(futex_sem_t *sem) {
    value add_and_fetch(sem.value, 1)
    if value <= 0:
        while futex_wake(sem.futex, 1) < 1: <1>
            sched_yield()
----
<1> La verificación de desbloqueó a un proceso (el `sched_yield()` no es imprescindible).


=== Inversión de prioridades

.Un bug marciano
****
El día 4 de julio de 1997 el _Mars Pathfinder_ aterriza en Marte, se despliega la nave que sirvió para el viaje y aterrizaje –el _SpaceCraft_– y a las pocas horas empieza a enviar las fotos en alta calidad. Hasta ese momento la misión era un éxito.

A los pocos días se detectan reinicios continuos del ordenador al intentar enviar a la tierra datos metereológicos y científicos. Los reinicios los iniciaba la tarea _bc_sched_ responsable de verificar que las demas tareas se ejecutan correctamente.

El procesador era un Power1/RS6000 de IBM, conectado a un bus VME con interfaces para la cámara, la radio y un bus 1553. El bus 1553 tenía dos partes, una usada para navegación espacial (aceleradores, válvulas, sensor solar y escáner de estrellas) y otra para el aterrizaje con interfaz para el acelerómetro, radar de altitud y los instrumentos científicos: el ASI/MET. El hardware del 1553 fue heredado de la sonda Cassini y tenía un modo de funcionamiento simple: el software controlador y toma de datos se planificaban exactamente cada 0.125 segundos (8 Hz).

El sistema operativo era un Unix de tiempo real desarrollado por Wind River, VxWorks, adaptado específicamente al procesador RS600. La arquitectura de software era la siguiente:

- _bc_sched_: La tarea con máxima prioridad, se encargaba de preparar las transacciones para el siguiente ciclo de 0.125 segs sobre el bus 1553.

- _entry+landing_: La tarea con la segunda prioridad, ya inactiva.

- _bc_dist_: La tarea de tercera prioridad, toma datos del 1553 y los copia en un doble buffer circular desde donde extraen información las otras tareas, salvo las ASI/MET.

- Otras tareas de prioridad intermedia.

- _ASI/MET_: La tarea de menor prioridad junto con otras tareas científicas (generación y compresión de imágenes, etc.). A diferencia de las otras ASI/MET toma datos al 1553 a través de un mecanismo de comunicación entre procesos usando el `pipe()` estándar de Unix.


Una vez detectados los reinicios se analizaron los datos de debug generados y enviados por _bc_sched_, el problema era siempre el mismo, _bc_dist_ no completaba su ejecución en el tiempo previsto. Después 18 horas de simulaciones descubrieron la causa, por la cantidad inesperada de datos que se recogía el sistema el sistema más cargado que el _mejor caso_ probado por la NASA. La tarea de baja prioridad _ASI/NET_ accedía a una sección crítica con un _wait_ a semáforos _mutex_ dentro de las funciones del `pipe()` pero no alcanzaba a salir porque el sistema operativo asignaba el procesador a las tareas de prioridad intermedia. La tarea _bc_dist_ también hacía un _wait_ al mismo _mutex_ de `pipe()` pero quedaba bloqueado porque _ASI/NET_ estaba en la sección crítica.

Así se legaba al final de su período _bc_dist_ no acababa (y forzaba el reinicio). El problema era la _inversión de prioridades_.
****

[[dining_image]]
.Inversión de prioridadesfootnote:[Imagen de <<Shiftehfar>>]
image::priority-inversion.png[height="250", align="center"]



////
https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ArrayBlockingQueue.html
http://docs.oracle.com/javase/7/docs/technotes/guides/collections/overview.html
http://docs.oracle.com/cd/E19683-01/806-6867/sync-27385/index.html

https://cs.nyu.edu/~yap/classes/os/resources/EWD74.pdf
http://docs.oracle.com/cd/E19683-01/806-6867/sync-27385/index.html
http://www.cs.utexas.edu/users/EWD/transcriptions/EWD00xx/EWD74.html

<<railroad>>
_It is Texas law that when two trains meet each other at a railroad crossing, each shall come to a full stop, and neither shall proceed until the other has gone._


http://locklessinc.com/articles/mutex_cv_futex/
http://locklessinc.com/articles/futex_cheat_sheet/
////
