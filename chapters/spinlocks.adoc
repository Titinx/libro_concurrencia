[[spinlocks]]
== _Spinlocks_
Todas las soluciones de exclusión mutua vistas tienen algo en común, una espera activa en un bucle que continuamente verifica el estado de una variable o registro _RMW_ hasta que el proceso puede entrar a la sección crítica. Estos algoritmos se denominan _spinlocks_, el de Dekker, Peterson, la Panadería o cualquiera de las soluciones de exclusión mutua del capítulo anterior son también _spinlocks_. Su uso solo tiene sentido si se cumple una de las siguientes condiciones:

. El código que se ejecuta en la sección crítica es muy breve y por lo tanto la competencia (_contention_) es baja. Esta es una solución empleada desde los inicios de la informática para sincronizar el núcleo de los sistemas operativos e implementar mecanismos de sincronización que evitan las esperas activasfootnote:[Los que veremos en los capítules siguientes.].

. Los procesos se ejecutan en paralelo en diferentes procesadores, mientras unos procesos están en sus _spinlocks_ otros pueden avanzar y salir de la sección crítica. Estas técnicas permiten evitar mayores pérdidas de tiempo ocasionadas por llamadas de sistema y/o cambio de estado de procesos. Si hay muchos más procesos en _spinlocks_ que procesadores se llega a una situación similar a la de un único procesador por lo que los procesos avanzarían muy lentamente y tendría más sentido utilizar construcciones sin esperas activas.

El problema principal es la ineficiencia provocada por la espera activa y los requerimientos de almacenamiento en las soluciones algorítmicas sin registros _RMW_. Por ello se desarrollaron las primitivas de hardware que permiten minimizar el impacto y sobre todo eliminar la necesidad de recorrer una multitud de registros como en el algoritmo de la Panadería. Estas primitivas suponen una gran mejora en el espacio necesario -requieren sólo una palabra por cada sección crítica (o _lock_)- como de facilidades de programación. Pero no todas los procesadores ofrecen las mismas, si se quiere obtener el máximo de eficiencia hay que programar para cada arquitectura como se suele hacer en el núcleo de los sistemas operativos. Para facilitar la portabilidad los compiladores incluyen primitivas fundamentales, los macros o _intrinsics_, que son traducidas a las operaciones que implementan o simulan esas primitivas y que son las que usé para el código de demostraciónfootnote:[Salvo el código en ensamblador con ldrex/strex para ARM.].

Analizaremos el comportamiento de cada uno de estos _spinlocks_ y las técnicas más usadas para optimizarlos. En la siguiente figura se muestran los tiempos de _reloj_ en segundos de la ejecución de los algoritmos del capítulo anterior ejecutados sobre un Intel i5 con 2 cores SMP (barra azul de la izquierda), ARM v7 de Raspberry Pi 2 con cuatro núcleos (barra naranja), ARM v6 de Raspberry 1 (barra amarilla) y finalmente la de una instancia m3.large (con dos núcleos virtuales) de Amazon EC2.

[[hardware_times]]
.Tiempos de ejecución para los diferentes macros e instrucciones de hardware para Intel y ARM v6
[caption=""]
image::times-hardware.png[align="center"]

Cada grupo es una medición diferente. El primero (_none_) es el tiempo sin ningún mecanismo de exclusión mutua. El segundo (_ultimate_) es el más eficiente para este caso de sólo sumar un entero usando la instrucción atómica _getAndAdd_ directamente sobre la variable `counter`. Los siguientes hacia la derecha son los algoritmos usando las instrucciones de hardware del capítulo anterior _swap_, _getAndAdd_, _testAndSet_, _getAndSet_ y _compareAndSwap_ respectivamente.

Se puede observar que todos los algoritmos de exclusión mutua imponen un sobrecoste importante pero que no es uniforme para todas las plataformasfootnote:[En _get&add_ no están los tiempos de la Raspberry 1 y la instancia m3.large porque necesitan mucho tiempo, hasta horas.].

En Raspberry 1 la implementación más eficiente es _getAndSet_ seguida por _compareAndSwap_.
En Raspberry 2 la más eficiente es _compareAndSwap_ (hay que recordar que además de arquitectura más moderna son cuatro procesadores). En Intel la más eficiente es _swap_ y la peor es _compareAndSwap_, un resultado curioso dado que Intel tiene _CAS_ nativo pero en ARM se emula con _LL/SC_.footnote:[También muestra las buenas propiedades de LL/SC.]. Es interesante lo bien que se comporta la instancia EC2, y que _CAS_ sea el más eficiente, seguramente influenciado por las características más modernas del procesador.

=== Optimizaciones
Los _spinlock_ son ineficientes por dos razones:

Uso y competencia por el procesador:: Los procesos consumen el 100% CPU verificando el valor de una variable, si hay más hilos compitiendo que procesadores la mayor parte del tiempo se pierde en el bucle de verificación.

La presión sobre la memoria cache:: Estos algoritmos no son _escalables_ En sistemas con varios procesadores todos los procesos verifican el estado de la misma variable (_hot spot_) por lo que se generan mensajes de sincronización de cache entre los diferentes procesadores.

Aunque son preferibles los _spinlocks_ escalables veremos técnicas básicas para mejorar el rendimiento de los _spinlocks_ anteriores, al final del capítulo estudiaremos los dos algoritmos escalables más importantes.

[NOTE]
._Spinlocks_ escalables
====
Se denominan _spinlocks escalables_ aquellos en que los _fallosfootnote:[No implica que haya producido un error en el sistema sino que el procesador no tiene una copia actualizada en su memoria cache por lo que se deben producir intercambios de mensajes para actualizarla al último valor.] de memoria cache_ se mantienen constantes independientemente de las iteraciones necesarias en la entrada a la sección crítica (<<MCS>>, <<Boyd-Wickizer>>).

Si en cada iteración (o _spin_) los procesos en diferentes procesadores verifican las mismas variables se produce -como mínimo- un _fallo de cache_ cada vez que un proceso cambia de estado ya que cada actualización genera invalidaciones de cache. El problema se agrava por el <<false_sharing, _false sharing_>>, los registros en la sección crítica suelen estar en áreas cercanas a las variables de los _spinlocks_. Por ello se estudiaron y desarrollaron los <<scalable_spinlocks, _spinlocks escalables_>> que veremos al final del capítulo.

====

Las tres que veremos a continuación, implementados sobre el _spinlock_ con _testAndSet_, no pueden ser considerados _escalables_ ya que no reducen la presión sobre la memoria cache.

==== Verificación local
Se trata de reducir la presión sobre el sistema de coherencia de cache y evitar la llamada a la instrucción atómica verificando antes (_corto circuitando_) el valor de la variable sobre la que se itera -la variable `mutex` en los ejemplos-. Si ésta vale `1` ya no se llama a la instrucción atómica. Esta técnica se la conoce como _TAS_ o _TATAS_ cuando se usa con la instrucción _TAS_.

[source]
----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        pass
----

La mejora de esta solución depende mucho de la arquitectura y de sus mecanismos de coherencia de cache. En los <<execution_times, tiempos de ejecución>> se observa que esta técnica mejora mucho la eficiencia en las arquitecturas Intel pero son casi despreciables en la arquitectura ARM.

Código fuente para <<test_test_and_set_c, _TAS_>>, <<test_swap_c, _swap_>> y <<test_compare_and_swap_c, _CAS_>>.

==== Ceder el procesador
La idea es sencilla, si un proceso está forzado a continuar en la espera activa porque no se cumple la condición de salida del bucle es mejor ceder el procesador para que otro lo intente o pueda salir antes de la sección crítica. En el ejemplo usamos la llamada de sistema estándar POSIX `sched_yield` que hace que el sistema operativo quite al proceso de ejecución y lo mueva a la cola de _listos para ejecutar_.
[source]
----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        sched_yield()
----
La cesión del procesador <<execution_times, produce reducciones de tiempo importantes>> en todas las arquitecturas salvo excepciones como en _CAS_ sobre la Raspeberry con un único procesadorfootnote:[La causa pueden ser el coste adicional de llamadas de sistemas y cambios de contexto, o el efecto ping-pong de procesos que cambian de estado continuamente.].

Código fuente para <<test_and_set_yield_c, _TAS_>>, <<swap_yield_c, _swap_>> y <<compare_and_swap_yield_c, _CAS_>>.


==== Espera exponencial
La forma de reducir la competencia (_contention_) y evitar que el efecto ping-pong de los procesos es forzar a que permanezcan bloqueados por un tiempo variable dependiendo de las veces que ha _fallado_.


[NOTE]
.Exponential backoff
====
_Exponential backoff_ es la técnica usada por redes Ethernet, WiFi y similares de _bus compartido_ para calcular el tiempo de espera para reenviar después de una colisión, _backoff_ se refiere a la espera y _exponential_ a que el valor límite del tiempo a esperar se duplica en cada _fallo_. El tiempo efectivo de espera de cada proceso es un número aleatorio entre 1 y el límitefootnote:[Se usa un número aleatorio para evitar que todos los procesos reintenten simultáneamente.].

El siguiente es el código en C usado en los ejemplos. En cada iteración fallida dentro del _spinlock_ el proceso incrementa el contador de fallos (`failures`) y llama a la función _backoff_. Ésta calcula el límite (`limit`) con desplazamiento de bits, cada posición desplazada multiplica por dos, por ello se desplaza el bit `1` hacia la izquierda con un máximo de 12, unos 4096 nanosegundos. Luego se calcula el tiempo que esperará con un número random entre 1 y el límite.


[source,c]
----
#define FAILURES_LIMIT 12
void backoff(int failures) {
    struct timespec deadline = {.tv_sec = 0};
    unsigned limit;

    if (failures > FAILURES_LIMIT) {
        limit = 1 << FAILURES_LIMIT;
    } else {
        limit = 1 << failures;
    }

    deadline.tv_nsec = 1 + rand() % limit;
    clock_nanosleep(CLOCK_REALTIME, 0, &deadline, NULL);
}
----
====


[source, c]
----
        mutex = 0

def lock():
    failures = 0

    while mutex or TAS(mutex):
        failures += 1
        backoff(failures)
----

La dificultad del _backoff_ reside en la elección de la unidad de tiempo de espera, no existe un valor ideal, depende de cada arquitectura y caso de uso. Si la espera es muy breve producirá un efecto similar al `sched_yield` con una sobrecarga aún mayor del sistema operativofootnote:[El proceso pasa de ejecución a _bloqueado_ luego a _listo_ y nuevamente a ejecución en un tiempo muy breve.]. Por el contrario, si la unidad es muy grande producirá demoras innecesarias y con tiempos CPUs inactivas ya que los procesos involucrados están _bloqueados_.

Código fuente para <<test_and_set_backoff_c, _TAS_>>, <<swap_backoff_c, _swap_>> y <<compare_and_swap_backoff_c, _CAS_>>.

[[execution_times]]
==== Tiempos de ejecución
A continuación cuatro gráficas que representan los tiempos de ejecución de los diferentes algoritmos. Hay que recordar que el ejemplo que usamos -hilos que sólo incrementan un contador compartido- son muy extremos. Aunque tienen una sección crítica muy breve lo único que hacen es entrar y salir de ella sin procesamiento adicional lo que significa que la competencia es extremadamente elevada y muy lejos de la inmensa mayoría de casos reales. Pero sirve para tener una base de comparación entre diferentes procesadores y arquitecturas.

También hay que tener en cuenta que los ejemplos fueron programados en C portable usando los macros atómicos de GCC. Éste no siempre genera el mejor código para cada una de las arquitecturas, por ejemplo las de barreras de memoria siempre generan una barrera completa para ARM (`dmb sy`) aunque se especifique que sólo se desea una barrera _release_. En estos casos la única solución es programar estos algoritmos en ensamblador para cada arquitectura diferente, como se hace en el núcleo de los sistemas operativos. Pero de haberlo hecho así me habría generado mucho más trabajo, dificultado la comprensión de lo fundamental y hasta las pruebas que podéis hacer vosotros mismos con los programas.

Lo interesante de las gráficas:

- El _compareAndSwap_ es la más ineficiente en Intel i5 y en el Core2 Quad pero la más eficiente en una instancia m3 de Amazon EC2.

- [[core2_vs_i5]]La mayor eficiencia del Intel i5 sobre el Core2 a pesar de que el segundo tiene más núcleos se debe a que el _Front Side Buffer_ del Intel Core2 usa un bus compartido para los mensajes del protocolo de coherencia de cache mientras que el i5 tiene el nuevo sistema <<quickpath, _QuickPath Interconnect_>>.

- Es notable el buen comportamiento y uniformidad de ARM para todas las instrucciones, sobre todo porque ellas se emulan con el _LL/SC_. En ambas versiones, v6 y v7 (de Raspberry 1 y 2 respectivamente) el _compareAndSwap_ es la más eficiente.

- La unidad de espera elegida para el `backoff` funciona muy bien en la Raspberry 1 aunque en principio no parecía una buena candidata.

- En todas las plataformas con multiprocesadores el `sched_yield` y el `backoff` producen reducciones de tiempos importantes, incluso cuando el número de procesos concurrentes (cuatro) es igual al número de procesadores (en el Intel Quad y en ARM v7 de Raspberry 2). La mejora no se debe a la reducción de uso de la CPU sino a la menor presión sobre el sistema de coherencia de cache,footnote:[Puedes hacer la prueba, en la versión de _backoff_ reemplaza el `clock_nanosleep` por un bucle como `for (i = 0; i < limit; i++);` y verás que se produce la misma reducción -incluso mayor-, simplemente por no acceder a las variables compartidas continuamente.] la causa principal por la que se estudiaron _spinlocks_ escalables.

[NOTE]
.Cede el procesador
====
No te despedirán por poner un `sched_yield` o _backoff_ exponencial en un _spinlock_ con mucha competencia aunque parezca que sobran procesadores o núcleos.
====

.Intel Core2 cuatro núcleos
image::optimized-intel-quad.png[align="center"]

.Intel i5 dos núcleos con extensión SMP
image::optimized-intel.png[align="center"]

.Intel AWS m3.large dos núcleos
image::optimized-m3-large.png[align="center"]

.ARMv7 Raspberry 2 cuatro núcleos
image::optimized-arm7.png[align="center"]

.ARMv6 Raspberry 1
image::optimized-arm.png[align="center"]


=== Lectores-escritores
La mayoría de las operaciones que se hacen sobre la memoria, incluida la compartida, son acceso para lectura. En estos casos interesa que las lecturas sean consistentes. En nuestros ejemplos con un único contador entero no existe el problema, las palabras de 32 bits son <<atomic_register, registros atómicos>> en las arquitecturas de 32 bits o más. Si un proceso  lee ese esa variable siempre obtendrá el último valor escrito. Pero si se trata de estructuras más complejas -incluso el acceso a ficheros o dispositivos externos- hay que imponer restricciones para que la estructura no sea modificada mientras haya procesos que la están accediendo.

Se puede usar exclusión mutua pero ello emplica que se estarían _serializando_ hasta los accesos de sólo lectura, es un mecanismo nada eficiente. Por ello una de las relajaciones más importantes a las condiciones de la exclusión mutua es que se permita que haya más de un lector en la sección crítica de forma simultánea, estos algoritmos de sincronización son llamados lectores-escritores (_reader-writer_).

Las condiciones que deben cumplir son:

- Se permite más de un lector.

- Mientras haya un lector en la sección crítica no puede entrar ningún escritor.

- Los lectores no pueden entrar si hay un escritor en la sección crítica.

- Sólo puede haber un escritor en la sección crítica.

Así como la exclusión mutua tiene un mecanismo de entrada la sección crítica (_lock_) y otro de salida (_unlock_) los de lectores-escritores necesitan distinguir entre ambos con  entradas y salidas diferenciadas (_reader_lock_, _writer_lock_, _reader_unlock_ y _writer_unlock_).

El siguiente algoritmo es una relativamente simple (<<rw_lock_c, código en C>>) que necesita las instrucciones _compareAndSwap_ y _getAndAdd_. Se usa una variable global entera _mutex_ como en los algoritmos anteriores pero el bit más significativo indica si un escritor está en la sección crítica, los restantes bits para contar el número de lectores que hay en ella. Si se usa un entero de 32 bits se permiten hasta 2^31^ lectoresfootnote:[Se un número muy elevado y puede reducirse a enteros más pequeños pero en las mediciones de tiempo no encontré diferencia favorable.].

Los lectores primero esperan a que no haya ningún escritor, luego incrementan el número de lectores e intentan hacer el _CAS_. Si se pudo hacer el intercambio condicional entran a la sección crítica, caso contrario vuelve a intentar desde el inicio.

.Entrada y salida para lectores
[source]
----
            rw_lock = 0             <1>

def reader_lock():
    while True:
        while rw_lock & 0x80000000: <2>
            pass
        old = rw_lock & 0x7fffffff  <3>
        new = old + 1               <4>
        if CAS(rw_lock, old, new):  <5>
            return


def reader_unlock():
    getAndAdd(rw_lock, -1)          <6>
----
<1> La variable global `mutex`, en el ejemplo de 32 bits.
<2> Verifica si el bit más significativo es `1`, si es así hay un escritor e itera hasta que sea `0`.
<3> No hay escritores, obtiene el número de lectores.
<4> Incrementa el número de lectores.
<5> Si `rw_lock` no fue modificado el _compareAndSwap_ almacenará el nuevo valor. Si  `rw_lock` fue modificado volverá al inicio del `while` y lo intentará nuevamente.
<6> Decrementa atómicamente el número de lectores.

Los escritores primero esperan a que no haya otro escritor en la sección crítica luego ponen el bit más significativo en `1` e intentan el intercambio con _CAS_. Si no se pudo hacer vuelven a intentarlo desde el principio. Si por el contrario fue satisfactorio esperan a que no queden lectores para entrar a la sección crítica.

.Entrada y salida para escritores
[source]
----
def writer_lock():
    while True:
        while rw_lock & 0x80000000:     <1>
            pass
        old = rw_lock & 0x7fffffff      <2>
        new = old | 0x80000000          <3>
        if CAS(rw_lock, old, new):      <4>
            while rw_lock & 0x7fffffff: <5>
                pass
            return


def writer_unlock():
    rw_lock = 0    <6>

----
<1> Verifica el bit más significativo e itera hasta que no haya ningún escritor.
<2> Obtiene el número de lectores actuales.
<3> Calcula el nuevo valor, será el número de lectores con el bit más significativo en `1` indicando que hay un escritor.
<4> Si el valor tomado de `rw_lock` no cambió se almacena el nuevo, caso contrario vuelve al principio del `while` para reintentarlo.
<5> Espera que salgan todos los lectores, los siguientes ya no podrán entrar porque el bit más significativo está en `1`.
<6> Para salir sólo debe poner `rw_lock` en cero ya que no quedan lectores ni escritores en la sección crítica.


Una característica importante de los algoritmos de lectores-escritores es la prioridad que da a unos o a otros. Si lo que interesa es _rendimiento_ (_throughput_) y lecturas muy rápidas es mejor dar prioridad a los lectores. Si por el contrario interesa que las actualizaciones sean rápidas y poder acceder a los últimos valores lo más pronto posible se deben usar algoritmos que den prioridad a los escritores. El problema es el riesgo de inanición en los que no tienen prioridad, aunque hay algoritmos que aseguran equidadfootnote:[Unos pocos párrafos más abajo veremos uno.] los más comunes dan prioridad a uno de ellos (<<MCS2>>).

Queda a ejercicio del lector encontrar si este algoritmo da prioridad a los lectores o escritoresfootnote:[Seguramente no lo has mirado todavía, pero este algoritmo da prioridad a los escritores. Cuando un escritor desea entrar a la sección crítica pone en `1` el bit más significativo, independientemente de los lectores que estén dentro, haciendo que los siguientes lectores que lleguen esperen hasta que el escritor haya entrado y salido.].

[[fairness]]
=== _Spinlocks_ equitativos

El problema de los algoritmos anteriores es que no cumplen uno de los <<em_requisites, requisitos de la exclusión mutua>>, asegurar que no se produce inanición. Aunque estadísticamente no se puede producirfootnote:[En miles centenares de miles de iteraciones es extremadamente improbable que nunca le toque a un proceso.] sí que plantea problemas de equidad -un proceso se retrasa mucho más que otros-, por ejemplo en 2008 se derectó este efecto en el núcleo de Linux (<<Corbet>>). Para evitarlo hay que usar algoritmos que aseguren que los procesos entren a la sección crítica en el orden que han llegado (_FIFO_).

==== _Ticket-lock_
[[ticket_lock]]
Una solución sencilla la hemos _descubierto_ con el uso de la instrucción <<get_and_add_ticket, _getAndAdd_ para asegurar exclusión mutua>>, la idea es la misma que el algoritmo de la Panadería sólo que la obtención del número se hace con la operación atómica _getAndAdd_ por lo que se evita que los procesos puedan seleccionar el mismo número y/o fuera de orden. Usa dos variables: el número creciente y el turno. Un proceso obtiene su número y luego espera que a su turno, cuando sale de la sección crítica incrementa el turno para que entre el siguiente proceso.

Este algoritmo es muy usado en el núcleo de Linux para asegurar equidad ya que se encontraron casos de _inanición_ en algunas arquitecturas de varios núcleos (<<Corbet>>, <<Corbet2>>):

[quote, Nick Piggin]
On an 8 core (2 socket) Opteron, spinlock unfairness is extremely noticable, with a userspace test having a difference of up to 2x runtime per thread, and some threads are starved or "unfairly" granted the lock up to 1 000 000 (!) times.


<<ticket_lock_c, El código en C>> de este algoritmo es idéntico al anterior de _getAndAdd_, sólo se unificaron ambas variables en una única estructura de 32 bits, con 16 bits para `turn` y `number` respectivamente. El número y turno pueden llegarán hasta 2^16^ y rotarán.

[source, c]
----
struct tickets {
    uint16_t turn;
    uint16_t number;
};
----

==== Lectores-escritores

Usando como base el algoritmo de _ticket-lock_ se puede implementar un algoritmo de lectores-escritores que asegure la equidad entre ellos (a diferencia de la mayoría que dan prioridad a unos u otros). Para hacerlo se necesita dos variables diferentes para los turnos de cada uno. Se necesita una estructura del siguiente tipo:

image::ticket_rw.png[width="80%", align="center"]

En <<ticket_rw_lock_c, el código en C>> se define de la siguiente forma:

[source, c]
----
struct ticket_rw {
    uint16_t number;
    union {
        uint32_t combined;
        struct {
            uint16_t writer_turn;
            uint16_t reader_turn;
        };
    };
};
----

El campo `number` es similar al algoritmo _ticket-lock_, `writer_turn` y `reader_turn` indicarán los turnos para los escritores y lectores respectivamente. Ambas variables tendrán que ser incrementadas para permitir que entren lectores o escritores de forma equitativa. El _truco_ está en el orden en que se hace la suma, un escritor sólo dará el turno a otros lectores o escritores cuando salga de la sección crítica. Un lector dará paso a otros lectores en cuanto haya entrado a la sección crítica, y solo permitirá escritores cuando haya salido.

Se define el campo `combined` que incluye a ambos turnos para poner hacer una asignación atómica a de ambos turnos. Para el desarrollo del algoritmo suponemos una variable global `rw_local` del tipo o clase `ticket_rw`.


.Entrada y salida para escritores
[source]
----
def writer_lock():
    number = getAndAdd(rw_lock.number, 1)
    while number != rw_lock.writer_turn:
        pass
----

El escritor obtiene su número y espera que sea un turno en `writer_turn`.

[source]
----
def writer_unlock():
    tmp.writer_turn = rw_lock.writer_turn + 1
    tmp.reader_turn = rw_lock.reader_turn + 1
    rw_lock.combined = tmp.combined

----

Cuando el escritor sale de la sección crítica debe poder entrar el siguiente lector o escritor por lo tanto incrementa ambas variables.


.Entrada y salida para lectores
[source]
----
def reader_lock:
    number = getAndAdd(rw_lock.number, 1)

    while number != rw_lock.reader_turn:
        pass
    rw_lock.reader_turn++
----

El lector obtiene su número y espera el turno de lectores. Cuando entró incrementa el turno de lectores para que puedan entrar el siguiente, si hay otro esperando. Éste hará lo mismo, así puede haber varios lectores en la sección críticafootnote:[No hace falta que este incremento se haga con operaciones atómicas ya que solo un lector puede ejecutarla, el siguiente no entra hasta que ya tiene el nuevo valor.].


[source]
----
def reader_unlock:
    getAndAdd(rw_lock.writer_turn)

----

El lector al salir incremente el turno de escritor por si al siguiente es uno de ellos. No hace falta incrementar el turno de lectores, ya lo hizo antes al entrar a la sección crítica.

Este algoritmo es equitativo porque todos los procesos entran en el orden en que obtuvieron su número, independientemente de que sea lector o escritor. Aunque los lectores incrementan el turno de lectores inmediatamente, si el siguiente proceso es un escritor ningún lector podrá entrar, esperarán hasta que entre el escritor que tiene el turno y a su salida incremente el turno dando oportunidad de entrada a un lector o escritor.


[[scalable_spinlocks]]
=== _Spinlocks_ escalables

Como comenté en el inicio del capítulo se buscan que los _spinlocks_ sean escalables, es decir que el número de invalidaciones de caché (que generan _fallos de cache_, también llamados _cache bouncing_) se constante respecto al número de procesos o procesadores involucrados. La forma de lograrlo es que cada proceso itere sobre posiciones de memoria diferentes.

==== _Array-lock_
La respuesta obvia al requerimiento es que cada proceso tenga su propia posición en un array de _locks_ inicializados en cero (salvo la primera posición que será `1` para que el primer proceso pueda entrar). Los procesos que compitan por la sección crítica tendrán una posición única en ese array, ésta vendrá indicada por la variable `tail` inicializada en cero. Cada proceso obtiene su posición con la operación _getAndAdd_ que al mismo tiempo incrementa `tail` para el siguiente.

La variable que indica si un proceso puede entrar es booleana por lo que se usará un único byte. Para evitar el _false sharing_ es mejor separar cada posición por varios bytes. Podemos definir una estructura de mayor tamaño con un campo de un byte para la verificación, o directamente se define un _padding_.

.Estructura del _Array-lock_
image::array_lock.png[align="center"]

En la figura anterior `Thread 0` ya entró en la sección crítica, `Thread 1` y `Thread 2` están esperando verificando el estado de sus respectivas posiciones en el array y `tail` apunta a la siguiente posición. Cuando `Thread 0` salga de la sección crítica cambiará el estado de `flag[1]` y podrá entrar `Thread 1`.

La inicialización (en C) es la siguiente:

[source]
----
#define PADDING 32
char flag[NUM_THREADS * PADDING];
int tail;
...

    flag[0] = 1;
----

Si hay cuatro hilos máximo la dimensión del array serà `4 * 32` (128 bytes en total). El cálculo de la posición real (`my_index`) requiere de una multiplicación y módulo, nada demasiado complicado. El algoritmo resumido (<<array_lock_c, código completo en C>>) es el siguiente:


[source]
----
def lock(my_index):
    slot = getAndAdd(tail, 1)
    my_index = (slot % NUM_THREADS) * PADDING
    while not flag[my_index]:
        pass
    flag[my_index] = 1


def unlock(my_index):
    next = (my_index + PADDING) % SIZE
    flag[next] = 1;

----

Este algoritmo también es equitativo, sólo necesita la instrucción atómica _getAndAdd_ y los procesos entran en el orden en que la ejecutaron. Según le teoría y toda la bibliografía (por ejempo <<Herlihy12>>) aseguran que así se evitar el _false sharing_ y por lo tanto más eficiente que _Ticket-lock_, analizaremos cuánto de hay de verdad y mito <<spinlock_times, un poco más adelante>>.


[[mcs_queue]]
==== MCS _Spinlock_

Lo ideal para evitar la presión en la cache es que cada hilo pueda usar variables locales, así se asegura que no se comparten línea de cache y además que éstas son cercanas a otros variables o estructuras de los proceso. El algoritmo de cola MCSfootnote:[El nombre  MCS son las iniciales de los apeelidos los autores.] fue descubierto en 1991 por John M. Mellor-Crummey y Michael L. Scott (<<MCS>>). Se le considera uno de los algoritmos más importantes e influyentes de exclusión mutua, sus autores recibieron el premio _Edsger W. Dijkstra Prize in Distributed Computing_ de 2006 y el uso de variantes de este algoritmo se usan en los sistemas más variadosfootnote:[Por ejemplo en la implementación de _monitores_ de la máquina virtual de Java.].

Para implementarlo hacen falta las operaciones _swap_ y _compareAndSwap_. Es rápido, equitativo (FIFO) y no necesita asignación previa de memoria (como en _array-lock_). Los procesos deben pasar como argumento la dirección de un nodo (de la pila) local por lo que se evita el _false sharing_.

.Cola MCS
image::mcs.png[align="center"]



==== CLH Spinlock

[[clh_queue]]
.Cola CLH
image::clh.png[align="center"]

[[spinlock_times]]
=== Análisis de tiempos de ejecución

===== Ticket vs MCS vs CLH
image::ticket-mcs-clh.png[align="center"]

===== Ticket vs MCS vs CLH con sched_yield
image::ticket-mcs-clh-yield.png[align="center"]




Agradecimientos a Marc Pampols

Reader-writer: https://jfdube.wordpress.com/2014/01/03/implementing-a-recursive-read-write-spinlock/
https://jfdube.wordpress.com/2014/01/12/optimizing-the-recursive-read-write-spinlock/



(http://nullprogram.com/blog/2014/09/02/ https://github.com/skeeto/lstack)
Common Pitfalls in Writing Lock-Free Algorithms http://blog.memsql.com/common-pitfalls-in-writing-lock-free-algorithms/

Toward generic atomic operations/The C11 memory model http://lwn.net/Articles/509102/

Ticket implementation https://github.com/karthick18/ticket_spinlock/blob/master/spinlock.h



Lightweight Contention Management for
Efficient Compare-and-Swap Operations http://arxiv.org/pdf/1305.5800.pdf

MCSLocks http://lwn.net/Articles/590243/

Improving ticket spinlocks  http://lwn.net/Articles/531254/

http://ftp.cs.rochester.edu/u/scott/papers/2001_PPoPP_Timeout.pdf
