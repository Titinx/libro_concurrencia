[[spinlocks]]
== _Spinlocks_
Todas las soluciones de exclusión mutua vistas tienen algo en común, una espera activa en un bucle que continuamente verifica el estado de una variable o registro _RMW_ hasta que el proceso puede entrar a la sección crítica. Estos algoritmos se denominan _spinlocks_, el de Dekker, Peterson, la Panadería o cualquiera de las soluciones de exclusión mutua del capítulo anterior son también _spinlocks_. Su uso solo tiene sentido si se cumple una de las siguientes condiciones:

. El código que se ejecuta en la sección crítica es muy breve y por lo tanto la competencia (_contention_) es baja. Esta es una solución empleada desde los inicios de la informática para sincronizar el núcleo de los sistemas operativos e implementar mecanismos de sincronización que evitan las esperas activasfootnote:[Los que veremos en los capítules siguientes.].

. Los procesos se ejecutan en paralelo en diferentes procesadores, mientras unos procesos están en sus _spinlocks_ otros pueden avanzar y salir de la sección crítica. Estas técnicas permiten evitar mayores pérdidas de tiempo ocasionadas por llamadas de sistema y/o cambio de estado de procesos. Si hay muchos más procesos en _spinlocks_ que procesadores se llega a una situación similar a la de un único procesador por lo que los procesos avanzarían muy lentamente y tendría más sentido utilizar construcciones sin esperas activas.

El problema principal es la ineficiencia provocada por la espera activa y los requerimientos de almacenamiento en las soluciones algorítmicas sin registros _RMW_. Por ello se desarrollaron las primitivas de hardware que permiten minimizar el impacto y sobre todo eliminar la necesidad de recorrer una multitud de registros como en el algoritmo de la Panadería. Estas primitivas suponen una gran mejora en el espacio necesario -requieren sólo una palabra por cada sección crítica (o _lock_)- como de facilidades de programación. Pero no todas los procesadores ofrecen las mismas, si se quiere obtener el máximo de eficiencia hay que programar para cada arquitectura como se suele hacer en el núcleo de los sistemas operativos. Para facilitar la portabilidad los compiladores incluyen primitivas fundamentales, los macros o _intrinsics_, que son traducidas a las operaciones que implementan o simulan esas primitivas y que son las que usé para el código de demostraciónfootnote:[Salvo el código en ensamblador con ldrex/strex para ARM.].

Analizaremos el comportamiento de cada uno de estos _spinlocks_ y las técnicas más usadas para optimizarlos. En la siguiente figura se muestran los tiempos de _reloj_ en segundos de la ejecución de los algoritmos del capítulo anterior ejecutados sobre un Intel i5 con 2 cores SMP (barra azul de la izquierda), ARM v7 de Raspberry Pi 2 con cuatro núcleos (barra naranja), ARM v6 de Raspberry 1 (barra amarilla) y finalmente la de una instancia m3.large (con dos núcleos virtuales) de Amazon EC2.

[[hardware_times]]
.Tiempos de ejecución para los diferentes macros e instrucciones de hardware para Intel y ARM v6
[caption=""]
image::times-hardware.png[align="center"]

Cada grupo es una medición diferente. El primero (_none_) es el tiempo sin ningún mecanismo de exclusión mutua. El segundo (_ultimate_) es el más eficiente para este caso de sólo sumar un entero usando la instrucción atómica _getAndAdd_ directamente sobre la variable `counter`. Los siguientes hacia la derecha son los algoritmos usando las instrucciones de hardware del capítulo anterior _swap_, _getAndAdd_, _testAndSet_, _getAndSet_ y _compareAndSwap_ respectivamente.

Se puede observar que todos los algoritmos de exclusión mutua imponen un sobrecoste importante pero que no es uniforme para todas las plataformasfootnote:[En _get&add_ no están los tiempos de la Raspberry 1 y la instancia m3.large porque necesitan mucho tiempo, hasta horas.].

En Raspberry 1 la implementación más eficiente es _getAndSet_ seguida por _compareAndSwap_.
En Raspberry 2 la más eficiente es _compareAndSwap_ (hay que recordar que además de arquitectura más moderna son cuatro procesadores). En Intel la más eficiente es _swap_ y la peor es _compareAndSwap_, un resultado curioso dado que Intel tiene _CAS_ nativo pero en ARM se emula con _LL/SC_.footnote:[También muestra las buenas propiedades de LL/SC.]. Es interesante lo bien que se comporta la instancia EC2, y que _CAS_ sea el más eficiente, seguramente influenciado por las características más modernas del procesador.

=== Optimizaciones
Los _spinlock_ son ineficientes por dos razones:

Uso y competencia por el procesador:: Los procesos consumen el 100% CPU verificando el valor de una variable, si hay más hilos compitiendo que procesadores la mayor parte del tiempo se pierde en el bucle de verificación.

La presión sobre la memoria cache:: Estos algoritmos no son _escalables_ En sistemas con varios procesadores todos los procesos verifican el estado de la misma variable (_hot spot_) por lo que se generan mensajes de sincronización de cache entre los diferentes procesadores.

Aunque son preferibles los _spinlocks_ escalables veremos técnicas básicas para mejorar el rendimiento de los _spinlocks_ anteriores, al final del capítulo veremos los dos algoritmos escalables más importantes.

[NOTE]
._Spinlocks_ escalables
====
Se denominan _spinlocks escalables_ aquellos en que los _fallosfootnote:[No implica que haya producido un error en el sistema sino que el procesador no tiene una copia actualizada en su memoria cache por lo que se deben producir intercambios de mensajes para actualizarla al último valor.] de memoria cache_ se mantienen constantes independientemente de las iteraciones necesarias en la entrada a la sección crítica (<<MCS>>, <<Boyd-Wickizer>>).

Si en cada iteración (o _spin_) los procesos en diferentes procesadores verifican las mismas variables se produce -como mínimo- un _fallo de cache_ cada vez que un proceso cambia de estado ya que cada actualización genera invalidaciones de cache. El problema se agrava por el <<false_sharing, _false sharing_>>, los registros en la sección crítica suelen estar en áreas cercanas a las variables de los _spinlocks_. Por ello se estudiaron _spinlocks escalables_, el fundamental es el <<mcs_queue>> que vemos más adelante.

====

Las tres que veremos a continuación, implementados sobre el _spinlock_ con _testAndSet_, no pueden ser considerados _escalables_ ya que no reducen la presión sobre la memoria cache.

==== Verificación local
Se trata de reducir la presión sobre el sistema de coherencia de cache y evitar la llamada a la instrucción atómica verificando antes (_corto circuitando_) el valor de la variable sobre la que se itera -la variable `mutex` en los ejemplos-. Si ésta vale `1` ya no se llama a la instrucción atómica. Esta técnica se la conoce como _TAS_ o _TATAS_ cuando se usa con la instrucción _TAS_.

[source]
----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        pass
----

La mejora de esta solución depende mucho de la arquitectura y de sus mecanismos de coherencia de cache. En los <<execution_times, tiempos de ejecución>> se observa que esta técnica mejora mucho la eficiencia en las arquitecturas Intel pero son casi despreciables en la arquitectura ARM.

Código fuente para <<test_test_and_set_c, _TAS_>>, <<test_swap_c, _swap_>> y <<test_compare_and_swap_c, _CAS_>>.

==== Ceder el procesador
La idea es sencilla, si un proceso está forzado a continuar en la espera activa porque no se cumple la condición de salida del bucle es mejor ceder el procesador para que otro lo intente o pueda salir antes de la sección crítica. En el ejemplo usamos la llamada de sistema estándar POSIX `sched_yield` que hace que el sistema operativo quite al proceso de ejecución y lo mueva a la cola de _listos para ejecutar_.
[source]
----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        sched_yield()
----
La cesión del procesador <<execution_times, produce reducciones de tiempo importantes>> en todas las arquitecturas salvo excepciones como en _CAS_ sobre la Raspeberry con un único procesadorfootnote:[La causa pueden ser el coste adicional de llamadas de sistemas y cambios de contexto, o el efecto ping-pong de procesos que cambian de estado continuamente.].

Código fuente para <<test_and_set_yield_c, _TAS_>>, <<swap_yield_c, _swap_>> y <<compare_and_swap_yield_c, _CAS_>>.


==== Espera exponencial
La forma de reducir la competencia (_contention_) y evitar que el efecto ping-pong de los procesos es forzar a que permanezcan bloqueados por un tiempo variable dependiendo de las veces que ha _fallado_.


[NOTE]
.Exponential backoff
====
_Exponential backoff_ es la técnica usada por redes Ethernet, WiFi y similares de _bus compartido_ para calcular el tiempo de espera para reenviar después de una colisión, _backoff_ se refiere a la espera y _exponential_ a que el valor límite del tiempo a esperar se duplica en cada _fallo_. El tiempo efectivo de espera de cada proceso es un número aleatorio entre 1 y el límitefootnote:[Se usa un número aleatorio para evitar que todos los procesos reintenten simultáneamente.].

El siguiente es el código en C usado en los ejemplos. En cada iteración fallida dentro del _spinlock_ el proceso incrementa el contador de fallos (`failures`) y llama a la función _backoff_. Ésta calcula el límite (`limit`) con desplazamiento de bits, cada posición desplazada multiplica por dos, por ello se desplaza el bit `1` hacia la izquierda con un máximo de 12, unos 4096 nanosegundos. Luego se calcula el tiempo que esperará con un número random entre 1 y el límite.


[source,c]
----
#define FAILURES_LIMIT 12
void backoff(int failures) {
    struct timespec deadline = {.tv_sec = 0};
    unsigned limit;

    if (failures > FAILURES_LIMIT) {
        limit = 1 << FAILURES_LIMIT;
    } else {
        limit = 1 << failures;
    }

    deadline.tv_nsec = 1 + rand() % limit;
    clock_nanosleep(CLOCK_REALTIME, 0, &deadline, NULL);
}
----
====


[source, c]
----
        mutex = 0

def lock():
    failures = 0

    while mutex or TAS(mutex):
        failures += 1
        backoff(failures)
----

La dificultad del _backoff_ reside en la elección de la unidad de tiempo de espera, no existe un valor ideal y depende de cada arquitectura y caso de uso. Si la espera es muy breve producirá un efecto similar al `sched_yield` con una sobrecarga aún mayor del sistema operativofootnote:[El proceso pasa de ejecución a _bloqueado_ y de allí a _listo_ y nuevamente a ejecución en un tiempo muy breve.]. Por el contrario, si la unidad es muy grande producirá demoras innecesarias y con las CPUs inactivas ya que todos los procesos involucrados están _bloqueados_.

Código fuente para <<test_and_set_backoff_c, _TAS_>>, <<swap_backoff_c, _swap_>> y <<compare_and_swap_backoff_c, _CAS_>>.

[[execution_times]]
==== Tiempos de ejecución
A continuación cuatro gráficas que representan los tiempos de ejecución de los diferentes algoritmos. Hay que recordar que el ejemplo que usamos -hilos que sólo incrementan un contador compartido- son muy extremos. Aunque tienen una sección crítica muy breve lo único que hacen es entrar y salir de ella sin procesamiento adicional lo que significa que la competencia es extremadamente elevada y muy lejos de la inmensa mayoría de casos reales. Pero sirve para tener una base de comparación entre diferentes procesadores y arquitecturas.

También hay que tener en cuenta que los ejemplos fueron programados en C portable usando los macros atómicos de GCC. Éste no siempre genera el mejor código para cada una de las arquitecturas, por ejemplo las de barreras de memoria siempre generan una barrera completa para ARM aunque se especifique que sólo se desea una barrera _release_. En estos casos la única solución es programar estos algoritmos en ensamblador para cada arquitectura diferente, como se hace en el núcleo de los sistemas operativos. Pero de haberlo hecho así me habría generado mucho más trabajo, dificultado la comprensión de lo fundamental y hasta las pruebas que podéis hacer vosotros mismos con los programas.

Lo interesante de las gráficas:

- El _compareAndSwap_ es la más ineficiente en Intel i5 y en el Core2 Quad pero la más eficiente en una instancia m3 de Amazon EC2.

- [[core2_vs_i5]]La mayor eficiencia del Intel i5 sobre el Core2 a pesar de que el segundo tiene más núcleos se debe a que el _Front Side Buffer_ del Intel Core2 usa un bus compartido para los mensajes del protocolo de coherencia de cache mientras que el i5 tiene el nuevo sistema <<quickpath, _QuickPath Interconnect_>>.

- Es notable el buen comportamiento y uniformidad de ARM para todas las instrucciones, sobre todo porque ellas se emulan con el _LL/SC_. En ambas versions, v6 y v7 (de Raspberry 1 y 2 respectivamente) el _compareAndSwap_ es la más eficiente.

- La unidad de espera elegida para el `backoff` funciona muy bien en la Raspberry 1 aunque en principio no parecía una buena candidata.

- En todas las plataformas con multiprocesadores el `sched_yield` y el `backoff` producen reducciones de tiempos importantes, incluso cuando el número de procesos concurrentes (cuatro) es igual al número de procesadores (en el Intel Quad y en ARM v7 de Raspberry 2). La mejora no se debe a la reducción de uso de la CPU sino a la menor presión sobre el sistema de coherencia de cache,footnote:[Puedes hacer la prueba, en la versión de _backoff_ reemplaza el `clock_nanosleep` por un bucle como `for (i = 0; i < limit; i++);` y verás que se produce la misma reducción -incluso mayor-, simplemente por no acceder a las variables compartidas continuamente.] la causa principal por la que se estudiaron _spinlocks_ escalables.

[NOTE]
.Cede el procesador
====
No te despedirán por poner un `sched_yield` o _backoff_ exponencial en un _spinlock_ con mucha competencia aunque parezca que sobran procesadores o núcleos.
====

.Intel Core2 cuatro núcleos
image::optimized-intel-quad.png[align="center"]

.Intel i5 dos núcleos con extensión SMP
image::optimized-intel.png[align="center"]

.Intel AWS m3.large dos núcleos
image::optimized-m3-large.png[align="center"]

.ARMv7 Raspberry 2 cuatro núcleos
image::optimized-arm7.png[align="center"]

.ARMv6 Raspberry 1
image::optimized-arm.png[align="center"]


=== Lectores-escritores
La mayoría de las operaciones que se hacen sobre la memoria, incluida la compartida, son acceso para lectura. En estos casos interesa que las lecturas sean consistentes. En nuestros ejemplos con un único contador entero no existe el problema, las palabras de 32 bits son <<atomic_register, registros atómicos>> en las arquitecturas de 32 bits o más. Si un proceso  lee ese esa variable siempre obtendrá el último valor escrito. Pero si se trata de estructuras más complejas -incluso el acceso a ficheros o dispositivos externos- hay que imponer restricciones para que la estructura no sea modificada mientras haya procesos que la están accediendo.

Se puede usar exclusión mutua pero ello emplica que se estarían _serializando_ hasta los accesos de sólo lectura, es un mecanismo nada eficiente. Por ello una de las relajaciones más importantes a las condiciones de la exclusión mutua es que se permita que haya más de un lector en la sección crítica de forma simultánea, estos algoritmos de sincronización son llamados lectores-escritores (_reader-writer_).

Las condiciones que deben cumplir son:

- Se permite más de un lector.

- Mientras haya un lector en la sección crítica no puede entrar ningún escritor.

- Los lectores no pueden entrar si hay un escritor en la sección crítica.

- Sólo puede haber un escritor en la sección crítica.

Así como la exclusión mutua tiene un mecanismo de entrada la sección crítica (_lock_) y otro de salida (_unlock_) los de lectores-escritores necesitan distinguir entre ambos con  entradas y salidas diferenciadas (_reader_lock_, _writer_lock_, _reader_unlock_ y _writer_unlock_).

El siguiente algoritmo es uno simple (<<rw_lock_c, código en C>>) que se implementa con las instrucciones _compareAndSwap_ y _getAndAdd_:

.Entrada y salida para lectores
[source]
----
            rw_lock = 0             <1>

def reader_lock():
    while True:
        while rw_lock & 0x80000000: <2>
            pass
        old = rw_lock & 0x7fffffff  <3>
        new = old + 1               <4>
        if CAS(rw_lock, old, new):  <5>
            return


def reader_unlock():
    getAndAdd(rw_lock, -1)          <6>
----
<1> Necesitamos una variable global, en el ejemplo de 32 bits permite hasta 2^31^ lectores simultáneos, el bit más significativo será usado para indicar que hay un escritor.
<2> Verifica si el bit más significativo es `1`, si es así hay un escritor e itera hasta que sea `0`.
<3> No hay escritores, obtiene el número de lectores.
<4> Incrementa el número de lectores.
<5> Si `rw_lock` no fue modificado el _compareAndSwap_ almacenará el nuevo valor. Si  `rw_lock` fue modificado volverá al inicio del `while` y lo intentará nuevamente.
<6> Decrementa atómicamente el número de lectores.

.Entrada y salida para escritores
[source]
----
def writer_lock():
    while True:
        while rw_lock & 0x80000000:     <1>
            pass
        old = rw_lock & 0x7fffffff      <2>
        new = old | 0x80000000          <3>
        if CAS(rw_lock, old, new):      <4>
            while rw_lock & 0x7fffffff: <5>
                pass
            return


def writer_unlock():
    rw_lock = 0    <6>

----
<1> Verifica el bit más significativo e itera hasta que no haya ningún escritor.
<2> Obtiene el número de lectores actuales.
<3> Calcula el nuevo valor, será el número de lectores con el bit más significativo en `1` indicando que hay un escritor.
<4> Si el valor tomado de `rw_lock` no cambió se almacena el nuevo, caso contrario vuelve al principio del `while` para reintentarlo.
<5> Espera que salgan todos los lectores que ya estaban en la seccción crítica, los siguientes ya no podrán entrar porque el bit más significativo está en `1`.
<6> Para salir sólo debe poner `rw_lock` en cero ya que no quedan lectores ni escritores en la sección crítica.


Una característica importante de los algoritmos de lectores-escritores es la prioridad que da a unos o a otros. Si lo que interesa es _rendimiento_ (_throughput_) y lecturas muy rápidas es mejor dar prioridad a los lectores. Si por el contrario interesa que las actualizaciones sean rápidas y poder acceder a los últimos valores lo más rápido posible se deben usar algoritmos que den prioridad a los escritores. El problema es el riesgo de inanición en los que no tienen prioridad, aunque hay algoritmos complejos que aseguran equidad (<<MCS2>>) los más comunes dan prioridad a uno de ellos.

Queda a ejercicio del lector encontrar si este algoritmo da prioridad a los lectores o escritoresfootnote:[Seguramente no lo has mirado todavía, pero este algoritmo da prioridad a los escritores. Cuando un escritor desea entrar a la sección crítica pone en `1` el bit más significativo, independientemente de los lectores que estén dentro, haciendo que los siguientes lectores que lleguen esperen hasta que el escritor haya entrado y salido.].

=== _Spinlocks_ equitativos



[[mcs_queue]]
==== MCS Spinlock


.Cola MCS
image::mcs.png[align="center"]

==== CLH Spinlock

[[clh_queue]]
.Cola CLH
image::clh.png[align="center"]


===== Ticket vs MCS vs CLH
image::ticket-mcs-clh.png[align="center"]

===== Ticket vs MCS vs CLH con sched_yield
image::ticket-mcs-clh-yield.png[align="center"]


Agradecimientos a Marc Pampols



Reader-writer: https://jfdube.wordpress.com/2014/01/03/implementing-a-recursive-read-write-spinlock/
https://jfdube.wordpress.com/2014/01/12/optimizing-the-recursive-read-write-spinlock/



(http://nullprogram.com/blog/2014/09/02/ https://github.com/skeeto/lstack)
Common Pitfalls in Writing Lock-Free Algorithms http://blog.memsql.com/common-pitfalls-in-writing-lock-free-algorithms/

Toward generic atomic operations/The C11 memory model http://lwn.net/Articles/509102/

Ticket Spinlocks: http://lwn.net/Articles/267968/
Ticket implementation https://github.com/karthick18/ticket_spinlock/blob/master/spinlock.h



Lightweight Contention Management for
Efficient Compare-and-Swap Operations http://arxiv.org/pdf/1305.5800.pdf

MCSLocks http://lwn.net/Articles/590243/

Improving ticket spinlocks  http://lwn.net/Articles/531254/

http://ftp.cs.rochester.edu/u/scott/papers/2001_PPoPP_Timeout.pdf
