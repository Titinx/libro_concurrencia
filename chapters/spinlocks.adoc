[[spinlocks]]
== _Spinlocks_ eficientes
Todas las soluciones de exclusión mutua vistas tienen algo en común, un bucle que continuamentefootnote:[Es decir, en espera activa.] verifica el estado de una variable o registro _RMW_ hasta que el proceso puede entrar a la sección crítica. Estos algoritmos se denominan _spinlocks_, el de Dekker, Peterson, la Panadería o cualquiera de las soluciones de exclusión mutua del capítulo anterior son también _spinlocks_. Su uso solo tiene sentido si se cumplen una de las siguientes condiciones:

. El código que se ejecuta en la sección crítica es muy breve y por lo tanto la competencia (_contention_) es baja. Esta es una solución empleada desde los inicios de la informática para sincronizar el núcleo de los sistemas operativos e implementar mecanismos de sincronización que evitan las esperas activasfootnote:[Los que veremos en los capítules siguientes.].

. Los procesos se ejecutan en paralelo en diferemtes procesadores, mientras unos procesos están en sus _spinlocks_ otros pueden avanzar y salir de la sección crítica. Estas técnicas permiten evitar mayores pérdidas de tiempo ocasionadas por llamadas de sistema y/o cambio de estado de procesos. Si hay muchos más procesos en _spinlocks_ que procesadores se llega a una situación similar a la de un único procesador por lo que los procesos avanzarían muy lentamente y tendría más sentido utilizar construcciones sin esperas activas.


El problema principal es la ineficiencia provocada por la espera activa y los requerimientos de almacenamiento en las soluciones algorítmicas sin registros _RMW_. Por ello se desarrollaron las primitivas de hardware que permiten minimizar el impacto y sobre todo eliminar la necesidad de recorrer una multitud de registros como en el algoritmo de la Panadería. Estas primitivas suponen una gran mejora tanto en eficiencia -de CPU y espacio- como de facilidades de programación. Pero no todas los procesadores ofrecen las mismas, si se quiere obtener el máximo de eficiencia hay que programar para cada arquitectura como se suele hacer en el núcleo de los sistemas operativos. Para facilitar el trabajo a los programadores los compiladores incluyen primitivas fundamentales, los macros o _intrinsics_, que son traducidas a las operaciones que implementan o simulan esas primitivas y que son las que usé para el código de demostraciónfootnote:[Salvo el código en ensamblador con ldrex/strex para ARM.].

Ahora toca analizar brevemente el comportamiento de cada una y las técnicas más usadas para optimizar los _spinlocks_. En la siguiente figura se muestran los tiempos de _reloj_ en segundos de la ejecución de los algoritmos del capítulo anterior ejecutados sobre un Intel i5 con 4 procesadores (barra azul de la izquierda), ARM v7 de Raspberry Pi 2 con cuatro núcleos (barra naranja), ARM v6 de Raspberry 1 (barra amarilla) y finalmente la de una instancia m3.largefootnote:[Dos núcleos virtuales.] de Amazon EC2.

[[hardware_times]]
.Tiempos de ejecución para los diferentes macros e instrucciones de hardware para Intel y ARM v6
[caption=""]
image::times-hardware.png[align="center"]

Cada grupo es una medición diferente. El primero (_none_) es el tiempo sin ningún mecanismo de exclusión mutua. El segundo (_ultimate_) es el más eficiente para este caso de sólo sumar un entero usando la instrucción atómica _getAndAdd_ directamente sobre la variable `counter`. Los siguientes hacia la derecha son los algoritmos usando las instrucciones de hardware del capítulo anterior _swap_, _getAndAdd_, _testAndSet_, _getAndSet_ y _compareAndSwap_ respectivamente.

Se puede obervar que todos los algoritmos de exclusión mutua imponen un sobrecoste importante pero que no es uniforme para todas las plataformasfootnote:[En _get&add_ no están los tiempos de la Raspberry 1 y la instancia m3.large porque necesitan mucho tiempo, hasta horas.].

En Raspberry 1 la implementación más eficiente es _getAndSet_ seguida por _compareAndSwap_.
En Raspberry 2 la más eficiente es _compareAndSwap_ (hay que recordar que además de arquitectura más moderna son cuatro procesadores). En Intel la más eficiente es _swap_ y la peor es _compareAndSwap_, un resultado curioso dado que Intel tiene _CAS_ nativo pero en ARM se emula con _LL/SC_.footnote:[También muestra las buenas propiedades de LL/SC.]. Es muy curioso lo bien que se comporta la instancia EC2, y que _CAS_ sea el más eficiente, seguramente influenciado por las caractéristicas más modernas del procesador.

=== Optimizaciones
Los _spinlock_ son ineficientes por dos razones:

Uso y competencia por el procesador:: Los procesos consumen el 100% CPU verificando el valor de una variable, si hay más hilos compitiendo que procesadores la mayor parte del tiempo se pierde en el bucle de verificación.

La presión sobre la memoria cache:: En sistemas con varios procesadores todos los procesos verifican el estado de la misma variable por lo que se generan mensajes o controles de sincronización con la memoria cache de los otros procesadores.

Las técnicas para hacer más eficiente implican básicamente reducir ambos parámetros. Las tres que veremos a continuación son las más sencillas, veremos cómo implementarlas tomando como base la instrucción _testAndCompare_.

 el _test local_ es evitar ejecutar las instrucciones atómicas ya que estas consumen más ciclos de reloj de CPU y sobre todo fuerzan a la sincronización de memoria cache. Para minimizar la competencia por el procesador hay que hacer que un proceso que no puede entrar a la sección crítica ceda el procesador a otro, se hace de dos formas, solicitando al sistema operativo que le pase a la cola de listos (_sched_yield_) o bloquearse por un tiempo variable aleatorio e incremental (_exponential backoff_).

==== Test local
La idea es evitar llamar a la instrucción atómica más _cara_ y compleja verificando antes (_corto circuitando_) el valor de la variable sobre la que se itera, en nuestros casos `mutex`. Si éste vale `1` ya no llamamamos a la instrucción _TAS_.

[source]
----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        pass
----

La mejora de esta solución depende mucho de la arquitectura y de sus mecanismos de coherencia de cache.

==== Ceder el procesador
La idea es sencilla, si un proceso está forzado a continuar en la espera activa porque no se cumple la condición de salida del bucle es mejor ceder el procesador para que otro lo intente o salga de la sección crítica. En el ejemplo usamos la llamada de sistema estándar POSIX `sched_yield` que hace que el sistema operativo quite al proceso de ejecución y lo lleve a la cola de _listos para ejecutar_.
[source]
----
        mutex = 0

def lock():
    while mutex or TAS(mutex):
        sched_yield()
----

La llamada a _sched_yield_ no significa que no continúe la ejecución, si no hay otro continuará el mismo. Por este motivo a veces no da los resultados esperados, en teoría debería beneficiar sobre todo a sistemas con un único procesador, pero como <<execution_times, se observa en los tiempos de ejecución>> en Raspberry 1 reduce muy poco e incluso perjudica en algunos casos. Las causas pueden ser el coste adicional de llamadas de sistemas y cambios de contexto, o el efecto ping-pong de procesos que cambian de estado continuamente.


==== Espera exponencial
La forma de reducir la competencia (_contention_) y evitar que el efecto ping-pong de los procesos es forzar a que permanezcan bloqueados por un tiempo variable dependiendo de las veces que ha _fallado_. Cuando un _spinlock_ usa mecanismos de este tipo para reducir la competencia se denominan _escalables_ (<<Boyd-Wickizer>>).


[NOTE]
.Exponential backoff
====
_Exponential backoff_ es la técnica usada por redes Ethernet o WiFi (y similares de bus compartido) para calcular el tiempo de espera para reenviar después de una colisión, _backoff_ se refiere a la espera y _exponential_ a que el valor límite del tiempo a esperar se duplica en cada _fallo_. El tiempo efectivo de espera de cada proceso es un número aleatorio entre 1 y el límitefootnote:[Se usa un número aleatorio para evitar que todos los procesos reintenten simultáneamente.].

El siguiente es el código en C usado en los ejemplos. En cada iteración fallida dentro del _spinlock_ el proceso incrementa el contado de fallos (`failures`) y llama a la función _backoff_. Ésta calcula el límite (`limit`) con desplazamiento de bits, cada posición desplazada multiplica por dos, por ello se desplaza el bit `1` hacia la izquierda con un máximo de 12, unos 4096 nanosegunodos. Luego se calcula el tiempo que esperará con un número random entre 1 y el límite.


[source,c]
----
#define FAILURES_LIMIT 12
void backoff(int failures) {
    struct timespec deadline = {.tv_sec = 0};
    unsigned limit;

    if (failures > FAILURES_LIMIT) {
        limit = 1 << FAILURES_LIMIT;
    } else {
        limit = 1 << failures;
    }

    deadline.tv_nsec = 1 + rand() % limit;
    clock_nanosleep(CLOCK_REALTIME, 0, &deadline, NULL);
}
----
====


[source]
----
        mutex = 0

def lock():
    failures = 0

    while mutex or TAS(mutex):
        failures += 1
        backoff(failures)
----


[[execution_times]]
==== Tiempos de ejecución

===== Intel i5 cuatro núcleos
image::optimized-intel.png[align="center"]

===== Intel AWS m3.large
image::optimized-m3-large.png[align="center"]

===== ARMv7 Raspberry 2
image::optimized-arm7.png[align="center"]

===== ARMv6 Raspberry 1
image::optimized-arm.png[align="center"]


===== Ticket vs MCS vs CLH
image::ticket-mcs-clh.png[align="center"]

===== Ticket vs MCS vs CLH con sched_yield
image::ticket-mcs-clh-yield.png[align="center"]


Reader-writer: https://jfdube.wordpress.com/2014/01/03/implementing-a-recursive-read-write-spinlock/
https://jfdube.wordpress.com/2014/01/12/optimizing-the-recursive-read-write-spinlock/



(http://nullprogram.com/blog/2014/09/02/ https://github.com/skeeto/lstack)
Common Pitfalls in Writing Lock-Free Algorithms http://blog.memsql.com/common-pitfalls-in-writing-lock-free-algorithms/

Toward generic atomic operations/The C11 memory model http://lwn.net/Articles/509102/

Ticket Spinlocks: http://lwn.net/Articles/267968/
Ticket implementation https://github.com/karthick18/ticket_spinlock/blob/master/spinlock.h



Lightweight Contention Management for
Efficient Compare-and-Swap Operations http://arxiv.org/pdf/1305.5800.pdf

MCSLocks http://lwn.net/Articles/590243/

Improving ticket spinlocks  http://lwn.net/Articles/531254/

http://ftp.cs.rochester.edu/u/scott/papers/2001_PPoPP_Timeout.pdf


==== MCS Spinlocks

[[mcs_queue]]
.Cola MCS
image::mcs.png[width=400, align="center"]

Agradecimientos a Marc Pampols
